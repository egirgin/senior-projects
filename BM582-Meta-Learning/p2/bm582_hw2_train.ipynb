{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bm582-hw2-train.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8hebvdDF1pxS",
        "outputId": "d5cb6c3b-dea7-4164-da7c-3cdd22ebfeae"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysnSzT3-11j9",
        "outputId": "681bd098-0ec5-4946-bfa6-6cc60b6fbade"
      },
      "source": [
        "!rsync -r --progress ./drive/MyDrive/MoNuSegTestData.zip .\n",
        "!rsync -r --progress ./drive/MyDrive/MoNuSegTrainingData.zip ."
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sending incremental file list\n",
            "MoNuSegTestData.zip\n",
            "     41,620,178 100%   72.77MB/s    0:00:00 (xfr#1, to-chk=0/1)\n",
            "sending incremental file list\n",
            "MoNuSegTrainingData.zip\n",
            "     84,126,760 100%   60.62MB/s    0:00:01 (xfr#1, to-chk=0/1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHiofjZR134s",
        "outputId": "d35fb21a-4125-46ef-f87a-b9eb528395f1"
      },
      "source": [
        "!unzip MoNuSegTestData.zip\n",
        "!unzip MoNuSegTrainingData.zip\n",
        "!rm MoNuSegTestData.zip\n",
        "!rm MoNuSegTrainingData.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  MoNuSegTestData.zip\n",
            "   creating: MoNuSegTestData/\n",
            "  inflating: MoNuSegTestData/TCGA-2Z-A9J9-01A-01-TS1.tif  \n",
            "  inflating: MoNuSegTestData/TCGA-2Z-A9J9-01A-01-TS1.xml  \n",
            "  inflating: MoNuSegTestData/TCGA-44-2665-01B-06-BS6.tif  \n",
            "  inflating: MoNuSegTestData/TCGA-44-2665-01B-06-BS6.xml  \n",
            "  inflating: MoNuSegTestData/TCGA-69-7764-01A-01-TS1.tif  \n",
            "  inflating: MoNuSegTestData/TCGA-69-7764-01A-01-TS1.xml  \n",
            "  inflating: MoNuSegTestData/TCGA-A6-6782-01A-01-BS1.tif  \n",
            "  inflating: MoNuSegTestData/TCGA-A6-6782-01A-01-BS1.xml  \n",
            "  inflating: MoNuSegTestData/TCGA-AC-A2FO-01A-01-TS1.tif  \n",
            "  inflating: MoNuSegTestData/TCGA-AC-A2FO-01A-01-TS1.xml  \n",
            "  inflating: MoNuSegTestData/TCGA-AO-A0J2-01A-01-BSA.tif  \n",
            "  inflating: MoNuSegTestData/TCGA-AO-A0J2-01A-01-BSA.xml  \n",
            "  inflating: MoNuSegTestData/TCGA-CU-A0YN-01A-02-BSB.tif  \n",
            "  inflating: MoNuSegTestData/TCGA-CU-A0YN-01A-02-BSB.xml  \n",
            "  inflating: MoNuSegTestData/TCGA-EJ-A46H-01A-03-TSC.tif  \n",
            "  inflating: MoNuSegTestData/TCGA-EJ-A46H-01A-03-TSC.xml  \n",
            "  inflating: MoNuSegTestData/TCGA-FG-A4MU-01B-01-TS1.tif  \n",
            "  inflating: MoNuSegTestData/TCGA-FG-A4MU-01B-01-TS1.xml  \n",
            "  inflating: MoNuSegTestData/TCGA-GL-6846-01A-01-BS1.tif  \n",
            "  inflating: MoNuSegTestData/TCGA-GL-6846-01A-01-BS1.xml  \n",
            "  inflating: MoNuSegTestData/TCGA-HC-7209-01A-01-TS1.tif  \n",
            "  inflating: MoNuSegTestData/TCGA-HC-7209-01A-01-TS1.xml  \n",
            "  inflating: MoNuSegTestData/TCGA-HT-8564-01Z-00-DX1.tif  \n",
            "  inflating: MoNuSegTestData/TCGA-HT-8564-01Z-00-DX1.xml  \n",
            "  inflating: MoNuSegTestData/TCGA-IZ-8196-01A-01-BS1.tif  \n",
            "  inflating: MoNuSegTestData/TCGA-IZ-8196-01A-01-BS1.xml  \n",
            "  inflating: MoNuSegTestData/TCGA-ZF-A9R5-01A-01-TS1.tif  \n",
            "  inflating: MoNuSegTestData/TCGA-ZF-A9R5-01A-01-TS1.xml  \n",
            "Archive:  MoNuSegTrainingData.zip\n",
            "   creating: MoNuSegTrainingData/\n",
            "   creating: MoNuSegTrainingData/Annotations/\n",
            "  inflating: MoNuSegTrainingData/Annotations/TCGA-18-5592-01Z-00-DX1.xml  \n",
            "  inflating: MoNuSegTrainingData/Annotations/TCGA-21-5784-01Z-00-DX1.xml  \n",
            "  inflating: MoNuSegTrainingData/Annotations/TCGA-21-5786-01Z-00-DX1.xml  \n",
            "  inflating: MoNuSegTrainingData/Annotations/TCGA-38-6178-01Z-00-DX1.xml  \n",
            "  inflating: MoNuSegTrainingData/Annotations/TCGA-49-4488-01Z-00-DX1.xml  \n",
            "  inflating: MoNuSegTrainingData/Annotations/TCGA-50-5931-01Z-00-DX1.xml  \n",
            "  inflating: MoNuSegTrainingData/Annotations/TCGA-A7-A13E-01Z-00-DX1.xml  \n",
            "  inflating: MoNuSegTrainingData/Annotations/TCGA-A7-A13F-01Z-00-DX1.xml  \n",
            "  inflating: MoNuSegTrainingData/Annotations/TCGA-AR-A1AK-01Z-00-DX1.xml  \n",
            "  inflating: MoNuSegTrainingData/Annotations/TCGA-AR-A1AS-01Z-00-DX1.xml  \n",
            "  inflating: MoNuSegTrainingData/Annotations/TCGA-AY-A8YK-01A-01-TS1.xml  \n",
            "  inflating: MoNuSegTrainingData/Annotations/TCGA-B0-5698-01Z-00-DX1.xml  \n",
            "  inflating: MoNuSegTrainingData/Annotations/TCGA-B0-5710-01Z-00-DX1.xml  \n",
            "  inflating: MoNuSegTrainingData/Annotations/TCGA-B0-5711-01Z-00-DX1.xml  \n",
            "  inflating: MoNuSegTrainingData/Annotations/TCGA-CH-5767-01Z-00-DX1.xml  \n",
            "  inflating: MoNuSegTrainingData/Annotations/TCGA-DK-A2I6-01A-01-TS1.xml  \n",
            "  inflating: MoNuSegTrainingData/Annotations/TCGA-E2-A14V-01Z-00-DX1.xml  \n",
            "  inflating: MoNuSegTrainingData/Annotations/TCGA-E2-A1B5-01Z-00-DX1.xml  \n",
            "  inflating: MoNuSegTrainingData/Annotations/TCGA-G2-A2EK-01A-02-TSB.xml  \n",
            "  inflating: MoNuSegTrainingData/Annotations/TCGA-G9-6336-01Z-00-DX1.xml  \n",
            "  inflating: MoNuSegTrainingData/Annotations/TCGA-G9-6348-01Z-00-DX1.xml  \n",
            "  inflating: MoNuSegTrainingData/Annotations/TCGA-G9-6356-01Z-00-DX1.xml  \n",
            "  inflating: MoNuSegTrainingData/Annotations/TCGA-G9-6362-01Z-00-DX1.xml  \n",
            "  inflating: MoNuSegTrainingData/Annotations/TCGA-G9-6363-01Z-00-DX1.xml  \n",
            "  inflating: MoNuSegTrainingData/Annotations/TCGA-HE-7128-01Z-00-DX1.xml  \n",
            "  inflating: MoNuSegTrainingData/Annotations/TCGA-HE-7129-01Z-00-DX1.xml  \n",
            "  inflating: MoNuSegTrainingData/Annotations/TCGA-HE-7130-01Z-00-DX1.xml  \n",
            "  inflating: MoNuSegTrainingData/Annotations/TCGA-KB-A93J-01A-01-TS1.xml  \n",
            "  inflating: MoNuSegTrainingData/Annotations/TCGA-NH-A8F7-01A-01-TS1.xml  \n",
            "  inflating: MoNuSegTrainingData/Annotations/TCGA-RD-A8N9-01A-01-TS1.xml  \n",
            "   creating: MoNuSegTrainingData/Tissue Images/\n",
            "  inflating: MoNuSegTrainingData/Tissue Images/TCGA-18-5592-01Z-00-DX1.tif  \n",
            "  inflating: MoNuSegTrainingData/Tissue Images/TCGA-21-5784-01Z-00-DX1.tif  \n",
            "  inflating: MoNuSegTrainingData/Tissue Images/TCGA-21-5786-01Z-00-DX1.tif  \n",
            "  inflating: MoNuSegTrainingData/Tissue Images/TCGA-38-6178-01Z-00-DX1.tif  \n",
            "  inflating: MoNuSegTrainingData/Tissue Images/TCGA-49-4488-01Z-00-DX1.tif  \n",
            "  inflating: MoNuSegTrainingData/Tissue Images/TCGA-50-5931-01Z-00-DX1.tif  \n",
            "  inflating: MoNuSegTrainingData/Tissue Images/TCGA-A7-A13E-01Z-00-DX1.tif  \n",
            "  inflating: MoNuSegTrainingData/Tissue Images/TCGA-A7-A13F-01Z-00-DX1.tif  \n",
            "  inflating: MoNuSegTrainingData/Tissue Images/TCGA-AR-A1AK-01Z-00-DX1.tif  \n",
            "  inflating: MoNuSegTrainingData/Tissue Images/TCGA-AR-A1AS-01Z-00-DX1.tif  \n",
            "  inflating: MoNuSegTrainingData/Tissue Images/TCGA-AY-A8YK-01A-01-TS1.tif  \n",
            "  inflating: MoNuSegTrainingData/Tissue Images/TCGA-B0-5698-01Z-00-DX1.tif  \n",
            "  inflating: MoNuSegTrainingData/Tissue Images/TCGA-B0-5710-01Z-00-DX1.tif  \n",
            "  inflating: MoNuSegTrainingData/Tissue Images/TCGA-B0-5711-01Z-00-DX1.tif  \n",
            "  inflating: MoNuSegTrainingData/Tissue Images/TCGA-CH-5767-01Z-00-DX1.tif  \n",
            "  inflating: MoNuSegTrainingData/Tissue Images/TCGA-DK-A2I6-01A-01-TS1.tif  \n",
            "  inflating: MoNuSegTrainingData/Tissue Images/TCGA-E2-A14V-01Z-00-DX1.tif  \n",
            "  inflating: MoNuSegTrainingData/Tissue Images/TCGA-E2-A1B5-01Z-00-DX1.tif  \n",
            "  inflating: MoNuSegTrainingData/Tissue Images/TCGA-G2-A2EK-01A-02-TSB.tif  \n",
            "  inflating: MoNuSegTrainingData/Tissue Images/TCGA-G9-6336-01Z-00-DX1.tif  \n",
            "  inflating: MoNuSegTrainingData/Tissue Images/TCGA-G9-6348-01Z-00-DX1.tif  \n",
            "  inflating: MoNuSegTrainingData/Tissue Images/TCGA-G9-6356-01Z-00-DX1.tif  \n",
            "  inflating: MoNuSegTrainingData/Tissue Images/TCGA-G9-6362-01Z-00-DX1.tif  \n",
            "  inflating: MoNuSegTrainingData/Tissue Images/TCGA-G9-6363-01Z-00-DX1.tif  \n",
            "  inflating: MoNuSegTrainingData/Tissue Images/TCGA-HE-7128-01Z-00-DX1.tif  \n",
            "  inflating: MoNuSegTrainingData/Tissue Images/TCGA-HE-7129-01Z-00-DX1.tif  \n",
            "  inflating: MoNuSegTrainingData/Tissue Images/TCGA-HE-7130-01Z-00-DX1.tif  \n",
            "  inflating: MoNuSegTrainingData/Tissue Images/TCGA-KB-A93J-01A-01-TS1.tif  \n",
            "  inflating: MoNuSegTrainingData/Tissue Images/TCGA-NH-A8F7-01A-01-TS1.tif  \n",
            "  inflating: MoNuSegTrainingData/Tissue Images/TCGA-RD-A8N9-01A-01-TS1.tif  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZIyEbRc6PZk",
        "outputId": "b9ea9b56-ec19-4338-986b-687ca0c60bf5"
      },
      "source": [
        "!pip install xmltodict"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting xmltodict\n",
            "  Downloading https://files.pythonhosted.org/packages/28/fd/30d5c1d3ac29ce229f6bdc40bbc20b28f716e8b363140c26eff19122d8a5/xmltodict-0.12.0-py2.py3-none-any.whl\n",
            "Installing collected packages: xmltodict\n",
            "Successfully installed xmltodict-0.12.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-M7PXUcH3sXF",
        "outputId": "6d5c6bfd-3b83-4c6f-b92e-485a503f1b8c"
      },
      "source": [
        "import glob, os, cv2\n",
        "import numpy as np\n",
        "import xmltodict\n",
        "import shutil\n",
        "\n",
        "def mask2impath_train(path):\n",
        "  return path.replace(\"Annotations\", \"Tissue Images\").replace(\".xml\", \".tif\")\n",
        "def mask2impath_test(path):\n",
        "  return path.replace(\".xml\", \".tif\")\n",
        "\n",
        "def create_mask(data_path, imwrite_path):\n",
        "\n",
        "  #data_path = \"./MoNuSegTrainingData/\"\n",
        "  annos = glob.glob(os.path.join(data_path, \"*.xml\"))\n",
        "  #imwrite_path = \"MoNuSegTrainingData/annot_jpg\"\n",
        "  try:\n",
        "    shutil.rmtree(imwrite_path)\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "  os.mkdir(imwrite_path)\n",
        "\n",
        "  for anno_path in annos:\n",
        "    print(anno_path)\n",
        "    cnts = []\n",
        "    with open(anno_path, \"r\") as f:\n",
        "      anno = xmltodict.parse(f.read())\n",
        "\n",
        "      try:\n",
        "        regions = anno[\"Annotations\"][\"Annotation\"][\"Regions\"][\"Region\"]\n",
        "      except:\n",
        "        regions = anno[\"Annotations\"][\"Annotation\"][0][\"Regions\"][\"Region\"]\n",
        "\n",
        "      for region in regions:\n",
        "        cnt = []\n",
        "        for point in region[\"Vertices\"][\"Vertex\"]:\n",
        "          cnt.append([float(point[\"@X\"]), float(point[\"@Y\"])])\n",
        "        cnt = np.array(cnt).reshape((-1,1,2)).astype(np.int32)\n",
        "        cnts.append(cnt)\n",
        "\n",
        "    if \"Annotations\" in data_path:\n",
        "      img = cv2.imread(mask2impath_train(anno_path))\n",
        "    else:\n",
        "      img = cv2.imread(mask2impath_test(anno_path))\n",
        "\n",
        "    img_zero = np.zeros_like(img)\n",
        "    img_mask = cv2.drawContours(img_zero, cnts, -1, (255,255,255), 3)\n",
        "\n",
        "    img = cv2.resize(img, (256,256))\n",
        "    img_mask = cv2.resize(img_mask, (256, 256))\n",
        "\n",
        "    if \"Annotations\" in data_path:\n",
        "      imwrite_path2 = os.path.join(imwrite_path, mask2impath_train(anno_path).split(\"/\")[-1].replace(\".tif\", \".png\"))\n",
        "    else:\n",
        "      imwrite_path2 = os.path.join(imwrite_path, mask2impath_test(anno_path).split(\"/\")[-1].replace(\".tif\", \".png\"))\n",
        "    #imwrite_path2 = os.path.join(imwrite_path, mask2impath(anno_path).split(\"/\")[-1].replace(\".tif\", \".png\"))\n",
        "    print(\"path: \", imwrite_path2)\n",
        "    cv2.imwrite(imwrite_path2, img_mask)\n",
        "\n",
        "\n",
        "create_mask(data_path = \"./MoNuSegTrainingData/Annotations\", imwrite_path = \"MoNuSegTrainingData/trainB\")\n",
        "create_mask(data_path = \"./MoNuSegTestData/\", imwrite_path = \"MoNuSegTestData/valB\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "./MoNuSegTrainingData/Annotations/TCGA-21-5786-01Z-00-DX1.xml\n",
            "path:  MoNuSegTrainingData/trainB/TCGA-21-5786-01Z-00-DX1.png\n",
            "./MoNuSegTrainingData/Annotations/TCGA-AR-A1AS-01Z-00-DX1.xml\n",
            "path:  MoNuSegTrainingData/trainB/TCGA-AR-A1AS-01Z-00-DX1.png\n",
            "./MoNuSegTrainingData/Annotations/TCGA-DK-A2I6-01A-01-TS1.xml\n",
            "path:  MoNuSegTrainingData/trainB/TCGA-DK-A2I6-01A-01-TS1.png\n",
            "./MoNuSegTrainingData/Annotations/TCGA-G9-6362-01Z-00-DX1.xml\n",
            "path:  MoNuSegTrainingData/trainB/TCGA-G9-6362-01Z-00-DX1.png\n",
            "./MoNuSegTrainingData/Annotations/TCGA-B0-5711-01Z-00-DX1.xml\n",
            "path:  MoNuSegTrainingData/trainB/TCGA-B0-5711-01Z-00-DX1.png\n",
            "./MoNuSegTrainingData/Annotations/TCGA-18-5592-01Z-00-DX1.xml\n",
            "path:  MoNuSegTrainingData/trainB/TCGA-18-5592-01Z-00-DX1.png\n",
            "./MoNuSegTrainingData/Annotations/TCGA-HE-7129-01Z-00-DX1.xml\n",
            "path:  MoNuSegTrainingData/trainB/TCGA-HE-7129-01Z-00-DX1.png\n",
            "./MoNuSegTrainingData/Annotations/TCGA-38-6178-01Z-00-DX1.xml\n",
            "path:  MoNuSegTrainingData/trainB/TCGA-38-6178-01Z-00-DX1.png\n",
            "./MoNuSegTrainingData/Annotations/TCGA-21-5784-01Z-00-DX1.xml\n",
            "path:  MoNuSegTrainingData/trainB/TCGA-21-5784-01Z-00-DX1.png\n",
            "./MoNuSegTrainingData/Annotations/TCGA-49-4488-01Z-00-DX1.xml\n",
            "path:  MoNuSegTrainingData/trainB/TCGA-49-4488-01Z-00-DX1.png\n",
            "./MoNuSegTrainingData/Annotations/TCGA-A7-A13F-01Z-00-DX1.xml\n",
            "path:  MoNuSegTrainingData/trainB/TCGA-A7-A13F-01Z-00-DX1.png\n",
            "./MoNuSegTrainingData/Annotations/TCGA-G9-6336-01Z-00-DX1.xml\n",
            "path:  MoNuSegTrainingData/trainB/TCGA-G9-6336-01Z-00-DX1.png\n",
            "./MoNuSegTrainingData/Annotations/TCGA-B0-5710-01Z-00-DX1.xml\n",
            "path:  MoNuSegTrainingData/trainB/TCGA-B0-5710-01Z-00-DX1.png\n",
            "./MoNuSegTrainingData/Annotations/TCGA-HE-7128-01Z-00-DX1.xml\n",
            "path:  MoNuSegTrainingData/trainB/TCGA-HE-7128-01Z-00-DX1.png\n",
            "./MoNuSegTrainingData/Annotations/TCGA-E2-A14V-01Z-00-DX1.xml\n",
            "path:  MoNuSegTrainingData/trainB/TCGA-E2-A14V-01Z-00-DX1.png\n",
            "./MoNuSegTrainingData/Annotations/TCGA-B0-5698-01Z-00-DX1.xml\n",
            "path:  MoNuSegTrainingData/trainB/TCGA-B0-5698-01Z-00-DX1.png\n",
            "./MoNuSegTrainingData/Annotations/TCGA-E2-A1B5-01Z-00-DX1.xml\n",
            "path:  MoNuSegTrainingData/trainB/TCGA-E2-A1B5-01Z-00-DX1.png\n",
            "./MoNuSegTrainingData/Annotations/TCGA-AY-A8YK-01A-01-TS1.xml\n",
            "path:  MoNuSegTrainingData/trainB/TCGA-AY-A8YK-01A-01-TS1.png\n",
            "./MoNuSegTrainingData/Annotations/TCGA-NH-A8F7-01A-01-TS1.xml\n",
            "path:  MoNuSegTrainingData/trainB/TCGA-NH-A8F7-01A-01-TS1.png\n",
            "./MoNuSegTrainingData/Annotations/TCGA-CH-5767-01Z-00-DX1.xml\n",
            "path:  MoNuSegTrainingData/trainB/TCGA-CH-5767-01Z-00-DX1.png\n",
            "./MoNuSegTrainingData/Annotations/TCGA-50-5931-01Z-00-DX1.xml\n",
            "path:  MoNuSegTrainingData/trainB/TCGA-50-5931-01Z-00-DX1.png\n",
            "./MoNuSegTrainingData/Annotations/TCGA-HE-7130-01Z-00-DX1.xml\n",
            "path:  MoNuSegTrainingData/trainB/TCGA-HE-7130-01Z-00-DX1.png\n",
            "./MoNuSegTrainingData/Annotations/TCGA-G9-6356-01Z-00-DX1.xml\n",
            "path:  MoNuSegTrainingData/trainB/TCGA-G9-6356-01Z-00-DX1.png\n",
            "./MoNuSegTrainingData/Annotations/TCGA-RD-A8N9-01A-01-TS1.xml\n",
            "path:  MoNuSegTrainingData/trainB/TCGA-RD-A8N9-01A-01-TS1.png\n",
            "./MoNuSegTrainingData/Annotations/TCGA-G2-A2EK-01A-02-TSB.xml\n",
            "path:  MoNuSegTrainingData/trainB/TCGA-G2-A2EK-01A-02-TSB.png\n",
            "./MoNuSegTrainingData/Annotations/TCGA-AR-A1AK-01Z-00-DX1.xml\n",
            "path:  MoNuSegTrainingData/trainB/TCGA-AR-A1AK-01Z-00-DX1.png\n",
            "./MoNuSegTrainingData/Annotations/TCGA-KB-A93J-01A-01-TS1.xml\n",
            "path:  MoNuSegTrainingData/trainB/TCGA-KB-A93J-01A-01-TS1.png\n",
            "./MoNuSegTrainingData/Annotations/TCGA-A7-A13E-01Z-00-DX1.xml\n",
            "path:  MoNuSegTrainingData/trainB/TCGA-A7-A13E-01Z-00-DX1.png\n",
            "./MoNuSegTrainingData/Annotations/TCGA-G9-6348-01Z-00-DX1.xml\n",
            "path:  MoNuSegTrainingData/trainB/TCGA-G9-6348-01Z-00-DX1.png\n",
            "./MoNuSegTrainingData/Annotations/TCGA-G9-6363-01Z-00-DX1.xml\n",
            "path:  MoNuSegTrainingData/trainB/TCGA-G9-6363-01Z-00-DX1.png\n",
            "./MoNuSegTestData/TCGA-CU-A0YN-01A-02-BSB.xml\n",
            "path:  MoNuSegTestData/valB/TCGA-CU-A0YN-01A-02-BSB.png\n",
            "./MoNuSegTestData/TCGA-A6-6782-01A-01-BS1.xml\n",
            "path:  MoNuSegTestData/valB/TCGA-A6-6782-01A-01-BS1.png\n",
            "./MoNuSegTestData/TCGA-44-2665-01B-06-BS6.xml\n",
            "path:  MoNuSegTestData/valB/TCGA-44-2665-01B-06-BS6.png\n",
            "./MoNuSegTestData/TCGA-HC-7209-01A-01-TS1.xml\n",
            "path:  MoNuSegTestData/valB/TCGA-HC-7209-01A-01-TS1.png\n",
            "./MoNuSegTestData/TCGA-EJ-A46H-01A-03-TSC.xml\n",
            "path:  MoNuSegTestData/valB/TCGA-EJ-A46H-01A-03-TSC.png\n",
            "./MoNuSegTestData/TCGA-69-7764-01A-01-TS1.xml\n",
            "path:  MoNuSegTestData/valB/TCGA-69-7764-01A-01-TS1.png\n",
            "./MoNuSegTestData/TCGA-IZ-8196-01A-01-BS1.xml\n",
            "path:  MoNuSegTestData/valB/TCGA-IZ-8196-01A-01-BS1.png\n",
            "./MoNuSegTestData/TCGA-HT-8564-01Z-00-DX1.xml\n",
            "path:  MoNuSegTestData/valB/TCGA-HT-8564-01Z-00-DX1.png\n",
            "./MoNuSegTestData/TCGA-GL-6846-01A-01-BS1.xml\n",
            "path:  MoNuSegTestData/valB/TCGA-GL-6846-01A-01-BS1.png\n",
            "./MoNuSegTestData/TCGA-AC-A2FO-01A-01-TS1.xml\n",
            "path:  MoNuSegTestData/valB/TCGA-AC-A2FO-01A-01-TS1.png\n",
            "./MoNuSegTestData/TCGA-AO-A0J2-01A-01-BSA.xml\n",
            "path:  MoNuSegTestData/valB/TCGA-AO-A0J2-01A-01-BSA.png\n",
            "./MoNuSegTestData/TCGA-FG-A4MU-01B-01-TS1.xml\n",
            "path:  MoNuSegTestData/valB/TCGA-FG-A4MU-01B-01-TS1.png\n",
            "./MoNuSegTestData/TCGA-2Z-A9J9-01A-01-TS1.xml\n",
            "path:  MoNuSegTestData/valB/TCGA-2Z-A9J9-01A-01-TS1.png\n",
            "./MoNuSegTestData/TCGA-ZF-A9R5-01A-01-TS1.xml\n",
            "path:  MoNuSegTestData/valB/TCGA-ZF-A9R5-01A-01-TS1.png\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikeisvb69afG"
      },
      "source": [
        "import glob\n",
        "from PIL import Image\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "def tif2png(data_path, imwrite_path):\n",
        "  #data_path = \"./MoNuSegTrainingData/Tissue Images/\"\n",
        "  tiff_path = glob.glob(os.path.join(data_path, \"*.tif\"))\n",
        "  #imwrite_path = \"./MoNuSegTrainingData/images_jpg/\"\n",
        "\n",
        "  try:\n",
        "    shutil.rmtree(imwrite_path)\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "  os.mkdir(imwrite_path)\n",
        "\n",
        "  for tif in tiff_path:\n",
        "    img = cv2.imread(tif)\n",
        "    img = cv2.resize(img, (256, 256))\n",
        "    imwrite_path2 = os.path.join(imwrite_path, tif.split(\"/\")[-1].replace(\".tif\", \".png\"))\n",
        "    cv2.imwrite(imwrite_path2, img)\n",
        "\n",
        "tif2png(data_path = \"./MoNuSegTrainingData/Tissue Images/\", imwrite_path = \"./MoNuSegTrainingData/trainA/\")\n",
        "tif2png(data_path = \"./MoNuSegTestData/\", imwrite_path = \"./MoNuSegTestData/valA/\")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFWfuOeY6K7N"
      },
      "source": [
        "from PIL import Image\n",
        "import glob\n",
        "\n",
        "\n",
        "def merge_images(rgb_path, mask_path, merged_path):\n",
        "\n",
        "  mask_name_list = {}\n",
        "  rgb_name_list = {}\n",
        "\n",
        "  #rgb_path = \"./MoNuSegTrainingData/images_jpg/*.jpg\"\n",
        "  #mask_path = \"./MoNuSegTrainingData/annot_jpg/*.png\"\n",
        "  #merged_path = \"./MoNuSegTrainingData/train/\"\n",
        "  try:\n",
        "    os.mkdir(merged_path)\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "  for i in glob.glob(rgb_path):\n",
        "    key_name = (i.split(\"/\")[-1]).split(\".\")[-2]\n",
        "    rgb_name_list[key_name] = Image.open(i)\n",
        "\n",
        "\n",
        "  for j in glob.glob(mask_path):\n",
        "    #print(\"Key: \", key_name)\n",
        "    key_name = (j.split(\"/\")[-1]).split(\".\")[-2]\n",
        "    mask_name_list[key_name] = Image.open(j)\n",
        "\n",
        "  for k in mask_name_list:\n",
        "    if k in rgb_name_list:\n",
        "      new_image = Image.new(\"RGB\", (512, 256), (250, 250, 250))\n",
        "      new_image.paste(rgb_name_list[k], (0,0))\n",
        "      new_image.paste(mask_name_list[k], (256, 0))\n",
        "      new_image.save(merged_path + str(k) + \".png\", \"PNG\")\n",
        "\n",
        "merge_images(rgb_path = \"./MoNuSegTrainingData/trainA/*.png\", mask_path = \"./MoNuSegTrainingData/trainB/*.png\", merged_path = \"./MoNuSegTrainingData/train/\")\n",
        "merge_images(rgb_path = \"./MoNuSegTestData/valA/*.png\", mask_path = \"./MoNuSegTestData/valB/*.png\", merged_path = \"./MoNuSegTestData/test/\")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gi1UHhIZdJ9b"
      },
      "source": [
        "try:\n",
        "  shutil.rmtree(\"pix2pixData\")\n",
        "except:\n",
        "  pass\n",
        "\n",
        "os.mkdir(\"pix2pixData\")\n",
        "os.mkdir(\"pix2pixData/train\")\n",
        "os.mkdir(\"pix2pixData/val\")\n",
        "\n",
        "\n",
        "try:\n",
        "  shutil.rmtree(\"cycleGanData\")\n",
        "except:\n",
        "  pass\n",
        "\n",
        "os.mkdir(\"cycleGanData\")\n",
        "os.mkdir(\"cycleGanData/train\")\n",
        "os.mkdir(\"cycleGanData/val\")"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSCTgaoOomL8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6446b8f5-1724-4e23-e15e-da85ae841e09"
      },
      "source": [
        "!rsync -r --progress ./MoNuSegTrainingData/train ./pix2pixData/train\n",
        "!rsync -r --progress ./MoNuSegTestData/test ./pix2pixData/val\n",
        "###########################################################################\n",
        "!rsync -r --progress ./MoNuSegTrainingData/trainA/ ./cycleGanData/train/trainA/\n",
        "!rsync -r --progress ./MoNuSegTestData/valA/ ./cycleGanData/val/valA/\n",
        "!rsync -r --progress ./MoNuSegTrainingData/trainB/ ./cycleGanData/train/trainB/\n",
        "!rsync -r --progress ./MoNuSegTestData/valB/ ./cycleGanData/val/valB/"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sending incremental file list\n",
            "train/\n",
            "train/TCGA-18-5592-01Z-00-DX1.png\n",
            "\r         32,768  16%    0.00kB/s    0:00:00  \r        200,268 100%  159.74MB/s    0:00:00 (xfr#1, to-chk=29/31)\n",
            "train/TCGA-21-5784-01Z-00-DX1.png\n",
            "\r         32,768  16%   31.25MB/s    0:00:00  \r        198,458 100%  189.26MB/s    0:00:00 (xfr#2, to-chk=28/31)\n",
            "train/TCGA-21-5786-01Z-00-DX1.png\n",
            "\r         32,768  15%   31.25MB/s    0:00:00  \r        213,898 100%  101.99MB/s    0:00:00 (xfr#3, to-chk=27/31)\n",
            "train/TCGA-38-6178-01Z-00-DX1.png\n",
            "\r         32,768  15%   15.62MB/s    0:00:00  \r        205,330 100%   65.27MB/s    0:00:00 (xfr#4, to-chk=26/31)\n",
            "train/TCGA-49-4488-01Z-00-DX1.png\n",
            "\r         32,768  15%   10.42MB/s    0:00:00  \r        209,155 100%   49.87MB/s    0:00:00 (xfr#5, to-chk=25/31)\n",
            "train/TCGA-50-5931-01Z-00-DX1.png\n",
            "\r         32,768  14%    7.81MB/s    0:00:00  \r        224,308 100%   53.48MB/s    0:00:00 (xfr#6, to-chk=24/31)\n",
            "train/TCGA-A7-A13E-01Z-00-DX1.png\n",
            "\r         32,768  16%    6.25MB/s    0:00:00  \r        197,585 100%   37.69MB/s    0:00:00 (xfr#7, to-chk=23/31)\n",
            "train/TCGA-A7-A13F-01Z-00-DX1.png\n",
            "\r         32,768  16%    6.25MB/s    0:00:00  \r        198,355 100%   31.53MB/s    0:00:00 (xfr#8, to-chk=22/31)\n",
            "train/TCGA-AR-A1AK-01Z-00-DX1.png\n",
            "\r         32,768  16%    5.21MB/s    0:00:00  \r        204,295 100%   27.83MB/s    0:00:00 (xfr#9, to-chk=21/31)\n",
            "train/TCGA-AR-A1AS-01Z-00-DX1.png\n",
            "\r         32,768  14%    4.46MB/s    0:00:00  \r        221,113 100%   26.36MB/s    0:00:00 (xfr#10, to-chk=20/31)\n",
            "train/TCGA-AY-A8YK-01A-01-TS1.png\n",
            "\r         32,768  16%    3.91MB/s    0:00:00  \r        199,674 100%   23.80MB/s    0:00:00 (xfr#11, to-chk=19/31)\n",
            "train/TCGA-B0-5698-01Z-00-DX1.png\n",
            "\r         32,768  16%    3.91MB/s    0:00:00  \r        203,010 100%   21.51MB/s    0:00:00 (xfr#12, to-chk=18/31)\n",
            "train/TCGA-B0-5710-01Z-00-DX1.png\n",
            "\r         32,768  16%    3.47MB/s    0:00:00  \r        195,166 100%   18.61MB/s    0:00:00 (xfr#13, to-chk=17/31)\n",
            "train/TCGA-B0-5711-01Z-00-DX1.png\n",
            "\r         32,768  16%    3.12MB/s    0:00:00  \r        201,468 100%   17.47MB/s    0:00:00 (xfr#14, to-chk=16/31)\n",
            "train/TCGA-CH-5767-01Z-00-DX1.png\n",
            "\r         32,768  16%    2.84MB/s    0:00:00  \r        201,192 100%   17.44MB/s    0:00:00 (xfr#15, to-chk=15/31)\n",
            "train/TCGA-DK-A2I6-01A-01-TS1.png\n",
            "\r         32,768  16%    2.60MB/s    0:00:00  \r        195,582 100%   15.54MB/s    0:00:00 (xfr#16, to-chk=14/31)\n",
            "train/TCGA-E2-A14V-01Z-00-DX1.png\n",
            "\r         32,768  15%    2.60MB/s    0:00:00  \r        208,052 100%   15.26MB/s    0:00:00 (xfr#17, to-chk=13/31)\n",
            "train/TCGA-E2-A1B5-01Z-00-DX1.png\n",
            "\r         32,768  16%    2.40MB/s    0:00:00  \r        196,871 100%   13.41MB/s    0:00:00 (xfr#18, to-chk=12/31)\n",
            "train/TCGA-G2-A2EK-01A-02-TSB.png\n",
            "\r         32,768  17%    2.23MB/s    0:00:00  \r        189,851 100%   12.07MB/s    0:00:00 (xfr#19, to-chk=11/31)\n",
            "train/TCGA-G9-6336-01Z-00-DX1.png\n",
            "\r         32,768  15%    2.08MB/s    0:00:00  \r        214,273 100%   13.62MB/s    0:00:00 (xfr#20, to-chk=10/31)\n",
            "train/TCGA-G9-6348-01Z-00-DX1.png\n",
            "\r         32,768  15%    1.95MB/s    0:00:00  \r        208,888 100%   12.45MB/s    0:00:00 (xfr#21, to-chk=9/31)\n",
            "train/TCGA-G9-6356-01Z-00-DX1.png\n",
            "\r         32,768  15%    1.95MB/s    0:00:00  \r        210,337 100%   11.80MB/s    0:00:00 (xfr#22, to-chk=8/31)\n",
            "train/TCGA-G9-6362-01Z-00-DX1.png\n",
            "\r         32,768  15%    1.84MB/s    0:00:00  \r        216,067 100%   11.45MB/s    0:00:00 (xfr#23, to-chk=7/31)\n",
            "train/TCGA-G9-6363-01Z-00-DX1.png\n",
            "\r         32,768  16%    1.74MB/s    0:00:00  \r        203,686 100%   10.22MB/s    0:00:00 (xfr#24, to-chk=6/31)\n",
            "train/TCGA-HE-7128-01Z-00-DX1.png\n",
            "\r         32,768  15%    1.64MB/s    0:00:00  \r        217,707 100%   10.38MB/s    0:00:00 (xfr#25, to-chk=5/31)\n",
            "train/TCGA-HE-7129-01Z-00-DX1.png\n",
            "\r         32,768  13%    1.56MB/s    0:00:00  \r        237,602 100%   10.79MB/s    0:00:00 (xfr#26, to-chk=4/31)\n",
            "train/TCGA-HE-7130-01Z-00-DX1.png\n",
            "\r         32,768  13%    1.49MB/s    0:00:00  \r        240,795 100%   10.44MB/s    0:00:00 (xfr#27, to-chk=3/31)\n",
            "train/TCGA-KB-A93J-01A-01-TS1.png\n",
            "\r         32,768  13%    1.42MB/s    0:00:00  \r        247,324 100%   10.26MB/s    0:00:00 (xfr#28, to-chk=2/31)\n",
            "train/TCGA-NH-A8F7-01A-01-TS1.png\n",
            "\r         32,768  16%    1.36MB/s    0:00:00  \r        199,885 100%    7.94MB/s    0:00:00 (xfr#29, to-chk=1/31)\n",
            "train/TCGA-RD-A8N9-01A-01-TS1.png\n",
            "        240,003 100%    9.54MB/s    0:00:00 (xfr#30, to-chk=0/31)\n",
            "sending incremental file list\n",
            "test/\n",
            "test/TCGA-2Z-A9J9-01A-01-TS1.png\n",
            "        212,832 100%  171.72MB/s    0:00:00 (xfr#1, to-chk=13/15)\n",
            "test/TCGA-44-2665-01B-06-BS6.png\n",
            "        234,034 100%  223.19MB/s    0:00:00 (xfr#2, to-chk=12/15)\n",
            "test/TCGA-69-7764-01A-01-TS1.png\n",
            "        215,016 100%  102.53MB/s    0:00:00 (xfr#3, to-chk=11/15)\n",
            "test/TCGA-A6-6782-01A-01-BS1.png\n",
            "        203,380 100%   64.65MB/s    0:00:00 (xfr#4, to-chk=10/15)\n",
            "test/TCGA-AC-A2FO-01A-01-TS1.png\n",
            "        217,011 100%   20.70MB/s    0:00:00 (xfr#5, to-chk=9/15)\n",
            "test/TCGA-AO-A0J2-01A-01-BSA.png\n",
            "        206,686 100%   17.92MB/s    0:00:00 (xfr#6, to-chk=8/15)\n",
            "test/TCGA-CU-A0YN-01A-02-BSB.png\n",
            "        220,922 100%   15.05MB/s    0:00:00 (xfr#7, to-chk=7/15)\n",
            "test/TCGA-EJ-A46H-01A-03-TSC.png\n",
            "        203,346 100%   13.85MB/s    0:00:00 (xfr#8, to-chk=6/15)\n",
            "test/TCGA-FG-A4MU-01B-01-TS1.png\n",
            "        215,265 100%   13.69MB/s    0:00:00 (xfr#9, to-chk=5/15)\n",
            "test/TCGA-GL-6846-01A-01-BS1.png\n",
            "        206,347 100%   12.30MB/s    0:00:00 (xfr#10, to-chk=4/15)\n",
            "test/TCGA-HC-7209-01A-01-TS1.png\n",
            "        198,471 100%   11.13MB/s    0:00:00 (xfr#11, to-chk=3/15)\n",
            "test/TCGA-HT-8564-01Z-00-DX1.png\n",
            "        206,867 100%   10.96MB/s    0:00:00 (xfr#12, to-chk=2/15)\n",
            "test/TCGA-IZ-8196-01A-01-BS1.png\n",
            "        219,049 100%   10.99MB/s    0:00:00 (xfr#13, to-chk=1/15)\n",
            "test/TCGA-ZF-A9R5-01A-01-TS1.png\n",
            "        209,718 100%   10.53MB/s    0:00:00 (xfr#14, to-chk=0/15)\n",
            "sending incremental file list\n",
            "created directory ./cycleGanData/train/trainA\n",
            "./\n",
            "TCGA-18-5592-01Z-00-DX1.png\n",
            "        147,287 100%  109.21MB/s    0:00:00 (xfr#1, to-chk=29/31)\n",
            "TCGA-21-5784-01Z-00-DX1.png\n",
            "        169,308 100%  161.46MB/s    0:00:00 (xfr#2, to-chk=28/31)\n",
            "TCGA-21-5786-01Z-00-DX1.png\n",
            "        169,699 100%  161.84MB/s    0:00:00 (xfr#3, to-chk=27/31)\n",
            "TCGA-38-6178-01Z-00-DX1.png\n",
            "        169,664 100%   80.90MB/s    0:00:00 (xfr#4, to-chk=26/31)\n",
            "TCGA-49-4488-01Z-00-DX1.png\n",
            "        159,171 100%   50.60MB/s    0:00:00 (xfr#5, to-chk=25/31)\n",
            "TCGA-50-5931-01Z-00-DX1.png\n",
            "        174,979 100%   55.62MB/s    0:00:00 (xfr#6, to-chk=24/31)\n",
            "TCGA-A7-A13E-01Z-00-DX1.png\n",
            "        167,024 100%   39.82MB/s    0:00:00 (xfr#7, to-chk=23/31)\n",
            "TCGA-A7-A13F-01Z-00-DX1.png\n",
            "        165,936 100%   31.65MB/s    0:00:00 (xfr#8, to-chk=22/31)\n",
            "TCGA-AR-A1AK-01Z-00-DX1.png\n",
            "        166,054 100%   31.67MB/s    0:00:00 (xfr#9, to-chk=21/31)\n",
            "TCGA-AR-A1AS-01Z-00-DX1.png\n",
            "        175,700 100%   27.93MB/s    0:00:00 (xfr#10, to-chk=20/31)\n",
            "TCGA-AY-A8YK-01A-01-TS1.png\n",
            "        155,824 100%   21.23MB/s    0:00:00 (xfr#11, to-chk=19/31)\n",
            "TCGA-B0-5698-01Z-00-DX1.png\n",
            "        174,790 100%   23.81MB/s    0:00:00 (xfr#12, to-chk=18/31)\n",
            "TCGA-B0-5710-01Z-00-DX1.png\n",
            "        166,955 100%   19.90MB/s    0:00:00 (xfr#13, to-chk=17/31)\n",
            "TCGA-B0-5711-01Z-00-DX1.png\n",
            "        174,015 100%   18.44MB/s    0:00:00 (xfr#14, to-chk=16/31)\n",
            "TCGA-CH-5767-01Z-00-DX1.png\n",
            "        171,964 100%   18.22MB/s    0:00:00 (xfr#15, to-chk=15/31)\n",
            "TCGA-DK-A2I6-01A-01-TS1.png\n",
            "        161,099 100%   15.36MB/s    0:00:00 (xfr#16, to-chk=14/31)\n",
            "TCGA-E2-A14V-01Z-00-DX1.png\n",
            "        176,017 100%   15.26MB/s    0:00:00 (xfr#17, to-chk=13/31)\n",
            "TCGA-E2-A1B5-01Z-00-DX1.png\n",
            "        172,204 100%   14.93MB/s    0:00:00 (xfr#18, to-chk=12/31)\n",
            "TCGA-G2-A2EK-01A-02-TSB.png\n",
            "        163,438 100%   12.99MB/s    0:00:00 (xfr#19, to-chk=11/31)\n",
            "TCGA-G9-6336-01Z-00-DX1.png\n",
            "        171,461 100%   12.58MB/s    0:00:00 (xfr#20, to-chk=10/31)\n",
            "TCGA-G9-6348-01Z-00-DX1.png\n",
            "        172,444 100%   12.65MB/s    0:00:00 (xfr#21, to-chk=9/31)\n",
            "TCGA-G9-6356-01Z-00-DX1.png\n",
            "        172,529 100%   11.75MB/s    0:00:00 (xfr#22, to-chk=8/31)\n",
            "TCGA-G9-6362-01Z-00-DX1.png\n",
            "        172,685 100%   11.76MB/s    0:00:00 (xfr#23, to-chk=7/31)\n",
            "TCGA-G9-6363-01Z-00-DX1.png\n",
            "        167,158 100%   10.63MB/s    0:00:00 (xfr#24, to-chk=6/31)\n",
            "TCGA-HE-7128-01Z-00-DX1.png\n",
            "        172,367 100%   10.27MB/s    0:00:00 (xfr#25, to-chk=5/31)\n",
            "TCGA-HE-7129-01Z-00-DX1.png\n",
            "        181,959 100%   10.85MB/s    0:00:00 (xfr#26, to-chk=4/31)\n",
            "TCGA-HE-7130-01Z-00-DX1.png\n",
            "        172,042 100%    9.65MB/s    0:00:00 (xfr#27, to-chk=3/31)\n",
            "TCGA-KB-A93J-01A-01-TS1.png\n",
            "        180,251 100%    9.55MB/s    0:00:00 (xfr#28, to-chk=2/31)\n",
            "TCGA-NH-A8F7-01A-01-TS1.png\n",
            "        158,821 100%    8.41MB/s    0:00:00 (xfr#29, to-chk=1/31)\n",
            "TCGA-RD-A8N9-01A-01-TS1.png\n",
            "        179,245 100%    9.00MB/s    0:00:00 (xfr#30, to-chk=0/31)\n",
            "sending incremental file list\n",
            "created directory ./cycleGanData/val/valA\n",
            "./\n",
            "TCGA-2Z-A9J9-01A-01-TS1.png\n",
            "        171,162 100%  131.98MB/s    0:00:00 (xfr#1, to-chk=13/15)\n",
            "TCGA-44-2665-01B-06-BS6.png\n",
            "        179,105 100%  170.81MB/s    0:00:00 (xfr#2, to-chk=12/15)\n",
            "TCGA-69-7764-01A-01-TS1.png\n",
            "        175,114 100%   83.50MB/s    0:00:00 (xfr#3, to-chk=11/15)\n",
            "TCGA-A6-6782-01A-01-BS1.png\n",
            "        167,969 100%   80.09MB/s    0:00:00 (xfr#4, to-chk=10/15)\n",
            "TCGA-AC-A2FO-01A-01-TS1.png\n",
            "        171,578 100%   54.54MB/s    0:00:00 (xfr#5, to-chk=9/15)\n",
            "TCGA-AO-A0J2-01A-01-BSA.png\n",
            "        167,372 100%   39.90MB/s    0:00:00 (xfr#6, to-chk=8/15)\n",
            "TCGA-CU-A0YN-01A-02-BSB.png\n",
            "        174,102 100%   41.51MB/s    0:00:00 (xfr#7, to-chk=7/15)\n",
            "TCGA-EJ-A46H-01A-03-TSC.png\n",
            "        169,002 100%   32.23MB/s    0:00:00 (xfr#8, to-chk=6/15)\n",
            "TCGA-FG-A4MU-01B-01-TS1.png\n",
            "        173,861 100%   33.16MB/s    0:00:00 (xfr#9, to-chk=5/15)\n",
            "TCGA-GL-6846-01A-01-BS1.png\n",
            "        171,374 100%   27.24MB/s    0:00:00 (xfr#10, to-chk=4/15)\n",
            "TCGA-HC-7209-01A-01-TS1.png\n",
            "        168,335 100%   22.93MB/s    0:00:00 (xfr#11, to-chk=3/15)\n",
            "TCGA-HT-8564-01Z-00-DX1.png\n",
            "        181,552 100%   24.73MB/s    0:00:00 (xfr#12, to-chk=2/15)\n",
            "TCGA-IZ-8196-01A-01-BS1.png\n",
            "        179,440 100%   21.39MB/s    0:00:00 (xfr#13, to-chk=1/15)\n",
            "TCGA-ZF-A9R5-01A-01-TS1.png\n",
            "        170,523 100%   18.07MB/s    0:00:00 (xfr#14, to-chk=0/15)\n",
            "sending incremental file list\n",
            "created directory ./cycleGanData/train/trainB\n",
            "./\n",
            "TCGA-18-5592-01Z-00-DX1.png\n",
            "         62,003 100%   27.88MB/s    0:00:00 (xfr#1, to-chk=29/31)\n",
            "TCGA-21-5784-01Z-00-DX1.png\n",
            "         34,371 100%   32.78MB/s    0:00:00 (xfr#2, to-chk=28/31)\n",
            "TCGA-21-5786-01Z-00-DX1.png\n",
            "         54,024 100%   25.76MB/s    0:00:00 (xfr#3, to-chk=27/31)\n",
            "TCGA-38-6178-01Z-00-DX1.png\n",
            "         42,568 100%   13.53MB/s    0:00:00 (xfr#4, to-chk=26/31)\n",
            "TCGA-49-4488-01Z-00-DX1.png\n",
            "         61,003 100%   19.39MB/s    0:00:00 (xfr#5, to-chk=25/31)\n",
            "TCGA-50-5931-01Z-00-DX1.png\n",
            "         59,185 100%   18.81MB/s    0:00:00 (xfr#6, to-chk=24/31)\n",
            "TCGA-A7-A13E-01Z-00-DX1.png\n",
            "         34,958 100%   11.11MB/s    0:00:00 (xfr#7, to-chk=23/31)\n",
            "TCGA-A7-A13F-01Z-00-DX1.png\n",
            "         37,829 100%    9.02MB/s    0:00:00 (xfr#8, to-chk=22/31)\n",
            "TCGA-AR-A1AK-01Z-00-DX1.png\n",
            "         44,407 100%   10.59MB/s    0:00:00 (xfr#9, to-chk=21/31)\n",
            "TCGA-AR-A1AS-01Z-00-DX1.png\n",
            "         54,769 100%   13.06MB/s    0:00:00 (xfr#10, to-chk=20/31)\n",
            "TCGA-AY-A8YK-01A-01-TS1.png\n",
            "         52,339 100%   12.48MB/s    0:00:00 (xfr#11, to-chk=19/31)\n",
            "TCGA-B0-5698-01Z-00-DX1.png\n",
            "         32,734 100%    6.24MB/s    0:00:00 (xfr#12, to-chk=18/31)\n",
            "TCGA-B0-5710-01Z-00-DX1.png\n",
            "         31,377 100%    5.98MB/s    0:00:00 (xfr#13, to-chk=17/31)\n",
            "TCGA-B0-5711-01Z-00-DX1.png\n",
            "         30,377 100%    5.79MB/s    0:00:00 (xfr#14, to-chk=16/31)\n",
            "TCGA-CH-5767-01Z-00-DX1.png\n",
            "         32,604 100%    6.22MB/s    0:00:00 (xfr#15, to-chk=15/31)\n",
            "TCGA-DK-A2I6-01A-01-TS1.png\n",
            "         44,362 100%    8.46MB/s    0:00:00 (xfr#16, to-chk=14/31)\n",
            "TCGA-E2-A14V-01Z-00-DX1.png\n",
            "         39,734 100%    7.58MB/s    0:00:00 (xfr#17, to-chk=13/31)\n",
            "TCGA-E2-A1B5-01Z-00-DX1.png\n",
            "         30,263 100%    4.81MB/s    0:00:00 (xfr#18, to-chk=12/31)\n",
            "TCGA-G2-A2EK-01A-02-TSB.png\n",
            "         36,171 100%    5.75MB/s    0:00:00 (xfr#19, to-chk=11/31)\n",
            "TCGA-G9-6336-01Z-00-DX1.png\n",
            "         50,445 100%    8.02MB/s    0:00:00 (xfr#20, to-chk=10/31)\n",
            "TCGA-G9-6348-01Z-00-DX1.png\n",
            "         41,980 100%    6.67MB/s    0:00:00 (xfr#21, to-chk=9/31)\n",
            "TCGA-G9-6356-01Z-00-DX1.png\n",
            "         44,357 100%    7.05MB/s    0:00:00 (xfr#22, to-chk=8/31)\n",
            "TCGA-G9-6362-01Z-00-DX1.png\n",
            "         51,599 100%    7.03MB/s    0:00:00 (xfr#23, to-chk=7/31)\n",
            "TCGA-G9-6363-01Z-00-DX1.png\n",
            "         41,392 100%    5.64MB/s    0:00:00 (xfr#24, to-chk=6/31)\n",
            "TCGA-HE-7128-01Z-00-DX1.png\n",
            "         51,012 100%    6.95MB/s    0:00:00 (xfr#25, to-chk=5/31)\n",
            "TCGA-HE-7129-01Z-00-DX1.png\n",
            "         65,397 100%    8.91MB/s    0:00:00 (xfr#26, to-chk=4/31)\n",
            "TCGA-HE-7130-01Z-00-DX1.png\n",
            "         84,070 100%   10.02MB/s    0:00:00 (xfr#27, to-chk=3/31)\n",
            "TCGA-KB-A93J-01A-01-TS1.png\n",
            "         90,510 100%   10.79MB/s    0:00:00 (xfr#28, to-chk=2/31)\n",
            "TCGA-NH-A8F7-01A-01-TS1.png\n",
            "         50,365 100%    6.00MB/s    0:00:00 (xfr#29, to-chk=1/31)\n",
            "TCGA-RD-A8N9-01A-01-TS1.png\n",
            "         82,406 100%    9.82MB/s    0:00:00 (xfr#30, to-chk=0/31)\n",
            "sending incremental file list\n",
            "created directory ./cycleGanData/val/valB\n",
            "./\n",
            "TCGA-2Z-A9J9-01A-01-TS1.png\n",
            "         53,276 100%   19.56MB/s    0:00:00 (xfr#1, to-chk=13/15)\n",
            "TCGA-44-2665-01B-06-BS6.png\n",
            "         67,902 100%   64.76MB/s    0:00:00 (xfr#2, to-chk=12/15)\n",
            "TCGA-69-7764-01A-01-TS1.png\n",
            "         49,123 100%   46.85MB/s    0:00:00 (xfr#3, to-chk=11/15)\n",
            "TCGA-A6-6782-01A-01-BS1.png\n",
            "         39,487 100%   37.66MB/s    0:00:00 (xfr#4, to-chk=10/15)\n",
            "TCGA-AC-A2FO-01A-01-TS1.png\n",
            "         58,446 100%   55.74MB/s    0:00:00 (xfr#5, to-chk=9/15)\n",
            "TCGA-AO-A0J2-01A-01-BSA.png\n",
            "         47,373 100%   45.18MB/s    0:00:00 (xfr#6, to-chk=8/15)\n",
            "TCGA-CU-A0YN-01A-02-BSB.png\n",
            "         60,953 100%   29.06MB/s    0:00:00 (xfr#7, to-chk=7/15)\n",
            "TCGA-EJ-A46H-01A-03-TSC.png\n",
            "         42,830 100%   20.42MB/s    0:00:00 (xfr#8, to-chk=6/15)\n",
            "TCGA-FG-A4MU-01B-01-TS1.png\n",
            "         50,180 100%   23.93MB/s    0:00:00 (xfr#9, to-chk=5/15)\n",
            "TCGA-GL-6846-01A-01-BS1.png\n",
            "         42,605 100%   20.32MB/s    0:00:00 (xfr#10, to-chk=4/15)\n",
            "TCGA-HC-7209-01A-01-TS1.png\n",
            "         35,928 100%   17.13MB/s    0:00:00 (xfr#11, to-chk=3/15)\n",
            "TCGA-HT-8564-01Z-00-DX1.png\n",
            "         26,202 100%    8.33MB/s    0:00:00 (xfr#12, to-chk=2/15)\n",
            "TCGA-IZ-8196-01A-01-BS1.png\n",
            "         55,364 100%   17.60MB/s    0:00:00 (xfr#13, to-chk=1/15)\n",
            "TCGA-ZF-A9R5-01A-01-TS1.png\n",
            "         49,830 100%   15.84MB/s    0:00:00 (xfr#14, to-chk=0/15)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBE-Qzfh2J2o",
        "outputId": "2f330bc9-0e9f-41c1-9f39-056672571415"
      },
      "source": [
        "!git clone https://github.com/mahmoodlab/NucleiSegmentation.git"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'NucleiSegmentation'...\n",
            "remote: Enumerating objects: 148, done.\u001b[K\n",
            "remote: Total 148 (delta 0), reused 0 (delta 0), pack-reused 148\u001b[K\n",
            "Receiving objects: 100% (148/148), 843.70 KiB | 2.14 MiB/s, done.\n",
            "Resolving deltas: 100% (44/44), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTHUo1ZJ4l01",
        "outputId": "81eb8d1f-6df7-4ee4-f046-fa06a797e311"
      },
      "source": [
        "%cd NucleiSegmentation"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/NucleiSegmentation\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itm6Up66lMZu"
      },
      "source": [
        "try:\n",
        "  shutil.rmtree(\"./checkpoints\")\n",
        "except:\n",
        "  pass"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-wXTMt45dq8",
        "outputId": "d6a3801b-92bc-486d-bc2c-670714872221"
      },
      "source": [
        "!pip install -r ./requirements.txt\n",
        "!pip install scipy==1.1.0"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from -r ./requirements.txt (line 1)) (1.7.0+cu101)\n",
            "Requirement already satisfied: torchvision>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from -r ./requirements.txt (line 2)) (0.8.1+cu101)\n",
            "Collecting dominate>=2.3.1\n",
            "  Downloading https://files.pythonhosted.org/packages/ef/a8/4354f8122c39e35516a2708746d89db5e339c867abbd8e0179bccee4b7f9/dominate-2.6.0-py2.py3-none-any.whl\n",
            "Collecting visdom>=0.1.8.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c9/75/e078f5a2e1df7e0d3044749089fc2823e62d029cc027ed8ae5d71fafcbdc/visdom-0.1.8.9.tar.gz (676kB)\n",
            "\u001b[K     |████████████████████████████████| 686kB 13.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.0->-r ./requirements.txt (line 1)) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.0->-r ./requirements.txt (line 1)) (3.7.4.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.0->-r ./requirements.txt (line 1)) (0.16.0)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.0->-r ./requirements.txt (line 1)) (0.8)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.2.1->-r ./requirements.txt (line 2)) (7.0.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from visdom>=0.1.8.3->-r ./requirements.txt (line 4)) (1.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from visdom>=0.1.8.3->-r ./requirements.txt (line 4)) (2.23.0)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.6/dist-packages (from visdom>=0.1.8.3->-r ./requirements.txt (line 4)) (5.1.1)\n",
            "Requirement already satisfied: pyzmq in /usr/local/lib/python3.6/dist-packages (from visdom>=0.1.8.3->-r ./requirements.txt (line 4)) (22.0.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from visdom>=0.1.8.3->-r ./requirements.txt (line 4)) (1.15.0)\n",
            "Collecting jsonpatch\n",
            "  Downloading https://files.pythonhosted.org/packages/40/d5/6640ac6d1bdd20f44bb6b3c6e6f2f1c525bf0b7595f99c4f38917f995d6b/jsonpatch-1.28-py2.py3-none-any.whl\n",
            "Collecting torchfile\n",
            "  Downloading https://files.pythonhosted.org/packages/91/af/5b305f86f2d218091af657ddb53f984ecbd9518ca9fe8ef4103a007252c9/torchfile-0.1.0.tar.gz\n",
            "Collecting websocket-client\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/5f/f61b420143ed1c8dc69f9eaec5ff1ac36109d52c80de49d66e0c36c3dfdf/websocket_client-0.57.0-py2.py3-none-any.whl (200kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 33.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->visdom>=0.1.8.3->-r ./requirements.txt (line 4)) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->visdom>=0.1.8.3->-r ./requirements.txt (line 4)) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->visdom>=0.1.8.3->-r ./requirements.txt (line 4)) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->visdom>=0.1.8.3->-r ./requirements.txt (line 4)) (2020.12.5)\n",
            "Collecting jsonpointer>=1.9\n",
            "  Downloading https://files.pythonhosted.org/packages/18/b0/a80d29577c08eea401659254dfaed87f1af45272899e1812d7e01b679bc5/jsonpointer-2.0-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: visdom, torchfile\n",
            "  Building wheel for visdom (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for visdom: filename=visdom-0.1.8.9-cp36-none-any.whl size=655252 sha256=04ac3abaf72c6c44590bc64b978fbf97f926da648fa30e326b1407f2e5c13ab6\n",
            "  Stored in directory: /root/.cache/pip/wheels/70/19/a7/6d589ed967f4dfefd33bc166d081257bd4ed0cb618dccfd62a\n",
            "  Building wheel for torchfile (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchfile: filename=torchfile-0.1.0-cp36-none-any.whl size=5713 sha256=0540432219f6a7d3f54e874d01469fd37823047a226ca670c59f02bc2c1badad\n",
            "  Stored in directory: /root/.cache/pip/wheels/b1/c3/d6/9a1cc8f3a99a0fc1124cae20153f36af59a6e683daca0a0814\n",
            "Successfully built visdom torchfile\n",
            "Installing collected packages: dominate, jsonpointer, jsonpatch, torchfile, websocket-client, visdom\n",
            "Successfully installed dominate-2.6.0 jsonpatch-1.28 jsonpointer-2.0 torchfile-0.1.0 visdom-0.1.8.9 websocket-client-0.57.0\n",
            "Collecting scipy==1.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/0b/f163da98d3a01b3e0ef1cab8dd2123c34aee2bafbb1c5bffa354cc8a1730/scipy-1.1.0-cp36-cp36m-manylinux1_x86_64.whl (31.2MB)\n",
            "\u001b[K     |████████████████████████████████| 31.2MB 111kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scipy==1.1.0) (1.19.5)\n",
            "\u001b[31mERROR: plotnine 0.6.0 has requirement scipy>=1.2.0, but you'll have scipy 1.1.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: scipy\n",
            "  Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "Successfully installed scipy-1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vN8Cpe1D4ke4"
      },
      "source": [
        "!find . -name \"*.pyc\" -exec rm -f {} \\;"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "se5IXfgpeg3u",
        "outputId": "02a32413-b579-4b36-ca05-60ebc8b7de55"
      },
      "source": [
        "!python train.py --dataroot \"../pix2pixData/\" --name CASE1  \\\n",
        "  --gpu_ids 0 --display_id 0 \\\n",
        "  --niter 100 --niter_decay 100 \\\n",
        "  --pool_size 64 --loadSize 256 --fineSize 256\\\n",
        "  --save_epoch_freq 100 \\"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------- Options ---------------\n",
            "                batchSize: 1                             \n",
            "                    beta1: 0.5                           \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "           continue_train: False                         \n",
            "                 dataroot: ../pix2pixData/               \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "             display_freq: 400                           \n",
            "               display_id: 0                             \t[default: 1]\n",
            "            display_ncols: 4                             \n",
            "             display_port: 8097                          \n",
            "           display_server: http://localhost              \n",
            "          display_winsize: 256                           \n",
            "              epoch_count: 1                             \n",
            "                 fineSize: 256                           \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: True                          \t[default: None]\n",
            "                lambda_L1: 100.0                         \n",
            "                 loadSize: 256                           \t[default: 286]\n",
            "                       lr: 0.0002                        \n",
            "           lr_decay_iters: 50                            \n",
            "                lr_policy: lambda                        \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \n",
            "                 nThreads: 4                             \n",
            "               n_layers_D: 3                             \n",
            "                     name: CASE1                         \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                      ngf: 64                            \n",
            "                    niter: 100                           \n",
            "              niter_decay: 100                           \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                  no_html: False                         \n",
            "                 no_lsgan: True                          \n",
            "                     norm: batch                         \n",
            "                output_nc: 3                             \n",
            "                    phase: train                         \n",
            "                pool_size: 64                            \t[default: 0]\n",
            "               print_freq: 100                           \n",
            "           resize_or_crop: resize_and_crop               \n",
            "          save_epoch_freq: 100                           \t[default: 5]\n",
            "         save_latest_freq: 5000                          \n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "         update_html_freq: 1000                          \n",
            "                  verbose: False                         \n",
            "          which_direction: AtoB                          \n",
            "              which_epoch: latest                        \n",
            "         which_model_netD: basic                         \n",
            "         which_model_netG: unet_256                      \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "#training images = 30\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "model [Pix2PixModel] was created\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 54.414 M\n",
            "[Network D] Total number of parameters : 2.767 M\n",
            "-----------------------------------------------\n",
            "create web directory ./checkpoints/CASE1/web...\n",
            "End of epoch 1 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 2 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 3 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 4, iters: 10, time: 0.099, data: 0.167) G_GAN: 3.473 G_L1: 67.432 D_real: 0.001 D_fake: 0.122 \n",
            "End of epoch 4 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 5 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 6 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 7, iters: 20, time: 0.098, data: 0.001) G_GAN: 4.282 G_L1: 52.812 D_real: 0.001 D_fake: 0.031 \n",
            "End of epoch 7 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 8 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 9 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 10, iters: 30, time: 0.094, data: 0.001) G_GAN: 4.861 G_L1: 47.952 D_real: 0.000 D_fake: 0.166 \n",
            "End of epoch 10 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 11 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 12 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 13 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 14, iters: 10, time: 0.181, data: 0.170) G_GAN: 3.558 G_L1: 23.435 D_real: 0.025 D_fake: 0.044 \n",
            "End of epoch 14 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 15 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 16 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 17, iters: 20, time: 0.098, data: 0.001) G_GAN: 4.200 G_L1: 54.831 D_real: 0.019 D_fake: 0.032 \n",
            "End of epoch 17 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 18 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 19 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 20, iters: 30, time: 0.097, data: 0.001) G_GAN: 4.470 G_L1: 39.887 D_real: 0.240 D_fake: 0.025 \n",
            "End of epoch 20 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 21 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 22 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 23 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 24, iters: 10, time: 0.100, data: 0.170) G_GAN: 2.431 G_L1: 23.646 D_real: 0.335 D_fake: 0.037 \n",
            "End of epoch 24 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 25 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 26 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 27, iters: 20, time: 0.208, data: 0.001) G_GAN: 1.262 G_L1: 18.319 D_real: 0.012 D_fake: 0.021 \n",
            "End of epoch 27 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 28 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 29 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 30, iters: 30, time: 0.096, data: 0.001) G_GAN: 2.835 G_L1: 26.911 D_real: 0.059 D_fake: 0.028 \n",
            "End of epoch 30 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 31 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 32 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 33 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 34, iters: 10, time: 0.103, data: 0.142) G_GAN: 1.835 G_L1: 53.446 D_real: 0.007 D_fake: 0.024 \n",
            "End of epoch 34 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 35 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 36 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 37, iters: 20, time: 0.100, data: 0.002) G_GAN: 2.918 G_L1: 53.160 D_real: 0.004 D_fake: 0.087 \n",
            "End of epoch 37 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 38 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 39 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 40, iters: 30, time: 0.253, data: 0.001) G_GAN: 1.327 G_L1: 18.057 D_real: 0.251 D_fake: 0.489 \n",
            "End of epoch 40 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 41 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 42 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 43 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 44, iters: 10, time: 0.094, data: 0.149) G_GAN: 1.636 G_L1: 20.505 D_real: 0.031 D_fake: 0.299 \n",
            "End of epoch 44 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 45 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 46 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 47, iters: 20, time: 0.103, data: 0.002) G_GAN: 1.957 G_L1: 21.828 D_real: 0.116 D_fake: 0.036 \n",
            "End of epoch 47 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 48 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 49 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 50, iters: 30, time: 0.103, data: 0.001) G_GAN: 3.310 G_L1: 43.190 D_real: 0.001 D_fake: 0.137 \n",
            "End of epoch 50 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 51 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 52 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 53 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 54, iters: 10, time: 0.283, data: 0.175) G_GAN: 1.878 G_L1: 16.295 D_real: 0.349 D_fake: 0.229 \n",
            "End of epoch 54 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 55 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 56 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 57, iters: 20, time: 0.103, data: 0.002) G_GAN: 1.855 G_L1: 14.920 D_real: 0.315 D_fake: 0.272 \n",
            "End of epoch 57 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 58 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 59 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 60, iters: 30, time: 0.106, data: 0.001) G_GAN: 1.251 G_L1: 11.681 D_real: 1.205 D_fake: 0.098 \n",
            "End of epoch 60 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 61 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 62 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 63 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 64, iters: 10, time: 0.105, data: 0.162) G_GAN: 1.744 G_L1: 10.606 D_real: 1.055 D_fake: 0.126 \n",
            "End of epoch 64 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 65 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 66 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 67, iters: 20, time: 0.315, data: 0.001) G_GAN: 1.848 G_L1: 16.173 D_real: 0.152 D_fake: 0.308 \n",
            "End of epoch 67 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 68 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 69 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 70, iters: 30, time: 0.106, data: 0.002) G_GAN: 1.243 G_L1: 8.474 D_real: 1.007 D_fake: 0.235 \n",
            "End of epoch 70 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 71 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 72 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 73 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 74, iters: 10, time: 0.104, data: 0.156) G_GAN: 0.864 G_L1: 7.780 D_real: 0.719 D_fake: 0.046 \n",
            "End of epoch 74 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 75 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 76 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 77, iters: 20, time: 0.105, data: 0.002) G_GAN: 2.989 G_L1: 28.345 D_real: 0.027 D_fake: 0.080 \n",
            "End of epoch 77 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 78 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 79 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 80, iters: 30, time: 0.356, data: 0.002) G_GAN: 1.484 G_L1: 14.040 D_real: 0.174 D_fake: 0.457 \n",
            "End of epoch 80 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 81 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 82 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 83 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 84, iters: 10, time: 0.104, data: 0.163) G_GAN: 0.657 G_L1: 9.329 D_real: 0.591 D_fake: 0.569 \n",
            "End of epoch 84 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 85 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 86 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 87, iters: 20, time: 0.100, data: 0.001) G_GAN: 2.038 G_L1: 27.805 D_real: 0.083 D_fake: 0.219 \n",
            "End of epoch 87 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 88 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 89 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 90, iters: 30, time: 0.108, data: 0.002) G_GAN: 0.820 G_L1: 18.579 D_real: 0.896 D_fake: 0.063 \n",
            "End of epoch 90 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 91 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 92 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 93 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 94, iters: 10, time: 0.398, data: 0.174) G_GAN: 0.525 G_L1: 16.730 D_real: 0.019 D_fake: 1.299 \n",
            "End of epoch 94 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 95 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 96 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 97, iters: 20, time: 0.105, data: 0.002) G_GAN: 0.832 G_L1: 5.554 D_real: 0.694 D_fake: 0.402 \n",
            "End of epoch 97 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 98 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 99 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001980\n",
            "(epoch: 100, iters: 30, time: 0.102, data: 0.001) G_GAN: 1.271 G_L1: 5.764 D_real: 1.048 D_fake: 0.439 \n",
            "saving the model at the end of epoch 100, iters 3000\n",
            "End of epoch 100 / 200 \t Time Taken: 3 sec\n",
            "learning rate = 0.0001960\n",
            "End of epoch 101 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001941\n",
            "End of epoch 102 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001921\n",
            "End of epoch 103 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001901\n",
            "(epoch: 104, iters: 10, time: 0.106, data: 0.179) G_GAN: 0.993 G_L1: 9.873 D_real: 0.919 D_fake: 0.352 \n",
            "End of epoch 104 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001881\n",
            "End of epoch 105 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001861\n",
            "End of epoch 106 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001842\n",
            "(epoch: 107, iters: 20, time: 0.412, data: 0.001) G_GAN: 0.558 G_L1: 8.831 D_real: 0.096 D_fake: 1.583 \n",
            "End of epoch 107 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001822\n",
            "End of epoch 108 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001802\n",
            "End of epoch 109 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001782\n",
            "(epoch: 110, iters: 30, time: 0.104, data: 0.001) G_GAN: 1.010 G_L1: 13.691 D_real: 0.725 D_fake: 0.718 \n",
            "End of epoch 110 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001762\n",
            "End of epoch 111 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001743\n",
            "End of epoch 112 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001723\n",
            "End of epoch 113 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001703\n",
            "(epoch: 114, iters: 10, time: 0.105, data: 0.167) G_GAN: 0.590 G_L1: 4.604 D_real: 0.437 D_fake: 0.960 \n",
            "End of epoch 114 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001683\n",
            "End of epoch 115 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001663\n",
            "End of epoch 116 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001644\n",
            "(epoch: 117, iters: 20, time: 0.102, data: 0.001) G_GAN: 0.737 G_L1: 7.517 D_real: 0.478 D_fake: 0.757 \n",
            "End of epoch 117 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001624\n",
            "End of epoch 118 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001604\n",
            "End of epoch 119 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001584\n",
            "(epoch: 120, iters: 30, time: 0.504, data: 0.001) G_GAN: 0.793 G_L1: 20.523 D_real: 0.243 D_fake: 0.599 \n",
            "End of epoch 120 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001564\n",
            "End of epoch 121 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001545\n",
            "End of epoch 122 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001525\n",
            "End of epoch 123 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001505\n",
            "(epoch: 124, iters: 10, time: 0.107, data: 0.178) G_GAN: 0.811 G_L1: 3.834 D_real: 0.659 D_fake: 0.484 \n",
            "End of epoch 124 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001485\n",
            "End of epoch 125 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001465\n",
            "End of epoch 126 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001446\n",
            "(epoch: 127, iters: 20, time: 0.100, data: 0.001) G_GAN: 0.742 G_L1: 3.781 D_real: 0.647 D_fake: 0.638 \n",
            "End of epoch 127 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001426\n",
            "End of epoch 128 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001406\n",
            "End of epoch 129 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001386\n",
            "(epoch: 130, iters: 30, time: 0.102, data: 0.002) G_GAN: 0.776 G_L1: 5.462 D_real: 0.599 D_fake: 0.636 \n",
            "End of epoch 130 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001366\n",
            "End of epoch 131 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001347\n",
            "End of epoch 132 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001327\n",
            "End of epoch 133 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001307\n",
            "(epoch: 134, iters: 10, time: 0.487, data: 0.169) G_GAN: 1.383 G_L1: 15.259 D_real: 0.124 D_fake: 0.842 \n",
            "End of epoch 134 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001287\n",
            "End of epoch 135 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001267\n",
            "End of epoch 136 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001248\n",
            "(epoch: 137, iters: 20, time: 0.100, data: 0.002) G_GAN: 0.767 G_L1: 6.737 D_real: 0.575 D_fake: 0.669 \n",
            "End of epoch 137 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001228\n",
            "End of epoch 138 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001208\n",
            "End of epoch 139 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001188\n",
            "(epoch: 140, iters: 30, time: 0.109, data: 0.001) G_GAN: 0.769 G_L1: 6.535 D_real: 0.613 D_fake: 0.610 \n",
            "End of epoch 140 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001168\n",
            "End of epoch 141 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001149\n",
            "End of epoch 142 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001129\n",
            "End of epoch 143 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001109\n",
            "(epoch: 144, iters: 10, time: 0.106, data: 0.166) G_GAN: 0.731 G_L1: 3.508 D_real: 0.688 D_fake: 0.606 \n",
            "End of epoch 144 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001089\n",
            "End of epoch 145 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001069\n",
            "End of epoch 146 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001050\n",
            "(epoch: 147, iters: 20, time: 0.494, data: 0.001) G_GAN: 1.014 G_L1: 6.220 D_real: 0.705 D_fake: 1.350 \n",
            "End of epoch 147 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001030\n",
            "End of epoch 148 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001010\n",
            "End of epoch 149 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000990\n",
            "(epoch: 150, iters: 30, time: 0.108, data: 0.002) G_GAN: 0.782 G_L1: 10.281 D_real: 0.666 D_fake: 0.583 \n",
            "End of epoch 150 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000970\n",
            "End of epoch 151 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000950\n",
            "End of epoch 152 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000931\n",
            "End of epoch 153 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000911\n",
            "(epoch: 154, iters: 10, time: 0.103, data: 0.177) G_GAN: 0.590 G_L1: 3.829 D_real: 0.622 D_fake: 0.801 \n",
            "End of epoch 154 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000891\n",
            "End of epoch 155 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000871\n",
            "End of epoch 156 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000851\n",
            "(epoch: 157, iters: 20, time: 0.105, data: 0.002) G_GAN: 0.625 G_L1: 3.267 D_real: 0.529 D_fake: 0.915 \n",
            "End of epoch 157 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000832\n",
            "End of epoch 158 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000812\n",
            "End of epoch 159 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000792\n",
            "(epoch: 160, iters: 30, time: 0.548, data: 0.002) G_GAN: 0.902 G_L1: 3.152 D_real: 0.800 D_fake: 0.788 \n",
            "End of epoch 160 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000772\n",
            "End of epoch 161 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000752\n",
            "End of epoch 162 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000733\n",
            "End of epoch 163 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000713\n",
            "(epoch: 164, iters: 10, time: 0.105, data: 0.182) G_GAN: 0.713 G_L1: 3.442 D_real: 0.607 D_fake: 0.706 \n",
            "End of epoch 164 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000693\n",
            "End of epoch 165 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000673\n",
            "End of epoch 166 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000653\n",
            "(epoch: 167, iters: 20, time: 0.107, data: 0.002) G_GAN: 0.809 G_L1: 5.443 D_real: 0.602 D_fake: 0.592 \n",
            "saving the latest model (epoch 167, total_steps 5000)\n",
            "End of epoch 167 / 200 \t Time Taken: 3 sec\n",
            "learning rate = 0.0000634\n",
            "End of epoch 168 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000614\n",
            "End of epoch 169 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000594\n",
            "(epoch: 170, iters: 30, time: 0.107, data: 0.002) G_GAN: 0.682 G_L1: 5.418 D_real: 0.491 D_fake: 0.707 \n",
            "End of epoch 170 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000574\n",
            "End of epoch 171 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000554\n",
            "End of epoch 172 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000535\n",
            "End of epoch 173 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000515\n",
            "(epoch: 174, iters: 10, time: 0.585, data: 0.162) G_GAN: 0.773 G_L1: 3.483 D_real: 0.686 D_fake: 0.630 \n",
            "End of epoch 174 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000495\n",
            "End of epoch 175 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000475\n",
            "End of epoch 176 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000455\n",
            "(epoch: 177, iters: 20, time: 0.106, data: 0.002) G_GAN: 0.829 G_L1: 3.244 D_real: 0.645 D_fake: 0.651 \n",
            "End of epoch 177 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000436\n",
            "End of epoch 178 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000416\n",
            "End of epoch 179 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000396\n",
            "(epoch: 180, iters: 30, time: 0.107, data: 0.002) G_GAN: 0.677 G_L1: 8.702 D_real: 0.156 D_fake: 1.011 \n",
            "End of epoch 180 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000376\n",
            "End of epoch 181 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000356\n",
            "End of epoch 182 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000337\n",
            "End of epoch 183 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000317\n",
            "(epoch: 184, iters: 10, time: 0.105, data: 0.140) G_GAN: 0.902 G_L1: 8.583 D_real: 0.342 D_fake: 0.600 \n",
            "End of epoch 184 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000297\n",
            "End of epoch 185 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000277\n",
            "End of epoch 186 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000257\n",
            "(epoch: 187, iters: 20, time: 0.699, data: 0.002) G_GAN: 0.786 G_L1: 11.648 D_real: 0.382 D_fake: 0.486 \n",
            "End of epoch 187 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000238\n",
            "End of epoch 188 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000218\n",
            "End of epoch 189 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000198\n",
            "(epoch: 190, iters: 30, time: 0.107, data: 0.002) G_GAN: 0.921 G_L1: 3.010 D_real: 0.713 D_fake: 0.523 \n",
            "End of epoch 190 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000178\n",
            "End of epoch 191 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000158\n",
            "End of epoch 192 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000139\n",
            "End of epoch 193 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000119\n",
            "(epoch: 194, iters: 10, time: 0.106, data: 0.167) G_GAN: 0.719 G_L1: 4.610 D_real: 0.447 D_fake: 0.520 \n",
            "End of epoch 194 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000099\n",
            "End of epoch 195 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000079\n",
            "End of epoch 196 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000059\n",
            "(epoch: 197, iters: 20, time: 0.106, data: 0.002) G_GAN: 0.945 G_L1: 7.660 D_real: 0.349 D_fake: 0.641 \n",
            "End of epoch 197 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000040\n",
            "End of epoch 198 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000020\n",
            "End of epoch 199 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000000\n",
            "(epoch: 200, iters: 30, time: 0.672, data: 0.002) G_GAN: 0.823 G_L1: 6.213 D_real: 0.536 D_fake: 0.561 \n",
            "saving the model at the end of epoch 200, iters 6000\n",
            "End of epoch 200 / 200 \t Time Taken: 4 sec\n",
            "learning rate = -0.0000020\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8dcomLu0JIL",
        "outputId": "f901fb28-d3e4-4a08-f20f-7a4fa1a9aad8"
      },
      "source": [
        "!python train.py --dataroot \"../cycleGanData/train\" --name CASE2  \\\n",
        "  --gpu_ids 0 --display_id 0 \\\n",
        "  --niter 100 --niter_decay 100 \\\n",
        "  --pool_size 64 --loadSize 256 --fineSize 256\\\n",
        "  --model \"cycle_gan\" --dataset_mode \"unaligned\" --which_direction \"AtoB\"\\\n",
        "  --save_epoch_freq 100"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------- Options ---------------\n",
            "                batchSize: 1                             \n",
            "                    beta1: 0.5                           \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "           continue_train: False                         \n",
            "                 dataroot: ../cycleGanData/train         \t[default: None]\n",
            "             dataset_mode: unaligned                     \t[default: aligned]\n",
            "             display_freq: 400                           \n",
            "               display_id: 0                             \t[default: 1]\n",
            "            display_ncols: 4                             \n",
            "             display_port: 8097                          \n",
            "           display_server: http://localhost              \n",
            "          display_winsize: 256                           \n",
            "              epoch_count: 1                             \n",
            "                 fineSize: 256                           \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: True                          \t[default: None]\n",
            "                 lambda_A: 10.0                          \n",
            "                 lambda_B: 10.0                          \n",
            "          lambda_identity: 0.5                           \n",
            "                 loadSize: 256                           \t[default: 286]\n",
            "                       lr: 0.0002                        \n",
            "           lr_decay_iters: 50                            \n",
            "                lr_policy: lambda                        \n",
            "         max_dataset_size: inf                           \n",
            "                    model: cycle_gan                     \t[default: pix2pix]\n",
            "                 nThreads: 4                             \n",
            "               n_layers_D: 3                             \n",
            "                     name: CASE2                         \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                      ngf: 64                            \n",
            "                    niter: 100                           \n",
            "              niter_decay: 100                           \n",
            "               no_dropout: True                          \n",
            "                  no_flip: False                         \n",
            "                  no_html: False                         \n",
            "                 no_lsgan: False                         \n",
            "                     norm: instance                      \n",
            "                output_nc: 3                             \n",
            "                    phase: train                         \n",
            "                pool_size: 64                            \t[default: 50]\n",
            "               print_freq: 100                           \n",
            "           resize_or_crop: resize_and_crop               \n",
            "          save_epoch_freq: 100                           \t[default: 5]\n",
            "         save_latest_freq: 5000                          \n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "         update_html_freq: 1000                          \n",
            "                  verbose: False                         \n",
            "          which_direction: AtoB                          \n",
            "              which_epoch: latest                        \n",
            "         which_model_netD: basic                         \n",
            "         which_model_netG: unet_256                      \n",
            "----------------- End -------------------\n",
            "dataset [UnalignedDataset] was created\n",
            "#training images = 30\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "model [CycleGANModel] was created\n",
            "---------- Networks initialized -------------\n",
            "[Network G_A] Total number of parameters : 54.414 M\n",
            "[Network G_B] Total number of parameters : 54.414 M\n",
            "[Network D_A] Total number of parameters : 2.764 M\n",
            "[Network D_B] Total number of parameters : 2.764 M\n",
            "-----------------------------------------------\n",
            "create web directory ./checkpoints/CASE2/web...\n",
            "End of epoch 1 / 200 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 2 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 3 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 4, iters: 10, time: 0.278, data: 0.232) D_A: 0.044 G_A: 0.448 cycle_A: 1.888 idt_A: 1.865 D_B: 0.188 G_B: 0.251 cycle_B: 4.064 idt_B: 0.713 \n",
            "End of epoch 4 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 5 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 6 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 7, iters: 20, time: 0.280, data: 0.001) D_A: 0.107 G_A: 0.323 cycle_A: 2.226 idt_A: 2.208 D_B: 0.172 G_B: 0.214 cycle_B: 4.381 idt_B: 1.102 \n",
            "End of epoch 7 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 8 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 9 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 10, iters: 30, time: 0.281, data: 0.002) D_A: 0.396 G_A: 0.049 cycle_A: 1.620 idt_A: 0.812 D_B: 0.312 G_B: 0.219 cycle_B: 1.794 idt_B: 0.583 \n",
            "End of epoch 10 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 11 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 12 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 13 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 14, iters: 10, time: 0.491, data: 0.215) D_A: 0.244 G_A: 0.465 cycle_A: 1.745 idt_A: 0.314 D_B: 0.053 G_B: 0.327 cycle_B: 1.189 idt_B: 0.721 \n",
            "End of epoch 14 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 15 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 16 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 17, iters: 20, time: 0.278, data: 0.001) D_A: 0.163 G_A: 0.367 cycle_A: 1.456 idt_A: 0.400 D_B: 0.088 G_B: 0.311 cycle_B: 1.018 idt_B: 0.542 \n",
            "End of epoch 17 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 18 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 19 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 20, iters: 30, time: 0.278, data: 0.002) D_A: 0.094 G_A: 0.471 cycle_A: 1.505 idt_A: 0.234 D_B: 0.134 G_B: 0.488 cycle_B: 0.601 idt_B: 0.687 \n",
            "End of epoch 20 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 21 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 22 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 23 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 24, iters: 10, time: 0.280, data: 0.212) D_A: 0.251 G_A: 0.561 cycle_A: 1.373 idt_A: 0.279 D_B: 0.273 G_B: 0.162 cycle_B: 0.760 idt_B: 0.449 \n",
            "End of epoch 24 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 25 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 26 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 27, iters: 20, time: 0.580, data: 0.001) D_A: 0.102 G_A: 0.374 cycle_A: 1.617 idt_A: 0.186 D_B: 0.204 G_B: 0.415 cycle_B: 0.460 idt_B: 0.711 \n",
            "End of epoch 27 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 28 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 29 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 30, iters: 30, time: 0.280, data: 0.001) D_A: 0.008 G_A: 0.065 cycle_A: 1.229 idt_A: 0.142 D_B: 0.199 G_B: 0.442 cycle_B: 0.426 idt_B: 0.366 \n",
            "End of epoch 30 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 31 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 32 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 33 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 34, iters: 10, time: 0.280, data: 0.197) D_A: 0.186 G_A: 0.590 cycle_A: 1.312 idt_A: 0.482 D_B: 0.044 G_B: 0.173 cycle_B: 1.120 idt_B: 0.461 \n",
            "End of epoch 34 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 35 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 36 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 37, iters: 20, time: 0.277, data: 0.002) D_A: 0.183 G_A: 0.888 cycle_A: 1.648 idt_A: 0.140 D_B: 0.271 G_B: 0.506 cycle_B: 0.357 idt_B: 0.520 \n",
            "End of epoch 37 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 38 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 39 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 40, iters: 30, time: 0.665, data: 0.001) D_A: 0.017 G_A: 0.336 cycle_A: 1.245 idt_A: 0.119 D_B: 0.279 G_B: 0.719 cycle_B: 0.475 idt_B: 0.350 \n",
            "End of epoch 40 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 41 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 42 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 43 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 44, iters: 10, time: 0.278, data: 0.231) D_A: 0.046 G_A: 0.853 cycle_A: 1.054 idt_A: 0.165 D_B: 0.120 G_B: 0.301 cycle_B: 0.407 idt_B: 0.344 \n",
            "End of epoch 44 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 45 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 46 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 47, iters: 20, time: 0.279, data: 0.001) D_A: 0.117 G_A: 0.950 cycle_A: 1.198 idt_A: 0.176 D_B: 0.146 G_B: 0.364 cycle_B: 0.463 idt_B: 0.396 \n",
            "End of epoch 47 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 48 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 49 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 50, iters: 30, time: 0.282, data: 0.002) D_A: 0.134 G_A: 0.861 cycle_A: 1.135 idt_A: 0.172 D_B: 0.271 G_B: 0.278 cycle_B: 0.442 idt_B: 0.316 \n",
            "End of epoch 50 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 51 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 52 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 53 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 54, iters: 10, time: 0.763, data: 0.205) D_A: 0.297 G_A: 0.883 cycle_A: 1.146 idt_A: 0.361 D_B: 0.277 G_B: 0.155 cycle_B: 0.791 idt_B: 0.348 \n",
            "End of epoch 54 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 55 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 56 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 57, iters: 20, time: 0.278, data: 0.001) D_A: 0.057 G_A: 0.399 cycle_A: 1.197 idt_A: 0.134 D_B: 0.315 G_B: 0.275 cycle_B: 0.319 idt_B: 0.326 \n",
            "End of epoch 57 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 58 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 59 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 60, iters: 30, time: 0.279, data: 0.001) D_A: 0.075 G_A: 0.958 cycle_A: 1.128 idt_A: 0.108 D_B: 0.164 G_B: 0.280 cycle_B: 0.247 idt_B: 0.380 \n",
            "End of epoch 60 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 61 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 62 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 63 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 64, iters: 10, time: 0.280, data: 0.212) D_A: 0.113 G_A: 0.538 cycle_A: 1.008 idt_A: 0.150 D_B: 0.122 G_B: 0.329 cycle_B: 0.348 idt_B: 0.328 \n",
            "End of epoch 64 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 65 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 66 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 67, iters: 20, time: 0.832, data: 0.001) D_A: 0.106 G_A: 0.468 cycle_A: 1.072 idt_A: 0.149 D_B: 0.193 G_B: 0.339 cycle_B: 0.333 idt_B: 0.294 \n",
            "End of epoch 67 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 68 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 69 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 70, iters: 30, time: 0.281, data: 0.001) D_A: 0.069 G_A: 0.636 cycle_A: 1.015 idt_A: 0.177 D_B: 0.167 G_B: 0.296 cycle_B: 0.428 idt_B: 0.310 \n",
            "End of epoch 70 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 71 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 72 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 73 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 74, iters: 10, time: 0.279, data: 0.188) D_A: 0.217 G_A: 0.321 cycle_A: 1.207 idt_A: 0.241 D_B: 0.155 G_B: 0.249 cycle_B: 0.516 idt_B: 0.296 \n",
            "End of epoch 74 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 75 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 76 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 77, iters: 20, time: 0.279, data: 0.001) D_A: 0.200 G_A: 0.814 cycle_A: 0.936 idt_A: 0.188 D_B: 0.176 G_B: 0.190 cycle_B: 0.416 idt_B: 0.280 \n",
            "End of epoch 77 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 78 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 79 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 80, iters: 30, time: 0.971, data: 0.001) D_A: 0.050 G_A: 0.743 cycle_A: 0.962 idt_A: 0.126 D_B: 0.203 G_B: 0.183 cycle_B: 0.294 idt_B: 0.257 \n",
            "End of epoch 80 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 81 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 82 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 83 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 84, iters: 10, time: 0.276, data: 0.244) D_A: 0.194 G_A: 0.360 cycle_A: 1.055 idt_A: 0.153 D_B: 0.258 G_B: 0.185 cycle_B: 0.376 idt_B: 0.276 \n",
            "End of epoch 84 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 85 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 86 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 87, iters: 20, time: 0.279, data: 0.001) D_A: 0.119 G_A: 0.470 cycle_A: 0.898 idt_A: 0.113 D_B: 0.366 G_B: 0.290 cycle_B: 0.260 idt_B: 0.235 \n",
            "End of epoch 87 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 88 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 89 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 90, iters: 30, time: 0.282, data: 0.001) D_A: 0.105 G_A: 0.984 cycle_A: 1.154 idt_A: 0.090 D_B: 0.275 G_B: 0.268 cycle_B: 0.214 idt_B: 0.278 \n",
            "End of epoch 90 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 91 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 92 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 93 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 94, iters: 10, time: 1.007, data: 0.204) D_A: 0.171 G_A: 0.198 cycle_A: 1.250 idt_A: 0.123 D_B: 0.198 G_B: 0.294 cycle_B: 0.303 idt_B: 0.273 \n",
            "End of epoch 94 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 95 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 96 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 97, iters: 20, time: 0.279, data: 0.002) D_A: 0.132 G_A: 0.603 cycle_A: 1.055 idt_A: 0.088 D_B: 0.191 G_B: 0.344 cycle_B: 0.202 idt_B: 0.272 \n",
            "End of epoch 97 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 98 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 99 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001980\n",
            "(epoch: 100, iters: 30, time: 0.280, data: 0.001) D_A: 0.119 G_A: 0.301 cycle_A: 1.113 idt_A: 0.125 D_B: 0.259 G_B: 0.282 cycle_B: 0.302 idt_B: 0.259 \n",
            "saving the model at the end of epoch 100, iters 3000\n",
            "End of epoch 100 / 200 \t Time Taken: 10 sec\n",
            "learning rate = 0.0001960\n",
            "End of epoch 101 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001941\n",
            "End of epoch 102 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001921\n",
            "End of epoch 103 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001901\n",
            "(epoch: 104, iters: 10, time: 0.278, data: 0.256) D_A: 0.111 G_A: 0.376 cycle_A: 1.186 idt_A: 0.097 D_B: 0.295 G_B: 0.282 cycle_B: 0.225 idt_B: 0.283 \n",
            "End of epoch 104 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001881\n",
            "End of epoch 105 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001861\n",
            "End of epoch 106 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001842\n",
            "(epoch: 107, iters: 20, time: 1.101, data: 0.002) D_A: 0.110 G_A: 0.565 cycle_A: 0.957 idt_A: 0.082 D_B: 0.280 G_B: 0.225 cycle_B: 0.198 idt_B: 0.227 \n",
            "End of epoch 107 / 200 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001822\n",
            "End of epoch 108 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001802\n",
            "End of epoch 109 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001782\n",
            "(epoch: 110, iters: 30, time: 0.279, data: 0.002) D_A: 0.104 G_A: 0.380 cycle_A: 0.905 idt_A: 0.128 D_B: 0.298 G_B: 0.192 cycle_B: 0.289 idt_B: 0.203 \n",
            "End of epoch 110 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001762\n",
            "End of epoch 111 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001743\n",
            "End of epoch 112 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001723\n",
            "End of epoch 113 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001703\n",
            "(epoch: 114, iters: 10, time: 0.279, data: 0.227) D_A: 0.129 G_A: 0.299 cycle_A: 0.869 idt_A: 0.086 D_B: 0.203 G_B: 0.362 cycle_B: 0.210 idt_B: 0.194 \n",
            "End of epoch 114 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001683\n",
            "End of epoch 115 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001663\n",
            "End of epoch 116 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001644\n",
            "(epoch: 117, iters: 20, time: 0.280, data: 0.001) D_A: 0.124 G_A: 0.374 cycle_A: 0.990 idt_A: 0.108 D_B: 0.195 G_B: 0.245 cycle_B: 0.248 idt_B: 0.255 \n",
            "End of epoch 117 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001624\n",
            "End of epoch 118 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001604\n",
            "End of epoch 119 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001584\n",
            "(epoch: 120, iters: 30, time: 1.240, data: 0.002) D_A: 0.168 G_A: 0.252 cycle_A: 1.028 idt_A: 0.106 D_B: 0.343 G_B: 0.270 cycle_B: 0.253 idt_B: 0.199 \n",
            "End of epoch 120 / 200 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001564\n",
            "End of epoch 121 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001545\n",
            "End of epoch 122 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001525\n",
            "End of epoch 123 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001505\n",
            "(epoch: 124, iters: 10, time: 0.279, data: 0.241) D_A: 0.018 G_A: 0.355 cycle_A: 1.038 idt_A: 0.090 D_B: 0.230 G_B: 0.201 cycle_B: 0.214 idt_B: 0.199 \n",
            "End of epoch 124 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001485\n",
            "End of epoch 125 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001465\n",
            "End of epoch 126 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001446\n",
            "(epoch: 127, iters: 20, time: 0.280, data: 0.001) D_A: 0.169 G_A: 0.206 cycle_A: 0.851 idt_A: 0.085 D_B: 0.198 G_B: 0.337 cycle_B: 0.211 idt_B: 0.185 \n",
            "End of epoch 127 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001426\n",
            "End of epoch 128 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001406\n",
            "End of epoch 129 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001386\n",
            "(epoch: 130, iters: 30, time: 0.281, data: 0.001) D_A: 0.138 G_A: 0.550 cycle_A: 1.059 idt_A: 0.070 D_B: 0.208 G_B: 0.262 cycle_B: 0.156 idt_B: 0.220 \n",
            "End of epoch 130 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001366\n",
            "End of epoch 131 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001347\n",
            "End of epoch 132 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001327\n",
            "End of epoch 133 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001307\n",
            "(epoch: 134, iters: 10, time: 1.287, data: 0.221) D_A: 0.059 G_A: 0.721 cycle_A: 0.815 idt_A: 0.114 D_B: 0.265 G_B: 0.225 cycle_B: 0.249 idt_B: 0.198 \n",
            "End of epoch 134 / 200 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001287\n",
            "End of epoch 135 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001267\n",
            "End of epoch 136 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001248\n",
            "(epoch: 137, iters: 20, time: 0.278, data: 0.002) D_A: 0.175 G_A: 0.200 cycle_A: 1.082 idt_A: 0.085 D_B: 0.274 G_B: 0.394 cycle_B: 0.218 idt_B: 0.227 \n",
            "End of epoch 137 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001228\n",
            "End of epoch 138 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001208\n",
            "End of epoch 139 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001188\n",
            "(epoch: 140, iters: 30, time: 0.282, data: 0.001) D_A: 0.392 G_A: 0.240 cycle_A: 1.440 idt_A: 0.192 D_B: 0.264 G_B: 0.246 cycle_B: 0.412 idt_B: 0.309 \n",
            "End of epoch 140 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001168\n",
            "End of epoch 141 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001149\n",
            "End of epoch 142 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001129\n",
            "End of epoch 143 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001109\n",
            "(epoch: 144, iters: 10, time: 0.278, data: 0.203) D_A: 0.108 G_A: 0.522 cycle_A: 1.105 idt_A: 0.063 D_B: 0.224 G_B: 0.345 cycle_B: 0.152 idt_B: 0.246 \n",
            "End of epoch 144 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001089\n",
            "End of epoch 145 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001069\n",
            "End of epoch 146 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001050\n",
            "(epoch: 147, iters: 20, time: 1.429, data: 0.002) D_A: 0.133 G_A: 0.499 cycle_A: 1.023 idt_A: 0.068 D_B: 0.223 G_B: 0.273 cycle_B: 0.157 idt_B: 0.227 \n",
            "End of epoch 147 / 200 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001030\n",
            "End of epoch 148 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001010\n",
            "End of epoch 149 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000990\n",
            "(epoch: 150, iters: 30, time: 0.283, data: 0.001) D_A: 0.141 G_A: 0.270 cycle_A: 1.112 idt_A: 0.076 D_B: 0.286 G_B: 0.271 cycle_B: 0.191 idt_B: 0.250 \n",
            "End of epoch 150 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000970\n",
            "End of epoch 151 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000950\n",
            "End of epoch 152 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000931\n",
            "End of epoch 153 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000911\n",
            "(epoch: 154, iters: 10, time: 0.279, data: 0.213) D_A: 0.114 G_A: 0.608 cycle_A: 1.209 idt_A: 0.063 D_B: 0.280 G_B: 0.266 cycle_B: 0.148 idt_B: 0.245 \n",
            "End of epoch 154 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000891\n",
            "End of epoch 155 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000871\n",
            "End of epoch 156 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000851\n",
            "(epoch: 157, iters: 20, time: 0.279, data: 0.001) D_A: 0.053 G_A: 0.571 cycle_A: 1.196 idt_A: 0.056 D_B: 0.265 G_B: 0.290 cycle_B: 0.137 idt_B: 0.244 \n",
            "End of epoch 157 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000832\n",
            "End of epoch 158 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000812\n",
            "End of epoch 159 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000792\n",
            "(epoch: 160, iters: 30, time: 1.477, data: 0.002) D_A: 0.244 G_A: 0.368 cycle_A: 1.009 idt_A: 0.169 D_B: 0.238 G_B: 0.257 cycle_B: 0.332 idt_B: 0.201 \n",
            "End of epoch 160 / 200 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000772\n",
            "End of epoch 161 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000752\n",
            "End of epoch 162 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000733\n",
            "End of epoch 163 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000713\n",
            "(epoch: 164, iters: 10, time: 0.277, data: 0.217) D_A: 0.121 G_A: 0.308 cycle_A: 1.099 idt_A: 0.056 D_B: 0.307 G_B: 0.224 cycle_B: 0.133 idt_B: 0.241 \n",
            "End of epoch 164 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000693\n",
            "End of epoch 165 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000673\n",
            "End of epoch 166 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000653\n",
            "(epoch: 167, iters: 20, time: 0.278, data: 0.001) D_A: 0.123 G_A: 0.370 cycle_A: 0.997 idt_A: 0.058 D_B: 0.283 G_B: 0.213 cycle_B: 0.131 idt_B: 0.226 \n",
            "saving the latest model (epoch 167, total_steps 5000)\n",
            "End of epoch 167 / 200 \t Time Taken: 9 sec\n",
            "learning rate = 0.0000634\n",
            "End of epoch 168 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000614\n",
            "End of epoch 169 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000594\n",
            "(epoch: 170, iters: 30, time: 0.279, data: 0.002) D_A: 0.155 G_A: 0.552 cycle_A: 0.975 idt_A: 0.088 D_B: 0.223 G_B: 0.283 cycle_B: 0.210 idt_B: 0.198 \n",
            "End of epoch 170 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000574\n",
            "End of epoch 171 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000554\n",
            "End of epoch 172 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000535\n",
            "End of epoch 173 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000515\n",
            "(epoch: 174, iters: 10, time: 1.603, data: 0.206) D_A: 0.150 G_A: 0.553 cycle_A: 1.141 idt_A: 0.058 D_B: 0.271 G_B: 0.267 cycle_B: 0.131 idt_B: 0.237 \n",
            "End of epoch 174 / 200 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000495\n",
            "End of epoch 175 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000475\n",
            "End of epoch 176 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000455\n",
            "(epoch: 177, iters: 20, time: 0.279, data: 0.002) D_A: 0.122 G_A: 0.386 cycle_A: 0.693 idt_A: 0.054 D_B: 0.266 G_B: 0.282 cycle_B: 0.119 idt_B: 0.161 \n",
            "End of epoch 177 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000436\n",
            "End of epoch 178 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000416\n",
            "End of epoch 179 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000396\n",
            "(epoch: 180, iters: 30, time: 0.283, data: 0.002) D_A: 0.091 G_A: 0.461 cycle_A: 1.055 idt_A: 0.053 D_B: 0.263 G_B: 0.268 cycle_B: 0.119 idt_B: 0.242 \n",
            "End of epoch 180 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000376\n",
            "End of epoch 181 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000356\n",
            "End of epoch 182 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000337\n",
            "End of epoch 183 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000317\n",
            "(epoch: 184, iters: 10, time: 0.280, data: 0.217) D_A: 0.073 G_A: 0.497 cycle_A: 1.070 idt_A: 0.049 D_B: 0.260 G_B: 0.247 cycle_B: 0.102 idt_B: 0.238 \n",
            "End of epoch 184 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000297\n",
            "End of epoch 185 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000277\n",
            "End of epoch 186 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000257\n",
            "(epoch: 187, iters: 20, time: 1.647, data: 0.002) D_A: 0.080 G_A: 0.434 cycle_A: 0.932 idt_A: 0.051 D_B: 0.232 G_B: 0.283 cycle_B: 0.109 idt_B: 0.242 \n",
            "End of epoch 187 / 200 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000238\n",
            "End of epoch 188 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000218\n",
            "End of epoch 189 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000198\n",
            "(epoch: 190, iters: 30, time: 0.280, data: 0.001) D_A: 0.038 G_A: 0.687 cycle_A: 0.915 idt_A: 0.050 D_B: 0.220 G_B: 0.261 cycle_B: 0.105 idt_B: 0.222 \n",
            "End of epoch 190 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000178\n",
            "End of epoch 191 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000158\n",
            "End of epoch 192 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000139\n",
            "End of epoch 193 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000119\n",
            "(epoch: 194, iters: 10, time: 0.279, data: 0.229) D_A: 0.041 G_A: 0.600 cycle_A: 0.943 idt_A: 0.051 D_B: 0.247 G_B: 0.293 cycle_B: 0.100 idt_B: 0.195 \n",
            "End of epoch 194 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000099\n",
            "End of epoch 195 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000079\n",
            "End of epoch 196 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000059\n",
            "(epoch: 197, iters: 20, time: 0.279, data: 0.001) D_A: 0.078 G_A: 0.571 cycle_A: 0.948 idt_A: 0.076 D_B: 0.243 G_B: 0.239 cycle_B: 0.134 idt_B: 0.216 \n",
            "End of epoch 197 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000040\n",
            "End of epoch 198 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000020\n",
            "End of epoch 199 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000000\n",
            "(epoch: 200, iters: 30, time: 1.771, data: 0.001) D_A: 0.079 G_A: 0.559 cycle_A: 1.329 idt_A: 0.055 D_B: 0.250 G_B: 0.270 cycle_B: 0.102 idt_B: 0.282 \n",
            "saving the model at the end of epoch 200, iters 6000\n",
            "End of epoch 200 / 200 \t Time Taken: 12 sec\n",
            "learning rate = -0.0000020\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Spf7wtagemLe",
        "outputId": "b2a69039-0381-45a2-be01-8e532b9f0964"
      },
      "source": [
        "!python train.py --dataroot \"../pix2pixData/\" --name CASE3  \\\n",
        "  --gpu_ids 0 --display_id 0 \\\n",
        "  --niter 100 --niter_decay 100 \\\n",
        "  --pool_size 64 --loadSize 256 --fineSize 256\\\n",
        "  --init_type \"xavier\"\\\n",
        "  --save_epoch_freq 100"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------- Options ---------------\n",
            "                batchSize: 1                             \n",
            "                    beta1: 0.5                           \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "           continue_train: False                         \n",
            "                 dataroot: ../pix2pixData/               \t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "             display_freq: 400                           \n",
            "               display_id: 0                             \t[default: 1]\n",
            "            display_ncols: 4                             \n",
            "             display_port: 8097                          \n",
            "           display_server: http://localhost              \n",
            "          display_winsize: 256                           \n",
            "              epoch_count: 1                             \n",
            "                 fineSize: 256                           \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: xavier                        \t[default: normal]\n",
            "                 input_nc: 3                             \n",
            "                  isTrain: True                          \t[default: None]\n",
            "                lambda_L1: 100.0                         \n",
            "                 loadSize: 256                           \t[default: 286]\n",
            "                       lr: 0.0002                        \n",
            "           lr_decay_iters: 50                            \n",
            "                lr_policy: lambda                        \n",
            "         max_dataset_size: inf                           \n",
            "                    model: pix2pix                       \n",
            "                 nThreads: 4                             \n",
            "               n_layers_D: 3                             \n",
            "                     name: CASE3                         \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                      ngf: 64                            \n",
            "                    niter: 100                           \n",
            "              niter_decay: 100                           \n",
            "               no_dropout: False                         \n",
            "                  no_flip: False                         \n",
            "                  no_html: False                         \n",
            "                 no_lsgan: True                          \n",
            "                     norm: batch                         \n",
            "                output_nc: 3                             \n",
            "                    phase: train                         \n",
            "                pool_size: 64                            \t[default: 0]\n",
            "               print_freq: 100                           \n",
            "           resize_or_crop: resize_and_crop               \n",
            "          save_epoch_freq: 100                           \t[default: 5]\n",
            "         save_latest_freq: 5000                          \n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "         update_html_freq: 1000                          \n",
            "                  verbose: False                         \n",
            "          which_direction: AtoB                          \n",
            "              which_epoch: latest                        \n",
            "         which_model_netD: basic                         \n",
            "         which_model_netG: unet_256                      \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "#training images = 30\n",
            "initialize network with xavier\n",
            "initialize network with xavier\n",
            "model [Pix2PixModel] was created\n",
            "---------- Networks initialized -------------\n",
            "[Network G] Total number of parameters : 54.414 M\n",
            "[Network D] Total number of parameters : 2.767 M\n",
            "-----------------------------------------------\n",
            "create web directory ./checkpoints/CASE3/web...\n",
            "End of epoch 1 / 200 \t Time Taken: 3 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 2 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 3 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 4, iters: 10, time: 0.108, data: 0.249) G_GAN: 6.336 G_L1: 69.868 D_real: 0.000 D_fake: 0.025 \n",
            "End of epoch 4 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 5 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 6 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 7, iters: 20, time: 0.109, data: 0.001) G_GAN: 4.051 G_L1: 37.410 D_real: 0.000 D_fake: 0.041 \n",
            "End of epoch 7 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 8 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 9 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 10, iters: 30, time: 0.111, data: 0.001) G_GAN: 5.267 G_L1: 25.745 D_real: 0.026 D_fake: 0.004 \n",
            "End of epoch 10 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 11 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 12 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 13 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 14, iters: 10, time: 0.200, data: 0.219) G_GAN: 8.523 G_L1: 70.182 D_real: 0.000 D_fake: 0.001 \n",
            "End of epoch 14 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 15 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 16 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 17, iters: 20, time: 0.110, data: 0.001) G_GAN: 2.185 G_L1: 48.335 D_real: 0.001 D_fake: 0.159 \n",
            "End of epoch 17 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 18 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 19 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 20, iters: 30, time: 0.114, data: 0.001) G_GAN: 7.673 G_L1: 45.060 D_real: 0.000 D_fake: 0.001 \n",
            "End of epoch 20 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 21 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 22 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 23 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 24, iters: 10, time: 0.110, data: 0.199) G_GAN: 6.345 G_L1: 25.101 D_real: 0.016 D_fake: 0.003 \n",
            "End of epoch 24 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 25 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 26 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 27, iters: 20, time: 0.214, data: 0.001) G_GAN: 5.012 G_L1: 27.177 D_real: 0.000 D_fake: 0.003 \n",
            "End of epoch 27 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 28 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 29 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 30, iters: 30, time: 0.112, data: 0.001) G_GAN: 6.370 G_L1: 32.010 D_real: 0.003 D_fake: 0.034 \n",
            "End of epoch 30 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 31 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 32 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 33 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 34, iters: 10, time: 0.109, data: 0.183) G_GAN: 8.220 G_L1: 38.434 D_real: 0.008 D_fake: 0.011 \n",
            "End of epoch 34 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 35 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 36 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 37, iters: 20, time: 0.108, data: 0.001) G_GAN: 6.718 G_L1: 45.686 D_real: 0.000 D_fake: 0.004 \n",
            "End of epoch 37 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 38 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 39 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 40, iters: 30, time: 0.259, data: 0.001) G_GAN: 7.443 G_L1: 40.582 D_real: 0.048 D_fake: 0.021 \n",
            "End of epoch 40 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 41 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 42 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 43 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 44, iters: 10, time: 0.109, data: 0.208) G_GAN: 3.866 G_L1: 63.326 D_real: 0.000 D_fake: 0.022 \n",
            "End of epoch 44 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 45 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 46 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 47, iters: 20, time: 0.107, data: 0.001) G_GAN: 2.481 G_L1: 47.012 D_real: 0.000 D_fake: 0.014 \n",
            "End of epoch 47 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 48 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 49 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 50, iters: 30, time: 0.112, data: 0.001) G_GAN: 2.590 G_L1: 23.991 D_real: 0.472 D_fake: 0.072 \n",
            "End of epoch 50 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 51 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 52 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 53 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 54, iters: 10, time: 0.285, data: 0.204) G_GAN: 1.850 G_L1: 19.673 D_real: 0.068 D_fake: 0.298 \n",
            "End of epoch 54 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 55 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 56 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 57, iters: 20, time: 0.108, data: 0.002) G_GAN: 2.829 G_L1: 42.223 D_real: 0.001 D_fake: 0.157 \n",
            "End of epoch 57 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 58 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 59 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 60, iters: 30, time: 0.112, data: 0.002) G_GAN: 2.730 G_L1: 22.055 D_real: 0.060 D_fake: 0.095 \n",
            "End of epoch 60 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 61 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 62 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 63 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 64, iters: 10, time: 0.108, data: 0.194) G_GAN: 1.626 G_L1: 16.877 D_real: 0.163 D_fake: 0.813 \n",
            "End of epoch 64 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 65 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 66 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 67, iters: 20, time: 0.319, data: 0.001) G_GAN: 2.182 G_L1: 16.645 D_real: 1.096 D_fake: 0.088 \n",
            "End of epoch 67 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 68 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 69 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 70, iters: 30, time: 0.104, data: 0.001) G_GAN: 2.194 G_L1: 26.127 D_real: 0.030 D_fake: 0.027 \n",
            "End of epoch 70 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 71 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 72 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 73 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 74, iters: 10, time: 0.109, data: 0.210) G_GAN: 2.193 G_L1: 25.355 D_real: 0.050 D_fake: 0.023 \n",
            "End of epoch 74 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 75 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 76 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 77, iters: 20, time: 0.110, data: 0.001) G_GAN: 1.453 G_L1: 14.499 D_real: 0.042 D_fake: 0.978 \n",
            "End of epoch 77 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 78 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 79 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 80, iters: 30, time: 0.353, data: 0.001) G_GAN: 1.849 G_L1: 12.033 D_real: 0.174 D_fake: 0.269 \n",
            "End of epoch 80 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 81 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 82 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 83 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 84, iters: 10, time: 0.105, data: 0.209) G_GAN: 1.727 G_L1: 24.190 D_real: 0.049 D_fake: 0.061 \n",
            "End of epoch 84 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 85 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 86 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 87, iters: 20, time: 0.109, data: 0.001) G_GAN: 3.013 G_L1: 22.219 D_real: 0.206 D_fake: 0.022 \n",
            "End of epoch 87 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 88 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 89 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 90, iters: 30, time: 0.109, data: 0.001) G_GAN: 2.600 G_L1: 21.690 D_real: 0.060 D_fake: 0.201 \n",
            "End of epoch 90 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 91 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 92 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 93 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 94, iters: 10, time: 0.395, data: 0.219) G_GAN: 2.245 G_L1: 14.442 D_real: 1.334 D_fake: 0.043 \n",
            "End of epoch 94 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 95 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 96 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 97, iters: 20, time: 0.108, data: 0.001) G_GAN: 4.826 G_L1: 34.772 D_real: 0.001 D_fake: 0.104 \n",
            "End of epoch 97 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 98 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 99 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001980\n",
            "(epoch: 100, iters: 30, time: 0.112, data: 0.001) G_GAN: 1.253 G_L1: 11.038 D_real: 0.325 D_fake: 0.350 \n",
            "saving the model at the end of epoch 100, iters 3000\n",
            "End of epoch 100 / 200 \t Time Taken: 4 sec\n",
            "learning rate = 0.0001960\n",
            "End of epoch 101 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001941\n",
            "End of epoch 102 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001921\n",
            "End of epoch 103 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001901\n",
            "(epoch: 104, iters: 10, time: 0.109, data: 0.230) G_GAN: 2.232 G_L1: 10.917 D_real: 1.588 D_fake: 0.112 \n",
            "End of epoch 104 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001881\n",
            "End of epoch 105 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001861\n",
            "End of epoch 106 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001842\n",
            "(epoch: 107, iters: 20, time: 0.418, data: 0.002) G_GAN: 1.232 G_L1: 10.840 D_real: 0.533 D_fake: 0.072 \n",
            "End of epoch 107 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001822\n",
            "End of epoch 108 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001802\n",
            "End of epoch 109 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001782\n",
            "(epoch: 110, iters: 30, time: 0.113, data: 0.001) G_GAN: 0.706 G_L1: 8.921 D_real: 0.761 D_fake: 0.531 \n",
            "End of epoch 110 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001762\n",
            "End of epoch 111 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001743\n",
            "End of epoch 112 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001723\n",
            "End of epoch 113 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001703\n",
            "(epoch: 114, iters: 10, time: 0.108, data: 0.224) G_GAN: 1.386 G_L1: 16.920 D_real: 0.102 D_fake: 0.439 \n",
            "End of epoch 114 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001683\n",
            "End of epoch 115 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001663\n",
            "End of epoch 116 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001644\n",
            "(epoch: 117, iters: 20, time: 0.109, data: 0.001) G_GAN: 2.062 G_L1: 15.465 D_real: 0.522 D_fake: 0.103 \n",
            "End of epoch 117 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001624\n",
            "End of epoch 118 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001604\n",
            "End of epoch 119 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001584\n",
            "(epoch: 120, iters: 30, time: 0.507, data: 0.001) G_GAN: 1.257 G_L1: 10.064 D_real: 0.742 D_fake: 0.026 \n",
            "End of epoch 120 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001564\n",
            "End of epoch 121 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001545\n",
            "End of epoch 122 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001525\n",
            "End of epoch 123 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001505\n",
            "(epoch: 124, iters: 10, time: 0.108, data: 0.229) G_GAN: 1.493 G_L1: 13.051 D_real: 0.073 D_fake: 0.969 \n",
            "End of epoch 124 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001485\n",
            "End of epoch 125 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001465\n",
            "End of epoch 126 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001446\n",
            "(epoch: 127, iters: 20, time: 0.108, data: 0.001) G_GAN: 1.598 G_L1: 11.595 D_real: 0.744 D_fake: 0.092 \n",
            "End of epoch 127 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001426\n",
            "End of epoch 128 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001406\n",
            "End of epoch 129 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001386\n",
            "(epoch: 130, iters: 30, time: 0.111, data: 0.001) G_GAN: 1.060 G_L1: 11.103 D_real: 0.335 D_fake: 0.798 \n",
            "End of epoch 130 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001366\n",
            "End of epoch 131 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001347\n",
            "End of epoch 132 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001327\n",
            "End of epoch 133 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001307\n",
            "(epoch: 134, iters: 10, time: 0.486, data: 0.214) G_GAN: 0.942 G_L1: 6.040 D_real: 0.524 D_fake: 0.523 \n",
            "End of epoch 134 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001287\n",
            "End of epoch 135 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001267\n",
            "End of epoch 136 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001248\n",
            "(epoch: 137, iters: 20, time: 0.109, data: 0.001) G_GAN: 0.830 G_L1: 6.685 D_real: 1.040 D_fake: 0.174 \n",
            "End of epoch 137 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001228\n",
            "End of epoch 138 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001208\n",
            "End of epoch 139 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001188\n",
            "(epoch: 140, iters: 30, time: 0.111, data: 0.001) G_GAN: 0.542 G_L1: 6.547 D_real: 0.303 D_fake: 0.305 \n",
            "End of epoch 140 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001168\n",
            "End of epoch 141 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001149\n",
            "End of epoch 142 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001129\n",
            "End of epoch 143 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001109\n",
            "(epoch: 144, iters: 10, time: 0.109, data: 0.219) G_GAN: 0.726 G_L1: 8.033 D_real: 0.639 D_fake: 0.343 \n",
            "End of epoch 144 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001089\n",
            "End of epoch 145 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001069\n",
            "End of epoch 146 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001050\n",
            "(epoch: 147, iters: 20, time: 0.521, data: 0.001) G_GAN: 1.120 G_L1: 11.608 D_real: 0.827 D_fake: 0.308 \n",
            "End of epoch 147 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001030\n",
            "End of epoch 148 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001010\n",
            "End of epoch 149 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000990\n",
            "(epoch: 150, iters: 30, time: 0.111, data: 0.001) G_GAN: 1.254 G_L1: 11.265 D_real: 0.334 D_fake: 0.454 \n",
            "End of epoch 150 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000970\n",
            "End of epoch 151 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000950\n",
            "End of epoch 152 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000931\n",
            "End of epoch 153 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000911\n",
            "(epoch: 154, iters: 10, time: 0.109, data: 0.235) G_GAN: 0.908 G_L1: 11.982 D_real: 0.525 D_fake: 0.525 \n",
            "End of epoch 154 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000891\n",
            "End of epoch 155 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000871\n",
            "End of epoch 156 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000851\n",
            "(epoch: 157, iters: 20, time: 0.108, data: 0.001) G_GAN: 0.708 G_L1: 10.731 D_real: 0.301 D_fake: 0.574 \n",
            "End of epoch 157 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000832\n",
            "End of epoch 158 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000812\n",
            "End of epoch 159 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000792\n",
            "(epoch: 160, iters: 30, time: 0.553, data: 0.002) G_GAN: 0.924 G_L1: 10.839 D_real: 0.479 D_fake: 0.416 \n",
            "End of epoch 160 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000772\n",
            "End of epoch 161 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000752\n",
            "End of epoch 162 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000733\n",
            "End of epoch 163 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000713\n",
            "(epoch: 164, iters: 10, time: 0.108, data: 0.220) G_GAN: 1.261 G_L1: 20.478 D_real: 0.484 D_fake: 0.130 \n",
            "End of epoch 164 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000693\n",
            "End of epoch 165 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000673\n",
            "End of epoch 166 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000653\n",
            "(epoch: 167, iters: 20, time: 0.109, data: 0.001) G_GAN: 1.083 G_L1: 8.395 D_real: 0.707 D_fake: 0.380 \n",
            "saving the latest model (epoch 167, total_steps 5000)\n",
            "End of epoch 167 / 200 \t Time Taken: 3 sec\n",
            "learning rate = 0.0000634\n",
            "End of epoch 168 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000614\n",
            "End of epoch 169 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000594\n",
            "(epoch: 170, iters: 30, time: 0.112, data: 0.002) G_GAN: 0.819 G_L1: 5.147 D_real: 0.827 D_fake: 0.539 \n",
            "End of epoch 170 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000574\n",
            "End of epoch 171 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000554\n",
            "End of epoch 172 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000535\n",
            "End of epoch 173 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000515\n",
            "(epoch: 174, iters: 10, time: 0.593, data: 0.206) G_GAN: 0.921 G_L1: 15.157 D_real: 0.428 D_fake: 0.593 \n",
            "End of epoch 174 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000495\n",
            "End of epoch 175 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000475\n",
            "End of epoch 176 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000455\n",
            "(epoch: 177, iters: 20, time: 0.108, data: 0.001) G_GAN: 1.292 G_L1: 15.103 D_real: 0.061 D_fake: 0.570 \n",
            "End of epoch 177 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000436\n",
            "End of epoch 178 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000416\n",
            "End of epoch 179 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000396\n",
            "(epoch: 180, iters: 30, time: 0.112, data: 0.001) G_GAN: 1.201 G_L1: 7.875 D_real: 0.735 D_fake: 0.405 \n",
            "End of epoch 180 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000376\n",
            "End of epoch 181 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000356\n",
            "End of epoch 182 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000337\n",
            "End of epoch 183 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000317\n",
            "(epoch: 184, iters: 10, time: 0.107, data: 0.256) G_GAN: 1.127 G_L1: 14.444 D_real: 0.594 D_fake: 0.448 \n",
            "End of epoch 184 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000297\n",
            "End of epoch 185 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000277\n",
            "End of epoch 186 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000257\n",
            "(epoch: 187, iters: 20, time: 0.681, data: 0.002) G_GAN: 0.996 G_L1: 5.527 D_real: 0.843 D_fake: 0.466 \n",
            "End of epoch 187 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000238\n",
            "End of epoch 188 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000218\n",
            "End of epoch 189 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000198\n",
            "(epoch: 190, iters: 30, time: 0.111, data: 0.002) G_GAN: 0.928 G_L1: 9.558 D_real: 0.610 D_fake: 0.441 \n",
            "End of epoch 190 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000178\n",
            "End of epoch 191 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000158\n",
            "End of epoch 192 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000139\n",
            "End of epoch 193 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000119\n",
            "(epoch: 194, iters: 10, time: 0.109, data: 0.232) G_GAN: 1.139 G_L1: 9.639 D_real: 0.390 D_fake: 0.432 \n",
            "End of epoch 194 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000099\n",
            "End of epoch 195 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000079\n",
            "End of epoch 196 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000059\n",
            "(epoch: 197, iters: 20, time: 0.109, data: 0.001) G_GAN: 0.972 G_L1: 8.856 D_real: 0.427 D_fake: 0.586 \n",
            "End of epoch 197 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000040\n",
            "End of epoch 198 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000020\n",
            "End of epoch 199 / 200 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000000\n",
            "(epoch: 200, iters: 30, time: 0.661, data: 0.001) G_GAN: 1.397 G_L1: 15.896 D_real: 0.338 D_fake: 0.503 \n",
            "saving the model at the end of epoch 200, iters 6000\n",
            "End of epoch 200 / 200 \t Time Taken: 4 sec\n",
            "learning rate = -0.0000020\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14YHjPIWetAx",
        "outputId": "b7d93c69-43f1-4357-bf4a-bc6c0bf1b0ca"
      },
      "source": [
        "!python train.py --dataroot \"../cycleGanData/train\" --name CASE4  \\\n",
        "  --gpu_ids 0 --display_id 0 \\\n",
        "  --niter 100 --niter_decay 100 \\\n",
        "  --pool_size 64 --loadSize 256 --fineSize 256\\\n",
        "  --model \"cycle_gan\" --dataset_mode \"unaligned\" --which_direction \"AtoB\"\\\n",
        "  --init_type \"xavier\"\\\n",
        "  --save_epoch_freq 100"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------- Options ---------------\n",
            "                batchSize: 1                             \n",
            "                    beta1: 0.5                           \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "           continue_train: False                         \n",
            "                 dataroot: ../cycleGanData/train         \t[default: None]\n",
            "             dataset_mode: unaligned                     \t[default: aligned]\n",
            "             display_freq: 400                           \n",
            "               display_id: 0                             \t[default: 1]\n",
            "            display_ncols: 4                             \n",
            "             display_port: 8097                          \n",
            "           display_server: http://localhost              \n",
            "          display_winsize: 256                           \n",
            "              epoch_count: 1                             \n",
            "                 fineSize: 256                           \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: xavier                        \t[default: normal]\n",
            "                 input_nc: 3                             \n",
            "                  isTrain: True                          \t[default: None]\n",
            "                 lambda_A: 10.0                          \n",
            "                 lambda_B: 10.0                          \n",
            "          lambda_identity: 0.5                           \n",
            "                 loadSize: 256                           \t[default: 286]\n",
            "                       lr: 0.0002                        \n",
            "           lr_decay_iters: 50                            \n",
            "                lr_policy: lambda                        \n",
            "         max_dataset_size: inf                           \n",
            "                    model: cycle_gan                     \t[default: pix2pix]\n",
            "                 nThreads: 4                             \n",
            "               n_layers_D: 3                             \n",
            "                     name: CASE4                         \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                      ngf: 64                            \n",
            "                    niter: 100                           \n",
            "              niter_decay: 100                           \n",
            "               no_dropout: True                          \n",
            "                  no_flip: False                         \n",
            "                  no_html: False                         \n",
            "                 no_lsgan: False                         \n",
            "                     norm: instance                      \n",
            "                output_nc: 3                             \n",
            "                    phase: train                         \n",
            "                pool_size: 64                            \t[default: 50]\n",
            "               print_freq: 100                           \n",
            "           resize_or_crop: resize_and_crop               \n",
            "          save_epoch_freq: 100                           \t[default: 5]\n",
            "         save_latest_freq: 5000                          \n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "         update_html_freq: 1000                          \n",
            "                  verbose: False                         \n",
            "          which_direction: AtoB                          \n",
            "              which_epoch: latest                        \n",
            "         which_model_netD: basic                         \n",
            "         which_model_netG: unet_256                      \n",
            "----------------- End -------------------\n",
            "dataset [UnalignedDataset] was created\n",
            "#training images = 30\n",
            "initialize network with xavier\n",
            "initialize network with xavier\n",
            "initialize network with xavier\n",
            "initialize network with xavier\n",
            "model [CycleGANModel] was created\n",
            "---------- Networks initialized -------------\n",
            "[Network G_A] Total number of parameters : 54.414 M\n",
            "[Network G_B] Total number of parameters : 54.414 M\n",
            "[Network D_A] Total number of parameters : 2.764 M\n",
            "[Network D_B] Total number of parameters : 2.764 M\n",
            "-----------------------------------------------\n",
            "create web directory ./checkpoints/CASE4/web...\n",
            "End of epoch 1 / 200 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 2 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 3 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 4, iters: 10, time: 0.278, data: 0.253) D_A: 0.066 G_A: 0.355 cycle_A: 1.884 idt_A: 1.043 D_B: 0.016 G_B: 0.297 cycle_B: 2.618 idt_B: 1.284 \n",
            "End of epoch 4 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 5 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 6 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 7, iters: 20, time: 0.279, data: 0.001) D_A: 0.088 G_A: 0.697 cycle_A: 1.893 idt_A: 1.368 D_B: 0.436 G_B: 0.494 cycle_B: 2.731 idt_B: 1.113 \n",
            "End of epoch 7 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 8 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 9 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 10, iters: 30, time: 0.280, data: 0.001) D_A: 0.155 G_A: 0.969 cycle_A: 1.983 idt_A: 1.084 D_B: 0.049 G_B: 0.483 cycle_B: 2.009 idt_B: 0.793 \n",
            "End of epoch 10 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 11 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 12 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 13 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 14, iters: 10, time: 0.493, data: 0.231) D_A: 0.058 G_A: 0.307 cycle_A: 1.582 idt_A: 0.889 D_B: 0.131 G_B: 0.923 cycle_B: 1.577 idt_B: 0.706 \n",
            "End of epoch 14 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 15 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 16 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 17, iters: 20, time: 0.280, data: 0.001) D_A: 0.124 G_A: 0.340 cycle_A: 1.729 idt_A: 1.277 D_B: 0.078 G_B: 0.604 cycle_B: 2.275 idt_B: 0.688 \n",
            "End of epoch 17 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 18 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 19 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 20, iters: 30, time: 0.280, data: 0.001) D_A: 0.023 G_A: 1.004 cycle_A: 1.444 idt_A: 1.065 D_B: 0.167 G_B: 0.576 cycle_B: 1.805 idt_B: 0.613 \n",
            "End of epoch 20 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 21 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 22 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 23 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 24, iters: 10, time: 0.277, data: 0.189) D_A: 0.136 G_A: 0.297 cycle_A: 1.753 idt_A: 1.141 D_B: 0.250 G_B: 0.376 cycle_B: 2.100 idt_B: 0.606 \n",
            "End of epoch 24 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 25 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 26 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 27, iters: 20, time: 0.582, data: 0.001) D_A: 0.043 G_A: 0.892 cycle_A: 1.369 idt_A: 1.360 D_B: 0.120 G_B: 0.486 cycle_B: 2.809 idt_B: 0.617 \n",
            "End of epoch 27 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 28 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 29 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 30, iters: 30, time: 0.280, data: 0.001) D_A: 0.056 G_A: 0.566 cycle_A: 1.376 idt_A: 0.349 D_B: 0.233 G_B: 0.206 cycle_B: 0.933 idt_B: 0.637 \n",
            "End of epoch 30 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 31 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 32 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 33 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 34, iters: 10, time: 0.281, data: 0.217) D_A: 0.057 G_A: 0.501 cycle_A: 1.704 idt_A: 0.398 D_B: 0.318 G_B: 0.585 cycle_B: 0.960 idt_B: 0.639 \n",
            "End of epoch 34 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 35 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 36 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 37, iters: 20, time: 0.279, data: 0.001) D_A: 0.007 G_A: 0.589 cycle_A: 1.320 idt_A: 0.284 D_B: 0.166 G_B: 0.467 cycle_B: 0.667 idt_B: 0.487 \n",
            "End of epoch 37 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 38 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 39 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 40, iters: 30, time: 0.671, data: 0.001) D_A: 0.010 G_A: 0.613 cycle_A: 1.480 idt_A: 0.300 D_B: 0.225 G_B: 0.473 cycle_B: 0.735 idt_B: 0.530 \n",
            "End of epoch 40 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 41 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 42 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 43 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 44, iters: 10, time: 0.280, data: 0.199) D_A: 0.008 G_A: 0.896 cycle_A: 1.864 idt_A: 0.254 D_B: 0.139 G_B: 0.381 cycle_B: 0.583 idt_B: 0.650 \n",
            "End of epoch 44 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 45 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 46 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 47, iters: 20, time: 0.279, data: 0.001) D_A: 0.156 G_A: 0.223 cycle_A: 1.777 idt_A: 0.354 D_B: 0.303 G_B: 0.545 cycle_B: 0.835 idt_B: 0.547 \n",
            "End of epoch 47 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 48 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 49 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 50, iters: 30, time: 0.282, data: 0.002) D_A: 0.055 G_A: 0.633 cycle_A: 1.506 idt_A: 0.255 D_B: 0.321 G_B: 0.626 cycle_B: 0.631 idt_B: 0.559 \n",
            "End of epoch 50 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 51 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 52 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 53 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 54, iters: 10, time: 0.742, data: 0.230) D_A: 0.060 G_A: 0.643 cycle_A: 1.352 idt_A: 0.302 D_B: 0.297 G_B: 0.388 cycle_B: 0.684 idt_B: 0.471 \n",
            "End of epoch 54 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 55 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 56 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 57, iters: 20, time: 0.278, data: 0.001) D_A: 0.079 G_A: 0.423 cycle_A: 1.744 idt_A: 0.344 D_B: 0.156 G_B: 0.376 cycle_B: 0.779 idt_B: 0.755 \n",
            "End of epoch 57 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 58 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 59 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 60, iters: 30, time: 0.282, data: 0.001) D_A: 0.028 G_A: 0.185 cycle_A: 1.466 idt_A: 0.350 D_B: 0.226 G_B: 0.350 cycle_B: 0.797 idt_B: 0.376 \n",
            "End of epoch 60 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 61 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 62 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 63 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 64, iters: 10, time: 0.279, data: 0.217) D_A: 0.087 G_A: 0.483 cycle_A: 1.219 idt_A: 0.320 D_B: 0.224 G_B: 0.509 cycle_B: 0.732 idt_B: 0.358 \n",
            "End of epoch 64 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 65 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 66 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 67, iters: 20, time: 0.835, data: 0.001) D_A: 0.105 G_A: 0.534 cycle_A: 1.680 idt_A: 0.176 D_B: 0.080 G_B: 0.405 cycle_B: 0.363 idt_B: 0.595 \n",
            "End of epoch 67 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 68 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 69 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 70, iters: 30, time: 0.282, data: 0.001) D_A: 0.039 G_A: 0.535 cycle_A: 1.565 idt_A: 0.262 D_B: 0.147 G_B: 0.347 cycle_B: 0.556 idt_B: 0.516 \n",
            "End of epoch 70 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 71 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 72 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 73 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 74, iters: 10, time: 0.280, data: 0.199) D_A: 0.098 G_A: 0.352 cycle_A: 1.683 idt_A: 0.266 D_B: 0.223 G_B: 0.380 cycle_B: 0.604 idt_B: 0.581 \n",
            "End of epoch 74 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 75 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 76 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 77, iters: 20, time: 0.277, data: 0.001) D_A: 0.074 G_A: 0.634 cycle_A: 1.267 idt_A: 0.159 D_B: 0.112 G_B: 0.390 cycle_B: 0.389 idt_B: 0.459 \n",
            "End of epoch 77 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 78 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 79 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 80, iters: 30, time: 0.979, data: 0.001) D_A: 0.025 G_A: 0.394 cycle_A: 1.170 idt_A: 0.227 D_B: 0.140 G_B: 0.352 cycle_B: 0.512 idt_B: 0.442 \n",
            "End of epoch 80 / 200 \t Time Taken: 8 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 81 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 82 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 83 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 84, iters: 10, time: 0.279, data: 0.199) D_A: 0.014 G_A: 0.752 cycle_A: 1.459 idt_A: 0.179 D_B: 0.405 G_B: 0.276 cycle_B: 0.369 idt_B: 0.520 \n",
            "End of epoch 84 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 85 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 86 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 87, iters: 20, time: 0.279, data: 0.002) D_A: 0.021 G_A: 0.835 cycle_A: 1.485 idt_A: 0.123 D_B: 0.377 G_B: 0.538 cycle_B: 0.248 idt_B: 0.406 \n",
            "End of epoch 87 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 88 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 89 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 90, iters: 30, time: 0.282, data: 0.001) D_A: 0.063 G_A: 0.348 cycle_A: 1.653 idt_A: 0.253 D_B: 0.271 G_B: 0.223 cycle_B: 0.606 idt_B: 0.355 \n",
            "End of epoch 90 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 91 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 92 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 93 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 94, iters: 10, time: 1.023, data: 0.208) D_A: 0.021 G_A: 0.563 cycle_A: 1.423 idt_A: 0.136 D_B: 0.280 G_B: 0.472 cycle_B: 0.282 idt_B: 0.422 \n",
            "End of epoch 94 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 95 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 96 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 97, iters: 20, time: 0.281, data: 0.002) D_A: 0.020 G_A: 0.477 cycle_A: 1.260 idt_A: 0.113 D_B: 0.180 G_B: 0.513 cycle_B: 0.250 idt_B: 0.446 \n",
            "End of epoch 97 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 98 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 99 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001980\n",
            "(epoch: 100, iters: 30, time: 0.279, data: 0.001) D_A: 0.074 G_A: 0.435 cycle_A: 1.444 idt_A: 0.224 D_B: 0.255 G_B: 0.279 cycle_B: 0.485 idt_B: 0.434 \n",
            "saving the model at the end of epoch 100, iters 3000\n",
            "End of epoch 100 / 200 \t Time Taken: 10 sec\n",
            "learning rate = 0.0001960\n",
            "End of epoch 101 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001941\n",
            "End of epoch 102 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001921\n",
            "End of epoch 103 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001901\n",
            "(epoch: 104, iters: 10, time: 0.279, data: 0.238) D_A: 0.036 G_A: 0.587 cycle_A: 1.116 idt_A: 0.207 D_B: 0.105 G_B: 0.367 cycle_B: 0.486 idt_B: 0.380 \n",
            "End of epoch 104 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001881\n",
            "End of epoch 105 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001861\n",
            "End of epoch 106 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001842\n",
            "(epoch: 107, iters: 20, time: 1.120, data: 0.001) D_A: 0.044 G_A: 0.818 cycle_A: 1.155 idt_A: 0.223 D_B: 0.088 G_B: 0.233 cycle_B: 0.542 idt_B: 0.354 \n",
            "End of epoch 107 / 200 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001822\n",
            "End of epoch 108 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001802\n",
            "End of epoch 109 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001782\n",
            "(epoch: 110, iters: 30, time: 0.280, data: 0.002) D_A: 0.027 G_A: 0.621 cycle_A: 1.070 idt_A: 0.188 D_B: 0.231 G_B: 0.328 cycle_B: 0.385 idt_B: 0.262 \n",
            "End of epoch 110 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001762\n",
            "End of epoch 111 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001743\n",
            "End of epoch 112 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001723\n",
            "End of epoch 113 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001703\n",
            "(epoch: 114, iters: 10, time: 0.279, data: 0.220) D_A: 0.158 G_A: 1.048 cycle_A: 1.423 idt_A: 0.197 D_B: 0.259 G_B: 0.270 cycle_B: 0.417 idt_B: 0.385 \n",
            "End of epoch 114 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001683\n",
            "End of epoch 115 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001663\n",
            "End of epoch 116 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001644\n",
            "(epoch: 117, iters: 20, time: 0.280, data: 0.001) D_A: 0.064 G_A: 0.850 cycle_A: 1.155 idt_A: 0.115 D_B: 0.135 G_B: 0.476 cycle_B: 0.261 idt_B: 0.324 \n",
            "End of epoch 117 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001624\n",
            "End of epoch 118 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001604\n",
            "End of epoch 119 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001584\n",
            "(epoch: 120, iters: 30, time: 1.299, data: 0.002) D_A: 0.153 G_A: 0.304 cycle_A: 1.147 idt_A: 0.199 D_B: 0.152 G_B: 0.307 cycle_B: 0.408 idt_B: 0.279 \n",
            "End of epoch 120 / 200 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001564\n",
            "End of epoch 121 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001545\n",
            "End of epoch 122 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001525\n",
            "End of epoch 123 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001505\n",
            "(epoch: 124, iters: 10, time: 0.281, data: 0.216) D_A: 0.176 G_A: 0.221 cycle_A: 1.147 idt_A: 0.118 D_B: 0.169 G_B: 0.317 cycle_B: 0.276 idt_B: 0.289 \n",
            "End of epoch 124 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001485\n",
            "End of epoch 125 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001465\n",
            "End of epoch 126 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001446\n",
            "(epoch: 127, iters: 20, time: 0.278, data: 0.001) D_A: 0.036 G_A: 0.760 cycle_A: 1.607 idt_A: 0.131 D_B: 0.377 G_B: 0.285 cycle_B: 0.263 idt_B: 0.452 \n",
            "End of epoch 127 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001426\n",
            "End of epoch 128 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001406\n",
            "End of epoch 129 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001386\n",
            "(epoch: 130, iters: 30, time: 0.281, data: 0.002) D_A: 0.050 G_A: 0.595 cycle_A: 1.166 idt_A: 0.183 D_B: 0.265 G_B: 0.200 cycle_B: 0.369 idt_B: 0.353 \n",
            "End of epoch 130 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001366\n",
            "End of epoch 131 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001347\n",
            "End of epoch 132 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001327\n",
            "End of epoch 133 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001307\n",
            "(epoch: 134, iters: 10, time: 1.291, data: 0.229) D_A: 0.044 G_A: 0.814 cycle_A: 1.164 idt_A: 0.208 D_B: 0.241 G_B: 0.257 cycle_B: 0.428 idt_B: 0.334 \n",
            "End of epoch 134 / 200 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001287\n",
            "End of epoch 135 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001267\n",
            "End of epoch 136 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001248\n",
            "(epoch: 137, iters: 20, time: 0.280, data: 0.001) D_A: 0.033 G_A: 0.629 cycle_A: 1.761 idt_A: 0.107 D_B: 0.116 G_B: 0.354 cycle_B: 0.228 idt_B: 0.476 \n",
            "End of epoch 137 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001228\n",
            "End of epoch 138 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001208\n",
            "End of epoch 139 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001188\n",
            "(epoch: 140, iters: 30, time: 0.282, data: 0.001) D_A: 0.145 G_A: 1.057 cycle_A: 1.125 idt_A: 0.188 D_B: 0.237 G_B: 0.244 cycle_B: 0.379 idt_B: 0.278 \n",
            "End of epoch 140 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001168\n",
            "End of epoch 141 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001149\n",
            "End of epoch 142 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001129\n",
            "End of epoch 143 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001109\n",
            "(epoch: 144, iters: 10, time: 0.280, data: 0.227) D_A: 0.073 G_A: 0.522 cycle_A: 1.598 idt_A: 0.205 D_B: 0.148 G_B: 0.298 cycle_B: 0.407 idt_B: 0.396 \n",
            "End of epoch 144 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001089\n",
            "End of epoch 145 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001069\n",
            "End of epoch 146 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001050\n",
            "(epoch: 147, iters: 20, time: 1.436, data: 0.001) D_A: 0.016 G_A: 0.892 cycle_A: 1.101 idt_A: 0.148 D_B: 0.148 G_B: 0.325 cycle_B: 0.300 idt_B: 0.311 \n",
            "End of epoch 147 / 200 \t Time Taken: 8 sec\n",
            "learning rate = 0.0001030\n",
            "End of epoch 148 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0001010\n",
            "End of epoch 149 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000990\n",
            "(epoch: 150, iters: 30, time: 0.280, data: 0.002) D_A: 0.041 G_A: 0.880 cycle_A: 1.623 idt_A: 0.122 D_B: 0.136 G_B: 0.262 cycle_B: 0.260 idt_B: 0.408 \n",
            "End of epoch 150 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000970\n",
            "End of epoch 151 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000950\n",
            "End of epoch 152 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000931\n",
            "End of epoch 153 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000911\n",
            "(epoch: 154, iters: 10, time: 0.281, data: 0.211) D_A: 0.040 G_A: 0.540 cycle_A: 1.627 idt_A: 0.204 D_B: 0.229 G_B: 0.228 cycle_B: 0.462 idt_B: 0.452 \n",
            "End of epoch 154 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000891\n",
            "End of epoch 155 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000871\n",
            "End of epoch 156 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000851\n",
            "(epoch: 157, iters: 20, time: 0.279, data: 0.001) D_A: 0.093 G_A: 0.620 cycle_A: 1.593 idt_A: 0.121 D_B: 0.312 G_B: 0.331 cycle_B: 0.247 idt_B: 0.409 \n",
            "End of epoch 157 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000832\n",
            "End of epoch 158 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000812\n",
            "End of epoch 159 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000792\n",
            "(epoch: 160, iters: 30, time: 1.468, data: 0.001) D_A: 0.066 G_A: 0.518 cycle_A: 1.200 idt_A: 0.183 D_B: 0.266 G_B: 0.268 cycle_B: 0.351 idt_B: 0.305 \n",
            "End of epoch 160 / 200 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000772\n",
            "End of epoch 161 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000752\n",
            "End of epoch 162 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000733\n",
            "End of epoch 163 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000713\n",
            "(epoch: 164, iters: 10, time: 0.280, data: 0.209) D_A: 0.149 G_A: 0.294 cycle_A: 1.278 idt_A: 0.183 D_B: 0.274 G_B: 0.319 cycle_B: 0.369 idt_B: 0.318 \n",
            "End of epoch 164 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000693\n",
            "End of epoch 165 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000673\n",
            "End of epoch 166 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000653\n",
            "(epoch: 167, iters: 20, time: 0.279, data: 0.002) D_A: 0.106 G_A: 0.068 cycle_A: 1.179 idt_A: 0.143 D_B: 0.346 G_B: 0.307 cycle_B: 0.270 idt_B: 0.275 \n",
            "saving the latest model (epoch 167, total_steps 5000)\n",
            "End of epoch 167 / 200 \t Time Taken: 9 sec\n",
            "learning rate = 0.0000634\n",
            "End of epoch 168 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000614\n",
            "End of epoch 169 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000594\n",
            "(epoch: 170, iters: 30, time: 0.282, data: 0.002) D_A: 0.084 G_A: 0.429 cycle_A: 1.023 idt_A: 0.125 D_B: 0.164 G_B: 0.348 cycle_B: 0.243 idt_B: 0.264 \n",
            "End of epoch 170 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000574\n",
            "End of epoch 171 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000554\n",
            "End of epoch 172 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000535\n",
            "End of epoch 173 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000515\n",
            "(epoch: 174, iters: 10, time: 1.621, data: 0.225) D_A: 0.252 G_A: 0.590 cycle_A: 1.175 idt_A: 0.253 D_B: 0.331 G_B: 0.151 cycle_B: 0.503 idt_B: 0.310 \n",
            "End of epoch 174 / 200 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000495\n",
            "End of epoch 175 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000475\n",
            "End of epoch 176 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000455\n",
            "(epoch: 177, iters: 20, time: 0.278, data: 0.001) D_A: 0.066 G_A: 0.479 cycle_A: 1.449 idt_A: 0.182 D_B: 0.148 G_B: 0.212 cycle_B: 0.351 idt_B: 0.352 \n",
            "End of epoch 177 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000436\n",
            "End of epoch 178 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000416\n",
            "End of epoch 179 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000396\n",
            "(epoch: 180, iters: 30, time: 0.281, data: 0.001) D_A: 0.114 G_A: 0.614 cycle_A: 0.830 idt_A: 0.322 D_B: 0.206 G_B: 0.273 cycle_B: 0.532 idt_B: 0.193 \n",
            "End of epoch 180 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000376\n",
            "End of epoch 181 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000356\n",
            "End of epoch 182 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000337\n",
            "End of epoch 183 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000317\n",
            "(epoch: 184, iters: 10, time: 0.279, data: 0.228) D_A: 0.070 G_A: 0.527 cycle_A: 0.870 idt_A: 0.180 D_B: 0.252 G_B: 0.260 cycle_B: 0.343 idt_B: 0.197 \n",
            "End of epoch 184 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000297\n",
            "End of epoch 185 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000277\n",
            "End of epoch 186 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000257\n",
            "(epoch: 187, iters: 20, time: 1.634, data: 0.001) D_A: 0.092 G_A: 0.479 cycle_A: 1.416 idt_A: 0.105 D_B: 0.096 G_B: 0.339 cycle_B: 0.196 idt_B: 0.340 \n",
            "End of epoch 187 / 200 \t Time Taken: 8 sec\n",
            "learning rate = 0.0000238\n",
            "End of epoch 188 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000218\n",
            "End of epoch 189 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000198\n",
            "(epoch: 190, iters: 30, time: 0.281, data: 0.001) D_A: 0.078 G_A: 0.483 cycle_A: 1.145 idt_A: 0.141 D_B: 0.209 G_B: 0.271 cycle_B: 0.263 idt_B: 0.291 \n",
            "End of epoch 190 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000178\n",
            "End of epoch 191 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000158\n",
            "End of epoch 192 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000139\n",
            "End of epoch 193 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000119\n",
            "(epoch: 194, iters: 10, time: 0.278, data: 0.213) D_A: 0.330 G_A: 0.739 cycle_A: 1.011 idt_A: 0.401 D_B: 0.212 G_B: 0.335 cycle_B: 0.617 idt_B: 0.275 \n",
            "End of epoch 194 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000099\n",
            "End of epoch 195 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000079\n",
            "End of epoch 196 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000059\n",
            "(epoch: 197, iters: 20, time: 0.279, data: 0.001) D_A: 0.035 G_A: 0.316 cycle_A: 1.090 idt_A: 0.172 D_B: 0.294 G_B: 0.241 cycle_B: 0.305 idt_B: 0.253 \n",
            "End of epoch 197 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000040\n",
            "End of epoch 198 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000020\n",
            "End of epoch 199 / 200 \t Time Taken: 7 sec\n",
            "learning rate = 0.0000000\n",
            "(epoch: 200, iters: 30, time: 1.753, data: 0.002) D_A: 0.052 G_A: 0.568 cycle_A: 1.296 idt_A: 0.117 D_B: 0.299 G_B: 0.287 cycle_B: 0.200 idt_B: 0.306 \n",
            "saving the model at the end of epoch 200, iters 6000\n",
            "End of epoch 200 / 200 \t Time Taken: 12 sec\n",
            "learning rate = -0.0000020\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qp1wp7o9lhvU",
        "outputId": "2c7625eb-6a03-4238-b568-b0ef3eea3783"
      },
      "source": [
        "!ls checkpoints"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CASE1  CASE2  CASE3  CASE4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xMB8RFnewVz",
        "outputId": "afb8b1ae-e094-4cec-cec8-308a06a90ee5"
      },
      "source": [
        "%cd .."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t287VGa87qBl",
        "outputId": "9e0c7083-866c-46ec-b24a-79a4c8dc35fb"
      },
      "source": [
        "!rsync -r --progress ./NucleiSegmentation ./drive/MyDrive/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sending incremental file list\n",
            "NucleiSegmentation/\n",
            "NucleiSegmentation/README.md\n",
            "\r          3,624 100%    0.00kB/s    0:00:00  \r          3,624 100%    0.00kB/s    0:00:00 (xfr#1, to-chk=505/507)\n",
            "NucleiSegmentation/environment.yml\n",
            "\r            249 100%   30.40kB/s    0:00:00  \r            249 100%   30.40kB/s    0:00:00 (xfr#2, to-chk=504/507)\n",
            "NucleiSegmentation/requirements.txt\n",
            "\r             64 100%    7.81kB/s    0:00:00  \r             64 100%    7.81kB/s    0:00:00 (xfr#3, to-chk=503/507)\n",
            "NucleiSegmentation/test.py\n",
            "\r          1,310 100%  142.14kB/s    0:00:00  \r          1,310 100%  142.14kB/s    0:00:00 (xfr#4, to-chk=502/507)\n",
            "NucleiSegmentation/train.py\n",
            "          2,359 100%  255.97kB/s    0:00:00 (xfr#5, to-chk=501/507)\n",
            "NucleiSegmentation/.git/\n",
            "NucleiSegmentation/.git/HEAD\n",
            "             23 100%    0.06kB/s    0:00:00 (xfr#6, to-chk=491/507)\n",
            "NucleiSegmentation/.git/config\n",
            "            277 100%    0.70kB/s    0:00:00 (xfr#7, to-chk=490/507)\n",
            "NucleiSegmentation/.git/description\n",
            "             73 100%    0.18kB/s    0:00:00 (xfr#8, to-chk=489/507)\n",
            "NucleiSegmentation/.git/index\n",
            "          5,876 100%   14.83kB/s    0:00:00 (xfr#9, to-chk=488/507)\n",
            "NucleiSegmentation/.git/packed-refs\n",
            "            189 100%    0.48kB/s    0:00:00 (xfr#10, to-chk=487/507)\n",
            "NucleiSegmentation/.git/branches/\n",
            "NucleiSegmentation/.git/hooks/\n",
            "NucleiSegmentation/.git/hooks/applypatch-msg.sample\n",
            "            478 100%    1.20kB/s    0:00:00 (xfr#11, to-chk=480/507)\n",
            "NucleiSegmentation/.git/hooks/commit-msg.sample\n",
            "            896 100%    2.25kB/s    0:00:00 (xfr#12, to-chk=479/507)\n",
            "NucleiSegmentation/.git/hooks/fsmonitor-watchman.sample\n",
            "          3,327 100%    8.33kB/s    0:00:00 (xfr#13, to-chk=478/507)\n",
            "NucleiSegmentation/.git/hooks/post-update.sample\n",
            "            189 100%    0.47kB/s    0:00:00 (xfr#14, to-chk=477/507)\n",
            "NucleiSegmentation/.git/hooks/pre-applypatch.sample\n",
            "            424 100%    1.06kB/s    0:00:00 (xfr#15, to-chk=476/507)\n",
            "NucleiSegmentation/.git/hooks/pre-commit.sample\n",
            "          1,642 100%    4.10kB/s    0:00:00 (xfr#16, to-chk=475/507)\n",
            "NucleiSegmentation/.git/hooks/pre-push.sample\n",
            "          1,348 100%    3.36kB/s    0:00:00 (xfr#17, to-chk=474/507)\n",
            "NucleiSegmentation/.git/hooks/pre-rebase.sample\n",
            "          4,898 100%   12.17kB/s    0:00:00 (xfr#18, to-chk=473/507)\n",
            "NucleiSegmentation/.git/hooks/pre-receive.sample\n",
            "            544 100%    1.35kB/s    0:00:00 (xfr#19, to-chk=472/507)\n",
            "NucleiSegmentation/.git/hooks/prepare-commit-msg.sample\n",
            "          1,492 100%    3.70kB/s    0:00:00 (xfr#20, to-chk=471/507)\n",
            "NucleiSegmentation/.git/hooks/update.sample\n",
            "          3,610 100%    8.95kB/s    0:00:00 (xfr#21, to-chk=470/507)\n",
            "NucleiSegmentation/.git/info/\n",
            "NucleiSegmentation/.git/info/exclude\n",
            "            240 100%    0.59kB/s    0:00:00 (xfr#22, to-chk=469/507)\n",
            "NucleiSegmentation/.git/logs/\n",
            "NucleiSegmentation/.git/logs/HEAD\n",
            "            196 100%    0.48kB/s    0:00:00 (xfr#23, to-chk=468/507)\n",
            "NucleiSegmentation/.git/logs/refs/\n",
            "NucleiSegmentation/.git/logs/refs/heads/\n",
            "NucleiSegmentation/.git/logs/refs/heads/master\n",
            "            196 100%    0.48kB/s    0:00:00 (xfr#24, to-chk=464/507)\n",
            "NucleiSegmentation/.git/logs/refs/remotes/\n",
            "NucleiSegmentation/.git/logs/refs/remotes/origin/\n",
            "NucleiSegmentation/.git/logs/refs/remotes/origin/HEAD\n",
            "            196 100%    0.48kB/s    0:00:00 (xfr#25, to-chk=462/507)\n",
            "NucleiSegmentation/.git/objects/\n",
            "NucleiSegmentation/.git/objects/info/\n",
            "NucleiSegmentation/.git/objects/pack/\n",
            "NucleiSegmentation/.git/objects/pack/pack-5ddf7e882ab5b843a8b6371cb21c4917e5c8d0f3.idx\n",
            "          5,216 100%   12.64kB/s    0:00:00 (xfr#26, to-chk=459/507)\n",
            "NucleiSegmentation/.git/objects/pack/pack-5ddf7e882ab5b843a8b6371cb21c4917e5c8d0f3.pack\n",
            "        863,953 100%    1.33MB/s    0:00:00 (xfr#27, to-chk=458/507)\n",
            "NucleiSegmentation/.git/refs/\n",
            "NucleiSegmentation/.git/refs/heads/\n",
            "NucleiSegmentation/.git/refs/heads/master\n",
            "             41 100%    0.06kB/s    0:00:00 (xfr#28, to-chk=454/507)\n",
            "NucleiSegmentation/.git/refs/remotes/\n",
            "NucleiSegmentation/.git/refs/remotes/origin/\n",
            "NucleiSegmentation/.git/refs/remotes/origin/HEAD\n",
            "             32 100%    0.05kB/s    0:00:00 (xfr#29, to-chk=452/507)\n",
            "NucleiSegmentation/.git/refs/tags/\n",
            "NucleiSegmentation/checkpoints/\n",
            "NucleiSegmentation/checkpoints/CASE1/\n",
            "NucleiSegmentation/checkpoints/CASE1/100_net_D.pth\n",
            "     22,144,558 100%   16.72MB/s    0:00:01 (xfr#30, to-chk=447/507)\n",
            "NucleiSegmentation/checkpoints/CASE1/100_net_G.pth\n",
            "    217,727,013 100%   31.41MB/s    0:00:06 (xfr#31, to-chk=446/507)\n",
            "NucleiSegmentation/checkpoints/CASE1/200_net_D.pth\n",
            "     22,144,552 100%   17.42MB/s    0:00:01 (xfr#32, to-chk=445/507)\n",
            "NucleiSegmentation/checkpoints/CASE1/200_net_G.pth\n",
            "    217,726,891 100%   30.52MB/s    0:00:06 (xfr#33, to-chk=444/507)\n",
            "NucleiSegmentation/checkpoints/CASE1/latest_net_D.pth\n",
            "     22,144,548 100%   14.94MB/s    0:00:01 (xfr#34, to-chk=443/507)\n",
            "NucleiSegmentation/checkpoints/CASE1/latest_net_G.pth\n",
            "    217,726,981 100%   32.41MB/s    0:00:06 (xfr#35, to-chk=442/507)\n",
            "NucleiSegmentation/checkpoints/CASE1/loss_log.txt\n",
            "          6,311 100%   15.00kB/s    0:00:00 (xfr#36, to-chk=441/507)\n",
            "NucleiSegmentation/checkpoints/CASE1/opt.txt\n",
            "          3,271 100%    7.75kB/s    0:00:00 (xfr#37, to-chk=440/507)\n",
            "NucleiSegmentation/checkpoints/CASE1/web/\n",
            "NucleiSegmentation/checkpoints/CASE1/web/index.html\n",
            "        194,247 100%  440.13kB/s    0:00:00 (xfr#38, to-chk=438/507)\n",
            "NucleiSegmentation/checkpoints/CASE1/web/images/\n",
            "NucleiSegmentation/checkpoints/CASE1/web/images/epoch014_fake_B.png\n",
            "         93,288 100%  208.95kB/s    0:00:00 (xfr#39, to-chk=436/507)\n",
            "NucleiSegmentation/checkpoints/CASE1/web/images/epoch014_real_A.png\n",
            "        180,392 100%  394.10kB/s    0:00:00 (xfr#40, to-chk=435/507)\n",
            "NucleiSegmentation/checkpoints/CASE1/web/images/epoch014_real_B.png\n",
            "         30,752 100%   67.18kB/s    0:00:00 (xfr#41, to-chk=434/507)\n",
            "NucleiSegmentation/checkpoints/CASE1/web/images/epoch027_fake_B.png\n",
            "         91,532 100%  198.20kB/s    0:00:00 (xfr#42, to-chk=433/507)\n",
            "NucleiSegmentation/checkpoints/CASE1/web/images/epoch027_real_A.png\n",
            "        168,847 100%  356.13kB/s    0:00:00 (xfr#43, to-chk=432/507)\n",
            "NucleiSegmentation/checkpoints/CASE1/web/images/epoch027_real_B.png\n",
            "         21,489 100%   45.32kB/s    0:00:00 (xfr#44, to-chk=431/507)\n",
            "NucleiSegmentation/checkpoints/CASE1/web/images/epoch040_fake_B.png\n",
            "         74,851 100%  156.86kB/s    0:00:00 (xfr#45, to-chk=430/507)\n",
            "NucleiSegmentation/checkpoints/CASE1/web/images/epoch040_real_A.png\n",
            "        163,538 100%  332.03kB/s    0:00:00 (xfr#46, to-chk=429/507)\n",
            "NucleiSegmentation/checkpoints/CASE1/web/images/epoch040_real_B.png\n",
            "         17,964 100%   36.47kB/s    0:00:00 (xfr#47, to-chk=428/507)\n",
            "NucleiSegmentation/checkpoints/CASE1/web/images/epoch054_fake_B.png\n",
            "         84,710 100%  171.63kB/s    0:00:00 (xfr#48, to-chk=427/507)\n",
            "NucleiSegmentation/checkpoints/CASE1/web/images/epoch054_real_A.png\n",
            "        149,844 100%  264.61kB/s    0:00:00 (xfr#49, to-chk=426/507)\n",
            "NucleiSegmentation/checkpoints/CASE1/web/images/epoch054_real_B.png\n",
            "         24,798 100%   43.79kB/s    0:00:00 (xfr#50, to-chk=425/507)\n",
            "NucleiSegmentation/checkpoints/CASE1/web/images/epoch067_fake_B.png\n",
            "         42,972 100%   75.75kB/s    0:00:00 (xfr#51, to-chk=424/507)\n",
            "NucleiSegmentation/checkpoints/CASE1/web/images/epoch067_real_A.png\n",
            "        166,965 100%  287.06kB/s    0:00:00 (xfr#52, to-chk=423/507)\n",
            "NucleiSegmentation/checkpoints/CASE1/web/images/epoch067_real_B.png\n",
            "         15,725 100%   27.04kB/s    0:00:00 (xfr#53, to-chk=422/507)\n",
            "NucleiSegmentation/checkpoints/CASE1/web/images/epoch080_fake_B.png\n",
            "         93,950 100%  160.68kB/s    0:00:00 (xfr#54, to-chk=421/507)\n",
            "NucleiSegmentation/checkpoints/CASE1/web/images/epoch080_real_A.png\n",
            "        173,134 100%  288.53kB/s    0:00:00 (xfr#55, to-chk=420/507)\n",
            "NucleiSegmentation/checkpoints/CASE1/web/images/epoch080_real_B.png\n",
            "         35,938 100%   59.79kB/s    0:00:00 (xfr#56, to-chk=419/507)\n",
            "NucleiSegmentation/checkpoints/CASE1/web/images/epoch094_fake_B.png\n",
            "         52,530 100%   87.09kB/s    0:00:00 (xfr#57, to-chk=418/507)\n",
            "NucleiSegmentation/checkpoints/CASE1/web/images/epoch094_real_A.png\n",
            "        150,127 100%  243.54kB/s    0:00:00 (xfr#58, to-chk=417/507)\n",
            "NucleiSegmentation/checkpoints/CASE1/web/images/epoch094_real_B.png\n",
            "         24,853 100%   40.32kB/s    0:00:00 (xfr#59, to-chk=416/507)\n",
            "NucleiSegmentation/checkpoints/CASE1/web/images/epoch107_fake_B.png\n",
            "         49,122 100%   79.55kB/s    0:00:00 (xfr#60, to-chk=415/507)\n",
            "NucleiSegmentation/checkpoints/CASE1/web/images/epoch107_real_A.png\n",
            "        171,939 100%  272.14kB/s    0:00:00 (xfr#61, to-chk=414/507)\n",
            "NucleiSegmentation/checkpoints/CASE1/web/images/epoch107_real_B.png\n",
            "         25,526 100%   40.40kB/s    0:00:00 (xfr#62, to-chk=413/507)\n",
            "NucleiSegmentation/checkpoints/CASE1/web/images/epoch120_fake_B.png\n",
            "         40,998 100%   64.78kB/s    0:00:00 (xfr#63, to-chk=412/507)\n",
            "NucleiSegmentation/checkpoints/CASE1/web/images/epoch120_real_A.png\n",
            "        165,442 100%  221.62kB/s    0:00:00 (xfr#64, to-chk=411/507)\n",
            "NucleiSegmentation/checkpoints/CASE1/web/images/epoch120_real_B.png\n",
            "         25,467 100%   34.12kB/s    0:00:00 (xfr#65, to-chk=410/507)\n",
            "NucleiSegmentation/checkpoints/CASE1/web/images/epoch134_fake_B.png\n",
            "         44,578 100%   59.55kB/s    0:00:00 (xfr#66, to-chk=409/507)\n",
            "NucleiSegmentation/checkpoints/CASE1/web/images/epoch134_real_A.png\n",
            "        172,559 100%  225.89kB/s    0:00:00 (xfr#67, to-chk=408/507)\n",
            "NucleiSegmentation/checkpoints/CASE1/web/images/epoch134_real_B.png\n",
            "         27,424 100%   35.85kB/s    0:00:00 (xfr#68, to-chk=407/507)\n",
            "NucleiSegmentation/checkpoints/CASE1/web/images/epoch147_fake_B.png\n",
            "         37,510 100%   48.97kB/s    0:00:00 (xfr#69, to-chk=406/507)\n",
            "NucleiSegmentation/checkpoints/CASE1/web/images/epoch147_real_A.png\n",
            "        169,652 100%  217.14kB/s    0:00:00 (xfr#70, to-chk=405/507)\n",
            "NucleiSegmentation/checkpoints/CASE1/web/images/epoch147_real_B.png\n",
            "         24,937 100%   31.92kB/s    0:00:00 (xfr#71, to-chk=404/507)\n",
            "NucleiSegmentation/checkpoints/CASE1/web/images/epoch160_fake_B.png\n",
            "         24,412 100%   31.12kB/s    0:00:00 (xfr#72, to-chk=403/507)\n",
            "NucleiSegmentation/checkpoints/CASE1/web/images/epoch160_real_A.png\n",
            "        170,148 100%  213.03kB/s    0:00:00 (xfr#73, to-chk=402/507)\n",
            "NucleiSegmentation/checkpoints/CASE1/web/images/epoch160_real_B.png\n",
            "         17,116 100%   21.40kB/s    0:00:00 (xfr#74, to-chk=401/507)\n",
            "NucleiSegmentation/checkpoints/CASE1/web/images/epoch174_fake_B.png\n",
            "         22,995 100%   28.75kB/s    0:00:00 (xfr#75, to-chk=400/507)\n",
            "NucleiSegmentation/checkpoints/CASE1/web/images/epoch174_real_A.png\n",
            "        169,503 100%  207.95kB/s    0:00:00 (xfr#76, to-chk=399/507)\n",
            "NucleiSegmentation/checkpoints/CASE1/web/images/epoch174_real_B.png\n",
            "         16,799 100%   20.61kB/s    0:00:00 (xfr#77, to-chk=398/507)\n",
            "NucleiSegmentation/checkpoints/CASE1/web/images/epoch187_fake_B.png\n",
            "         24,056 100%   29.48kB/s    0:00:00 (xfr#78, to-chk=397/507)\n",
            "NucleiSegmentation/checkpoints/CASE1/web/images/epoch187_real_A.png\n",
            "        165,019 100%  175.55kB/s    0:00:00 (xfr#79, to-chk=396/507)\n",
            "NucleiSegmentation/checkpoints/CASE1/web/images/epoch187_real_B.png\n",
            "         17,736 100%   18.87kB/s    0:00:00 (xfr#80, to-chk=395/507)\n",
            "NucleiSegmentation/checkpoints/CASE1/web/images/epoch200_fake_B.png\n",
            "         25,236 100%   26.85kB/s    0:00:00 (xfr#81, to-chk=394/507)\n",
            "NucleiSegmentation/checkpoints/CASE1/web/images/epoch200_real_A.png\n",
            "        163,187 100%  170.44kB/s    0:00:00 (xfr#82, to-chk=393/507)\n",
            "NucleiSegmentation/checkpoints/CASE1/web/images/epoch200_real_B.png\n",
            "         17,933 100%   18.73kB/s    0:00:00 (xfr#83, to-chk=392/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/\n",
            "NucleiSegmentation/checkpoints/CASE2/100_net_D_A.pth\n",
            "     22,119,995 100%   13.99MB/s    0:00:01 (xfr#84, to-chk=391/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/100_net_D_B.pth\n",
            "     22,119,994 100%   15.35MB/s    0:00:01 (xfr#85, to-chk=390/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/100_net_G_A.pth\n",
            "    217,726,832 100%   32.58MB/s    0:00:06 (xfr#86, to-chk=389/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/100_net_G_B.pth\n",
            "    217,726,962 100%   28.85MB/s    0:00:07 (xfr#87, to-chk=388/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/200_net_D_A.pth\n",
            "     22,119,988 100%   29.96MB/s    0:00:00 (xfr#88, to-chk=387/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/200_net_D_B.pth\n",
            "     22,119,989 100%   16.14MB/s    0:00:01 (xfr#89, to-chk=386/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/200_net_G_A.pth\n",
            "    217,726,729 100%   29.46MB/s    0:00:07 (xfr#90, to-chk=385/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/200_net_G_B.pth\n",
            "    217,726,876 100%   34.47MB/s    0:00:06 (xfr#91, to-chk=384/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/latest_net_D_A.pth\n",
            "     22,119,990 100%   34.47MB/s    0:00:00 (xfr#92, to-chk=383/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/latest_net_D_B.pth\n",
            "     22,119,987 100%   17.41MB/s    0:00:01 (xfr#93, to-chk=382/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/latest_net_G_A.pth\n",
            "    217,726,817 100%   29.08MB/s    0:00:07 (xfr#94, to-chk=381/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/latest_net_G_B.pth\n",
            "    217,726,871 100%   33.94MB/s    0:00:06 (xfr#95, to-chk=380/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/loss_log.txt\n",
            "          9,104 100%   74.71kB/s    0:00:00 (xfr#96, to-chk=379/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/opt.txt\n",
            "          3,426 100%   27.88kB/s    0:00:00 (xfr#97, to-chk=378/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/\n",
            "NucleiSegmentation/checkpoints/CASE2/web/index.html\n",
            "        477,847 100%    3.02MB/s    0:00:00 (xfr#98, to-chk=376/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch014_fake_A.png\n",
            "        161,078 100%  977.04kB/s    0:00:00 (xfr#99, to-chk=374/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch014_fake_B.png\n",
            "        188,473 100%    1.06MB/s    0:00:00 (xfr#100, to-chk=373/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch014_idt_A.png\n",
            "         62,679 100%  353.81kB/s    0:00:00 (xfr#101, to-chk=372/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch014_idt_B.png\n",
            "        145,671 100%  764.82kB/s    0:00:00 (xfr#102, to-chk=371/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch014_real_A.png\n",
            "        165,442 100%  795.88kB/s    0:00:00 (xfr#103, to-chk=370/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch014_real_B.png\n",
            "         18,389 100%   88.03kB/s    0:00:00 (xfr#104, to-chk=369/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch014_rec_A.png\n",
            "        154,646 100%  626.65kB/s    0:00:00 (xfr#105, to-chk=368/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch014_rec_B.png\n",
            "        134,396 100%  533.52kB/s    0:00:00 (xfr#106, to-chk=367/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch027_fake_A.png\n",
            "        164,296 100%  629.20kB/s    0:00:00 (xfr#107, to-chk=366/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch027_fake_B.png\n",
            "        135,461 100%  501.08kB/s    0:00:00 (xfr#108, to-chk=365/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch027_idt_A.png\n",
            "         55,753 100%  206.24kB/s    0:00:00 (xfr#109, to-chk=364/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch027_idt_B.png\n",
            "        160,207 100%  568.92kB/s    0:00:00 (xfr#110, to-chk=363/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch027_real_A.png\n",
            "        173,985 100%  604.65kB/s    0:00:00 (xfr#111, to-chk=362/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch027_real_B.png\n",
            "         21,737 100%   75.54kB/s    0:00:00 (xfr#112, to-chk=361/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch027_rec_A.png\n",
            "        165,292 100%  552.80kB/s    0:00:00 (xfr#113, to-chk=360/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch027_rec_B.png\n",
            "         71,476 100%  239.04kB/s    0:00:00 (xfr#114, to-chk=359/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch040_fake_A.png\n",
            "        163,475 100%  526.88kB/s    0:00:00 (xfr#115, to-chk=358/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch040_fake_B.png\n",
            "        107,504 100%  345.34kB/s    0:00:00 (xfr#116, to-chk=357/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch040_idt_A.png\n",
            "         31,934 100%  100.92kB/s    0:00:00 (xfr#117, to-chk=356/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch040_idt_B.png\n",
            "        145,744 100%  446.17kB/s    0:00:00 (xfr#118, to-chk=355/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch040_real_A.png\n",
            "        153,941 100%  462.56kB/s    0:00:00 (xfr#119, to-chk=354/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch040_real_B.png\n",
            "         17,933 100%   53.89kB/s    0:00:00 (xfr#120, to-chk=353/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch040_rec_A.png\n",
            "        148,304 100%  314.84kB/s    0:00:00 (xfr#121, to-chk=352/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch040_rec_B.png\n",
            "         66,056 100%  140.23kB/s    0:00:00 (xfr#122, to-chk=351/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch054_fake_A.png\n",
            "        173,345 100%  359.41kB/s    0:00:00 (xfr#123, to-chk=350/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch054_fake_B.png\n",
            "        170,384 100%  348.83kB/s    0:00:00 (xfr#124, to-chk=349/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch054_idt_A.png\n",
            "         85,011 100%  174.04kB/s    0:00:00 (xfr#125, to-chk=348/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch054_idt_B.png\n",
            "        159,449 100%  319.74kB/s    0:00:00 (xfr#126, to-chk=347/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch054_real_A.png\n",
            "        169,652 100%  336.06kB/s    0:00:00 (xfr#127, to-chk=346/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch054_real_B.png\n",
            "         37,270 100%   73.83kB/s    0:00:00 (xfr#128, to-chk=345/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch054_rec_A.png\n",
            "        159,248 100%  308.56kB/s    0:00:00 (xfr#129, to-chk=344/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch054_rec_B.png\n",
            "        107,156 100%  207.22kB/s    0:00:00 (xfr#130, to-chk=343/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch067_fake_A.png\n",
            "        170,865 100%  323.37kB/s    0:00:00 (xfr#131, to-chk=342/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch067_fake_B.png\n",
            "        144,692 100%  271.21kB/s    0:00:00 (xfr#132, to-chk=341/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch067_idt_A.png\n",
            "         37,849 100%   70.81kB/s    0:00:00 (xfr#133, to-chk=340/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch067_idt_B.png\n",
            "        164,004 100%  247.54kB/s    0:00:00 (xfr#134, to-chk=339/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch067_real_A.png\n",
            "        168,977 100%  251.93kB/s    0:00:00 (xfr#135, to-chk=338/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch067_real_B.png\n",
            "         24,912 100%   37.14kB/s    0:00:00 (xfr#136, to-chk=337/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch067_rec_A.png\n",
            "        157,664 100%  231.53kB/s    0:00:00 (xfr#137, to-chk=336/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch067_rec_B.png\n",
            "         50,851 100%   74.56kB/s    0:00:00 (xfr#138, to-chk=335/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch080_fake_A.png\n",
            "        169,709 100%  245.16kB/s    0:00:00 (xfr#139, to-chk=334/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch080_fake_B.png\n",
            "        153,209 100%  219.38kB/s    0:00:00 (xfr#140, to-chk=333/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch080_idt_A.png\n",
            "         34,118 100%   48.85kB/s    0:00:00 (xfr#141, to-chk=332/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch080_idt_B.png\n",
            "        155,902 100%  220.01kB/s    0:00:00 (xfr#142, to-chk=331/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch080_real_A.png\n",
            "        161,842 100%  226.43kB/s    0:00:00 (xfr#143, to-chk=330/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch080_real_B.png\n",
            "         24,104 100%   33.72kB/s    0:00:00 (xfr#144, to-chk=329/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch080_rec_A.png\n",
            "        158,841 100%  219.09kB/s    0:00:00 (xfr#145, to-chk=328/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch080_rec_B.png\n",
            "         52,198 100%   71.90kB/s    0:00:00 (xfr#146, to-chk=327/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch094_fake_A.png\n",
            "        167,814 100%  227.93kB/s    0:00:00 (xfr#147, to-chk=326/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch094_fake_B.png\n",
            "         28,637 100%   38.90kB/s    0:00:00 (xfr#148, to-chk=325/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch094_idt_A.png\n",
            "         32,508 100%   44.09kB/s    0:00:00 (xfr#149, to-chk=324/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch094_idt_B.png\n",
            "        147,822 100%  168.45kB/s    0:00:00 (xfr#150, to-chk=323/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch094_real_A.png\n",
            "        153,827 100%  174.07kB/s    0:00:00 (xfr#151, to-chk=322/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch094_real_B.png\n",
            "         24,119 100%   27.29kB/s    0:00:00 (xfr#152, to-chk=321/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch094_rec_A.png\n",
            "        139,467 100%  155.66kB/s    0:00:00 (xfr#153, to-chk=320/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch094_rec_B.png\n",
            "         54,359 100%   60.67kB/s    0:00:00 (xfr#154, to-chk=319/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch107_fake_A.png\n",
            "        161,918 100%  178.67kB/s    0:00:00 (xfr#155, to-chk=318/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch107_fake_B.png\n",
            "        140,422 100%  153.91kB/s    0:00:00 (xfr#156, to-chk=317/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch107_idt_A.png\n",
            "         22,730 100%   24.91kB/s    0:00:00 (xfr#157, to-chk=316/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch107_idt_B.png\n",
            "        158,720 100%  172.03kB/s    0:00:00 (xfr#158, to-chk=315/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch107_real_A.png\n",
            "        162,188 100%  174.63kB/s    0:00:00 (xfr#159, to-chk=314/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch107_real_B.png\n",
            "         18,300 100%   19.70kB/s    0:00:00 (xfr#160, to-chk=313/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch107_rec_A.png\n",
            "        154,361 100%  164.39kB/s    0:00:00 (xfr#161, to-chk=312/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch107_rec_B.png\n",
            "         38,155 100%   40.59kB/s    0:00:00 (xfr#162, to-chk=311/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch120_fake_A.png\n",
            "        167,014 100%  175.19kB/s    0:00:00 (xfr#163, to-chk=310/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch120_fake_B.png\n",
            "         74,112 100%   77.66kB/s    0:00:00 (xfr#164, to-chk=309/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch120_idt_A.png\n",
            "         32,713 100%   34.20kB/s    0:00:00 (xfr#165, to-chk=308/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch120_idt_B.png\n",
            "        161,358 100%  148.66kB/s    0:00:01 (xfr#166, to-chk=307/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch120_real_A.png\n",
            "        163,996 100%   10.43MB/s    0:00:00 (xfr#167, to-chk=306/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch120_real_B.png\n",
            "         24,937 100%    1.49MB/s    0:00:00 (xfr#168, to-chk=305/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch120_rec_A.png\n",
            "        145,413 100%    5.33MB/s    0:00:00 (xfr#169, to-chk=304/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch120_rec_B.png\n",
            "         51,252 100%    1.88MB/s    0:00:00 (xfr#170, to-chk=303/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch134_fake_A.png\n",
            "        167,169 100%    3.89MB/s    0:00:00 (xfr#171, to-chk=302/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch134_fake_B.png\n",
            "         35,598 100%  847.89kB/s    0:00:00 (xfr#172, to-chk=301/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch134_idt_A.png\n",
            "         39,831 100%  926.13kB/s    0:00:00 (xfr#173, to-chk=300/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch134_idt_B.png\n",
            "        146,169 100%    2.49MB/s    0:00:00 (xfr#174, to-chk=299/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch134_real_A.png\n",
            "        142,540 100%    2.23MB/s    0:00:00 (xfr#175, to-chk=298/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch134_real_B.png\n",
            "         27,424 100%  431.96kB/s    0:00:00 (xfr#176, to-chk=297/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch134_rec_A.png\n",
            "        131,092 100%    1.74MB/s    0:00:00 (xfr#177, to-chk=296/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch134_rec_B.png\n",
            "         57,499 100%  779.88kB/s    0:00:00 (xfr#178, to-chk=295/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch147_fake_A.png\n",
            "        160,462 100%  775.75kB/s    0:00:00 (xfr#179, to-chk=294/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch147_fake_B.png\n",
            "        109,753 100%  527.98kB/s    0:00:00 (xfr#180, to-chk=293/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch147_idt_A.png\n",
            "         22,810 100%  106.58kB/s    0:00:00 (xfr#181, to-chk=292/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch147_idt_B.png\n",
            "        164,509 100%  733.58kB/s    0:00:00 (xfr#182, to-chk=291/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch147_real_A.png\n",
            "        169,239 100%  731.29kB/s    0:00:00 (xfr#183, to-chk=290/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch147_real_B.png\n",
            "         18,300 100%   79.08kB/s    0:00:00 (xfr#184, to-chk=289/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch147_rec_A.png\n",
            "        151,927 100%  628.67kB/s    0:00:00 (xfr#185, to-chk=288/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch147_rec_B.png\n",
            "         33,958 100%  139.92kB/s    0:00:00 (xfr#186, to-chk=287/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch160_fake_A.png\n",
            "        174,242 100%  688.90kB/s    0:00:00 (xfr#187, to-chk=286/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch160_fake_B.png\n",
            "        109,368 100%  427.22kB/s    0:00:00 (xfr#188, to-chk=285/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch160_idt_A.png\n",
            "         68,466 100%  261.18kB/s    0:00:00 (xfr#189, to-chk=284/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch160_idt_B.png\n",
            "        165,770 100%  608.59kB/s    0:00:00 (xfr#190, to-chk=283/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch160_real_A.png\n",
            "        168,809 100%  601.65kB/s    0:00:00 (xfr#191, to-chk=282/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch160_real_B.png\n",
            "         38,782 100%  138.22kB/s    0:00:00 (xfr#192, to-chk=281/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch160_rec_A.png\n",
            "        152,445 100%  524.20kB/s    0:00:00 (xfr#193, to-chk=280/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch160_rec_B.png\n",
            "         83,464 100%  285.99kB/s    0:00:00 (xfr#194, to-chk=279/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch174_fake_A.png\n",
            "        160,588 100%  377.89kB/s    0:00:00 (xfr#195, to-chk=278/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch174_fake_B.png\n",
            "         50,312 100%  117.82kB/s    0:00:00 (xfr#196, to-chk=277/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch174_idt_A.png\n",
            "         22,508 100%   52.46kB/s    0:00:00 (xfr#197, to-chk=276/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch174_idt_B.png\n",
            "        168,944 100%  381.91kB/s    0:00:00 (xfr#198, to-chk=275/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch174_real_A.png\n",
            "        172,770 100%  383.46kB/s    0:00:00 (xfr#199, to-chk=274/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch174_real_B.png\n",
            "         18,389 100%   40.72kB/s    0:00:00 (xfr#200, to-chk=273/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch174_rec_A.png\n",
            "        150,447 100%  325.05kB/s    0:00:00 (xfr#201, to-chk=272/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch174_rec_B.png\n",
            "         32,045 100%   69.23kB/s    0:00:00 (xfr#202, to-chk=271/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch187_fake_A.png\n",
            "        163,771 100%  346.17kB/s    0:00:00 (xfr#203, to-chk=270/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch187_fake_B.png\n",
            "        103,584 100%  218.48kB/s    0:00:00 (xfr#204, to-chk=269/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch187_idt_A.png\n",
            "         26,727 100%   56.37kB/s    0:00:00 (xfr#205, to-chk=268/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch187_idt_B.png\n",
            "        162,100 100%  331.17kB/s    0:00:00 (xfr#206, to-chk=267/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch187_real_A.png\n",
            "        165,628 100%  334.88kB/s    0:00:00 (xfr#207, to-chk=266/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch187_real_B.png\n",
            "         20,733 100%   41.92kB/s    0:00:00 (xfr#208, to-chk=265/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch187_rec_A.png\n",
            "        154,644 100%  248.80kB/s    0:00:00 (xfr#209, to-chk=264/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch187_rec_B.png\n",
            "         38,751 100%   62.24kB/s    0:00:00 (xfr#210, to-chk=263/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch200_fake_A.png\n",
            "        161,863 100%  255.36kB/s    0:00:00 (xfr#211, to-chk=262/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch200_fake_B.png\n",
            "         55,778 100%   88.00kB/s    0:00:00 (xfr#212, to-chk=261/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch200_idt_A.png\n",
            "         26,523 100%   41.78kB/s    0:00:00 (xfr#213, to-chk=260/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch200_idt_B.png\n",
            "        174,698 100%  268.67kB/s    0:00:00 (xfr#214, to-chk=259/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch200_real_A.png\n",
            "        180,447 100%  274.91kB/s    0:00:00 (xfr#215, to-chk=258/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch200_real_B.png\n",
            "         21,018 100%   31.97kB/s    0:00:00 (xfr#216, to-chk=257/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch200_rec_A.png\n",
            "        155,948 100%  233.58kB/s    0:00:00 (xfr#217, to-chk=256/507)\n",
            "NucleiSegmentation/checkpoints/CASE2/web/images/epoch200_rec_B.png\n",
            "         38,527 100%   57.71kB/s    0:00:00 (xfr#218, to-chk=255/507)\n",
            "NucleiSegmentation/checkpoints/CASE3/\n",
            "NucleiSegmentation/checkpoints/CASE3/100_net_D.pth\n",
            "     22,144,569 100%   16.84MB/s    0:00:01 (xfr#219, to-chk=254/507)\n",
            "NucleiSegmentation/checkpoints/CASE3/100_net_G.pth\n",
            "    217,727,102 100%   31.11MB/s    0:00:06 (xfr#220, to-chk=253/507)\n",
            "NucleiSegmentation/checkpoints/CASE3/200_net_D.pth\n",
            "     22,144,573 100%   17.57MB/s    0:00:01 (xfr#221, to-chk=252/507)\n",
            "NucleiSegmentation/checkpoints/CASE3/200_net_G.pth\n",
            "    217,727,015 100%   32.88MB/s    0:00:06 (xfr#222, to-chk=251/507)\n",
            "NucleiSegmentation/checkpoints/CASE3/latest_net_D.pth\n",
            "     22,144,571 100%   21.31MB/s    0:00:00 (xfr#223, to-chk=250/507)\n",
            "NucleiSegmentation/checkpoints/CASE3/latest_net_G.pth\n",
            "    217,727,105 100%   29.63MB/s    0:00:07 (xfr#224, to-chk=249/507)\n",
            "NucleiSegmentation/checkpoints/CASE3/loss_log.txt\n",
            "          6,332 100%  772.95kB/s    0:00:00 (xfr#225, to-chk=248/507)\n",
            "NucleiSegmentation/checkpoints/CASE3/opt.txt\n",
            "          3,289 100%  356.88kB/s    0:00:00 (xfr#226, to-chk=247/507)\n",
            "NucleiSegmentation/checkpoints/CASE3/web/\n",
            "NucleiSegmentation/checkpoints/CASE3/web/index.html\n",
            "        194,247 100%    5.61MB/s    0:00:00 (xfr#227, to-chk=245/507)\n",
            "NucleiSegmentation/checkpoints/CASE3/web/images/\n",
            "NucleiSegmentation/checkpoints/CASE3/web/images/epoch014_fake_B.png\n",
            "         68,582 100%    1.87MB/s    0:00:00 (xfr#228, to-chk=243/507)\n",
            "NucleiSegmentation/checkpoints/CASE3/web/images/epoch014_real_A.png\n",
            "        169,129 100%    2.48MB/s    0:00:00 (xfr#229, to-chk=242/507)\n",
            "NucleiSegmentation/checkpoints/CASE3/web/images/epoch014_real_B.png\n",
            "         37,248 100%  559.62kB/s    0:00:00 (xfr#230, to-chk=241/507)\n",
            "NucleiSegmentation/checkpoints/CASE3/web/images/epoch027_fake_B.png\n",
            "         30,364 100%  442.57kB/s    0:00:00 (xfr#231, to-chk=240/507)\n",
            "NucleiSegmentation/checkpoints/CASE3/web/images/epoch027_real_A.png\n",
            "        171,539 100%    1.95MB/s    0:00:00 (xfr#232, to-chk=239/507)\n",
            "NucleiSegmentation/checkpoints/CASE3/web/images/epoch027_real_B.png\n",
            "         19,839 100%  230.64kB/s    0:00:00 (xfr#233, to-chk=238/507)\n",
            "NucleiSegmentation/checkpoints/CASE3/web/images/epoch040_fake_B.png\n",
            "        118,210 100%    1.33MB/s    0:00:00 (xfr#234, to-chk=237/507)\n",
            "NucleiSegmentation/checkpoints/CASE3/web/images/epoch040_real_A.png\n",
            "        150,127 100%    1.42MB/s    0:00:00 (xfr#235, to-chk=236/507)\n",
            "NucleiSegmentation/checkpoints/CASE3/web/images/epoch040_real_B.png\n",
            "         24,853 100%  240.30kB/s    0:00:00 (xfr#236, to-chk=235/507)\n",
            "NucleiSegmentation/checkpoints/CASE3/web/images/epoch054_fake_B.png\n",
            "         78,474 100%  736.87kB/s    0:00:00 (xfr#237, to-chk=234/507)\n",
            "NucleiSegmentation/checkpoints/CASE3/web/images/epoch054_real_A.png\n",
            "        163,566 100%    1.31MB/s    0:00:00 (xfr#238, to-chk=233/507)\n",
            "NucleiSegmentation/checkpoints/CASE3/web/images/epoch054_real_B.png\n",
            "         16,696 100%  137.01kB/s    0:00:00 (xfr#239, to-chk=232/507)\n",
            "NucleiSegmentation/checkpoints/CASE3/web/images/epoch067_fake_B.png\n",
            "         68,924 100%  565.62kB/s    0:00:00 (xfr#240, to-chk=231/507)\n",
            "NucleiSegmentation/checkpoints/CASE3/web/images/epoch067_real_A.png\n",
            "        154,031 100%    1.10MB/s    0:00:00 (xfr#241, to-chk=230/507)\n",
            "NucleiSegmentation/checkpoints/CASE3/web/images/epoch067_real_B.png\n",
            "         18,389 100%  134.01kB/s    0:00:00 (xfr#242, to-chk=229/507)\n",
            "NucleiSegmentation/checkpoints/CASE3/web/images/epoch080_fake_B.png\n",
            "         45,877 100%  331.86kB/s    0:00:00 (xfr#243, to-chk=228/507)\n",
            "NucleiSegmentation/checkpoints/CASE3/web/images/epoch080_real_A.png\n",
            "        163,566 100%  892.36kB/s    0:00:00 (xfr#244, to-chk=227/507)\n",
            "NucleiSegmentation/checkpoints/CASE3/web/images/epoch080_real_B.png\n",
            "         16,696 100%   90.58kB/s    0:00:00 (xfr#245, to-chk=226/507)\n",
            "NucleiSegmentation/checkpoints/CASE3/web/images/epoch094_fake_B.png\n",
            "         58,056 100%  314.97kB/s    0:00:00 (xfr#246, to-chk=225/507)\n",
            "NucleiSegmentation/checkpoints/CASE3/web/images/epoch094_real_A.png\n",
            "        153,941 100%  770.94kB/s    0:00:00 (xfr#247, to-chk=224/507)\n",
            "NucleiSegmentation/checkpoints/CASE3/web/images/epoch094_real_B.png\n",
            "         21,591 100%  108.13kB/s    0:00:00 (xfr#248, to-chk=223/507)\n",
            "NucleiSegmentation/checkpoints/CASE3/web/images/epoch107_fake_B.png\n",
            "         48,246 100%  241.62kB/s    0:00:00 (xfr#249, to-chk=222/507)\n",
            "NucleiSegmentation/checkpoints/CASE3/web/images/epoch107_real_A.png\n",
            "        153,941 100%  715.87kB/s    0:00:00 (xfr#250, to-chk=221/507)\n",
            "NucleiSegmentation/checkpoints/CASE3/web/images/epoch107_real_B.png\n",
            "         21,591 100%  100.40kB/s    0:00:00 (xfr#251, to-chk=220/507)\n",
            "NucleiSegmentation/checkpoints/CASE3/web/images/epoch120_fake_B.png\n",
            "         36,251 100%  167.78kB/s    0:00:00 (xfr#252, to-chk=219/507)\n",
            "NucleiSegmentation/checkpoints/CASE3/web/images/epoch120_real_A.png\n",
            "        161,842 100%  702.44kB/s    0:00:00 (xfr#253, to-chk=218/507)\n",
            "NucleiSegmentation/checkpoints/CASE3/web/images/epoch120_real_B.png\n",
            "         18,853 100%   81.83kB/s    0:00:00 (xfr#254, to-chk=217/507)\n",
            "NucleiSegmentation/checkpoints/CASE3/web/images/epoch134_fake_B.png\n",
            "         26,768 100%  115.67kB/s    0:00:00 (xfr#255, to-chk=216/507)\n",
            "NucleiSegmentation/checkpoints/CASE3/web/images/epoch134_real_A.png\n",
            "        163,566 100%  662.79kB/s    0:00:00 (xfr#256, to-chk=215/507)\n",
            "NucleiSegmentation/checkpoints/CASE3/web/images/epoch134_real_B.png\n",
            "         16,696 100%   67.37kB/s    0:00:00 (xfr#257, to-chk=214/507)\n",
            "NucleiSegmentation/checkpoints/CASE3/web/images/epoch147_fake_B.png\n",
            "         40,830 100%  164.76kB/s    0:00:00 (xfr#258, to-chk=213/507)\n",
            "NucleiSegmentation/checkpoints/CASE3/web/images/epoch147_real_A.png\n",
            "        168,809 100%  416.29kB/s    0:00:00 (xfr#259, to-chk=212/507)\n",
            "NucleiSegmentation/checkpoints/CASE3/web/images/epoch147_real_B.png\n",
            "         24,119 100%   59.48kB/s    0:00:00 (xfr#260, to-chk=211/507)\n",
            "NucleiSegmentation/checkpoints/CASE3/web/images/epoch160_fake_B.png\n",
            "         41,420 100%  102.14kB/s    0:00:00 (xfr#261, to-chk=210/507)\n",
            "NucleiSegmentation/checkpoints/CASE3/web/images/epoch160_real_A.png\n",
            "        172,268 100%  409.32kB/s    0:00:00 (xfr#262, to-chk=209/507)\n",
            "NucleiSegmentation/checkpoints/CASE3/web/images/epoch160_real_B.png\n",
            "         25,649 100%   60.80kB/s    0:00:00 (xfr#263, to-chk=208/507)\n",
            "NucleiSegmentation/checkpoints/CASE3/web/images/epoch174_fake_B.png\n",
            "         48,212 100%  114.28kB/s    0:00:00 (xfr#264, to-chk=207/507)\n",
            "NucleiSegmentation/checkpoints/CASE3/web/images/epoch174_real_A.png\n",
            "        142,540 100%  325.99kB/s    0:00:00 (xfr#265, to-chk=206/507)\n",
            "NucleiSegmentation/checkpoints/CASE3/web/images/epoch174_real_B.png\n",
            "         28,963 100%   66.24kB/s    0:00:00 (xfr#266, to-chk=205/507)\n",
            "NucleiSegmentation/checkpoints/CASE3/web/images/epoch187_fake_B.png\n",
            "         24,134 100%   55.20kB/s    0:00:00 (xfr#267, to-chk=204/507)\n",
            "NucleiSegmentation/checkpoints/CASE3/web/images/epoch187_real_A.png\n",
            "        169,903 100%  375.39kB/s    0:00:00 (xfr#268, to-chk=203/507)\n",
            "NucleiSegmentation/checkpoints/CASE3/web/images/epoch187_real_B.png\n",
            "         17,000 100%   37.56kB/s    0:00:00 (xfr#269, to-chk=202/507)\n",
            "NucleiSegmentation/checkpoints/CASE3/web/images/epoch200_fake_B.png\n",
            "         65,069 100%  143.44kB/s    0:00:00 (xfr#270, to-chk=201/507)\n",
            "NucleiSegmentation/checkpoints/CASE3/web/images/epoch200_real_A.png\n",
            "        173,134 100%  288.03kB/s    0:00:00 (xfr#271, to-chk=200/507)\n",
            "NucleiSegmentation/checkpoints/CASE3/web/images/epoch200_real_B.png\n",
            "         35,938 100%   59.79kB/s    0:00:00 (xfr#272, to-chk=199/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/\n",
            "NucleiSegmentation/checkpoints/CASE4/100_net_D_A.pth\n",
            "     22,119,994 100%   17.67MB/s    0:00:01 (xfr#273, to-chk=198/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/100_net_D_B.pth\n",
            "     22,119,994 100%   17.77MB/s    0:00:01 (xfr#274, to-chk=197/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/100_net_G_A.pth\n",
            "    217,726,742 100%   31.41MB/s    0:00:06 (xfr#275, to-chk=196/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/100_net_G_B.pth\n",
            "    217,726,853 100%   30.81MB/s    0:00:06 (xfr#276, to-chk=195/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/200_net_D_A.pth\n",
            "     22,119,981 100%   17.56MB/s    0:00:01 (xfr#277, to-chk=194/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/200_net_D_B.pth\n",
            "     22,119,981 100%   26.27MB/s    0:00:00 (xfr#278, to-chk=193/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/200_net_G_A.pth\n",
            "    217,726,707 100%   30.51MB/s    0:00:06 (xfr#279, to-chk=192/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/200_net_G_B.pth\n",
            "    217,726,848 100%   30.51MB/s    0:00:06 (xfr#280, to-chk=191/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/latest_net_D_A.pth\n",
            "     22,119,978 100%   14.97MB/s    0:00:01 (xfr#281, to-chk=190/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/latest_net_D_B.pth\n",
            "     22,119,913 100%   20.89MB/s    0:00:01 (xfr#282, to-chk=189/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/latest_net_G_A.pth\n",
            "    217,726,720 100%   34.53MB/s    0:00:06 (xfr#283, to-chk=188/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/latest_net_G_B.pth\n",
            "    217,726,834 100%   34.53MB/s    0:00:06 (xfr#284, to-chk=187/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/loss_log.txt\n",
            "          9,104 100%  555.66kB/s    0:00:00 (xfr#285, to-chk=186/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/opt.txt\n",
            "          3,444 100%  197.84kB/s    0:00:00 (xfr#286, to-chk=185/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/\n",
            "NucleiSegmentation/checkpoints/CASE4/web/index.html\n",
            "        477,847 100%   10.85MB/s    0:00:00 (xfr#287, to-chk=183/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch014_fake_A.png\n",
            "        151,119 100%    2.77MB/s    0:00:00 (xfr#288, to-chk=181/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch014_fake_B.png\n",
            "        184,284 100%    2.88MB/s    0:00:00 (xfr#289, to-chk=180/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch014_idt_A.png\n",
            "         56,904 100%  896.30kB/s    0:00:00 (xfr#290, to-chk=179/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch014_idt_B.png\n",
            "        131,639 100%    1.72MB/s    0:00:00 (xfr#291, to-chk=178/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch014_real_A.png\n",
            "        167,582 100%    1.86MB/s    0:00:00 (xfr#292, to-chk=177/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch014_real_B.png\n",
            "         16,696 100%  133.64kB/s    0:00:00 (xfr#293, to-chk=176/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch014_rec_A.png\n",
            "        146,276 100%  958.71kB/s    0:00:00 (xfr#294, to-chk=175/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch014_rec_B.png\n",
            "        115,112 100%  749.43kB/s    0:00:00 (xfr#295, to-chk=174/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch027_fake_A.png\n",
            "        157,095 100%  952.88kB/s    0:00:00 (xfr#296, to-chk=173/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch027_fake_B.png\n",
            "        178,923 100%    1.01MB/s    0:00:00 (xfr#297, to-chk=172/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch027_idt_A.png\n",
            "        100,052 100%  571.39kB/s    0:00:00 (xfr#298, to-chk=171/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch027_idt_B.png\n",
            "        142,279 100%  767.65kB/s    0:00:00 (xfr#299, to-chk=170/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch027_real_A.png\n",
            "        171,747 100%  892.14kB/s    0:00:00 (xfr#300, to-chk=169/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch027_real_B.png\n",
            "         30,857 100%  160.29kB/s    0:00:00 (xfr#301, to-chk=168/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch027_rec_A.png\n",
            "        150,744 100%  743.49kB/s    0:00:00 (xfr#302, to-chk=167/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch027_rec_B.png\n",
            "        120,210 100%  589.91kB/s    0:00:00 (xfr#303, to-chk=166/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch040_fake_A.png\n",
            "        166,982 100%  780.23kB/s    0:00:00 (xfr#304, to-chk=165/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch040_fake_B.png\n",
            "        124,825 100%  572.30kB/s    0:00:00 (xfr#305, to-chk=164/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch040_idt_A.png\n",
            "         51,429 100%  230.38kB/s    0:00:00 (xfr#306, to-chk=163/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch040_idt_B.png\n",
            "        144,465 100%  618.77kB/s    0:00:00 (xfr#307, to-chk=162/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch040_real_A.png\n",
            "        163,971 100%  485.24kB/s    0:00:00 (xfr#308, to-chk=161/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch040_real_B.png\n",
            "         20,446 100%   60.51kB/s    0:00:00 (xfr#309, to-chk=160/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch040_rec_A.png\n",
            "        151,948 100%  433.88kB/s    0:00:00 (xfr#310, to-chk=159/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch040_rec_B.png\n",
            "         70,243 100%  199.99kB/s    0:00:00 (xfr#311, to-chk=158/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch054_fake_A.png\n",
            "        171,473 100%  471.70kB/s    0:00:00 (xfr#312, to-chk=157/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch054_fake_B.png\n",
            "         84,755 100%  232.50kB/s    0:00:00 (xfr#313, to-chk=156/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch054_idt_A.png\n",
            "         51,822 100%  142.16kB/s    0:00:00 (xfr#314, to-chk=155/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch054_idt_B.png\n",
            "        140,062 100%  363.77kB/s    0:00:00 (xfr#315, to-chk=154/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch054_real_A.png\n",
            "        152,276 100%  388.27kB/s    0:00:00 (xfr#316, to-chk=153/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch054_real_B.png\n",
            "         24,104 100%   61.46kB/s    0:00:00 (xfr#317, to-chk=152/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch054_rec_A.png\n",
            "        149,998 100%  369.91kB/s    0:00:00 (xfr#318, to-chk=151/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch054_rec_B.png\n",
            "         79,157 100%  195.21kB/s    0:00:00 (xfr#319, to-chk=150/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch067_fake_A.png\n",
            "        161,792 100%  386.31kB/s    0:00:00 (xfr#320, to-chk=149/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch067_fake_B.png\n",
            "        181,409 100%  423.82kB/s    0:00:00 (xfr#321, to-chk=148/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch067_idt_A.png\n",
            "         29,194 100%   68.21kB/s    0:00:00 (xfr#322, to-chk=147/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch067_idt_B.png\n",
            "        134,879 100%  247.59kB/s    0:00:00 (xfr#323, to-chk=146/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch067_real_A.png\n",
            "        164,890 100%  298.75kB/s    0:00:00 (xfr#324, to-chk=145/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch067_real_B.png\n",
            "         17,964 100%   32.55kB/s    0:00:00 (xfr#325, to-chk=144/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch067_rec_A.png\n",
            "        149,982 100%  263.43kB/s    0:00:00 (xfr#326, to-chk=143/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch067_rec_B.png\n",
            "         38,307 100%   67.16kB/s    0:00:00 (xfr#327, to-chk=142/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch080_fake_A.png\n",
            "        166,405 100%  283.60kB/s    0:00:00 (xfr#328, to-chk=141/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch080_fake_B.png\n",
            "        169,551 100%  283.52kB/s    0:00:00 (xfr#329, to-chk=140/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch080_idt_A.png\n",
            "         37,852 100%   63.30kB/s    0:00:00 (xfr#330, to-chk=139/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch080_idt_B.png\n",
            "        146,931 100%  240.35kB/s    0:00:00 (xfr#331, to-chk=138/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch080_real_A.png\n",
            "        166,965 100%  269.95kB/s    0:00:00 (xfr#332, to-chk=137/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch080_real_B.png\n",
            "         24,104 100%   38.91kB/s    0:00:00 (xfr#333, to-chk=136/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch080_rec_A.png\n",
            "        148,895 100%  234.52kB/s    0:00:00 (xfr#334, to-chk=135/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch080_rec_B.png\n",
            "         56,538 100%   89.05kB/s    0:00:00 (xfr#335, to-chk=134/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch094_fake_A.png\n",
            "        160,506 100%  216.80kB/s    0:00:00 (xfr#336, to-chk=133/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch094_fake_B.png\n",
            "        114,384 100%  153.86kB/s    0:00:00 (xfr#337, to-chk=132/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch094_idt_A.png\n",
            "         22,540 100%   30.07kB/s    0:00:00 (xfr#338, to-chk=131/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch094_idt_B.png\n",
            "        156,082 100%  204.87kB/s    0:00:00 (xfr#339, to-chk=130/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch094_real_A.png\n",
            "        170,148 100%  220.96kB/s    0:00:00 (xfr#340, to-chk=129/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch094_real_B.png\n",
            "         17,933 100%   23.29kB/s    0:00:00 (xfr#341, to-chk=128/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch094_rec_A.png\n",
            "        151,618 100%  193.55kB/s    0:00:00 (xfr#342, to-chk=127/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch094_rec_B.png\n",
            "         29,774 100%   37.96kB/s    0:00:00 (xfr#343, to-chk=126/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch107_fake_A.png\n",
            "        171,559 100%  215.07kB/s    0:00:00 (xfr#344, to-chk=125/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch107_fake_B.png\n",
            "        135,328 100%  167.50kB/s    0:00:00 (xfr#345, to-chk=124/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch107_idt_A.png\n",
            "         38,876 100%   48.06kB/s    0:00:00 (xfr#346, to-chk=123/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch107_idt_B.png\n",
            "        158,713 100%  193.02kB/s    0:00:00 (xfr#347, to-chk=122/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch107_real_A.png\n",
            "        169,018 100%  203.02kB/s    0:00:00 (xfr#348, to-chk=121/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch107_real_B.png\n",
            "         27,472 100%   33.00kB/s    0:00:00 (xfr#349, to-chk=120/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch107_rec_A.png\n",
            "        150,970 100%  159.56kB/s    0:00:00 (xfr#350, to-chk=119/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch107_rec_B.png\n",
            "         68,097 100%   71.89kB/s    0:00:00 (xfr#351, to-chk=118/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch120_fake_A.png\n",
            "        170,180 100%  176.99kB/s    0:00:00 (xfr#352, to-chk=117/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch120_fake_B.png\n",
            "         72,672 100%   75.58kB/s    0:00:00 (xfr#353, to-chk=116/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch120_idt_A.png\n",
            "         31,427 100%   32.65kB/s    0:00:00 (xfr#354, to-chk=115/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch120_idt_B.png\n",
            "        148,225 100%  151.25kB/s    0:00:00 (xfr#355, to-chk=114/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch120_real_A.png\n",
            "        153,676 100%  155.52kB/s    0:00:00 (xfr#356, to-chk=113/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch120_real_B.png\n",
            "         24,912 100%   25.21kB/s    0:00:00 (xfr#357, to-chk=112/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch120_rec_A.png\n",
            "        143,333 100%  143.42kB/s    0:00:00 (xfr#358, to-chk=111/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch120_rec_B.png\n",
            "         46,611 100%   46.64kB/s    0:00:00 (xfr#359, to-chk=110/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch134_fake_A.png\n",
            "        169,966 100%  168.17kB/s    0:00:00 (xfr#360, to-chk=109/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch134_fake_B.png\n",
            "        118,586 100%  116.98kB/s    0:00:00 (xfr#361, to-chk=108/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch134_idt_A.png\n",
            "         34,787 100%   34.11kB/s    0:00:00 (xfr#362, to-chk=107/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch134_idt_B.png\n",
            "        158,466 100%  153.52kB/s    0:00:01 (xfr#363, to-chk=106/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch134_real_A.png\n",
            "        168,666 100%    1.39MB/s    0:00:00 (xfr#364, to-chk=105/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch134_real_B.png\n",
            "         28,071 100%  236.32kB/s    0:00:00 (xfr#365, to-chk=104/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch134_rec_A.png\n",
            "        152,188 100%    1.13MB/s    0:00:00 (xfr#366, to-chk=103/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch134_rec_B.png\n",
            "         53,878 100%  407.87kB/s    0:00:00 (xfr#367, to-chk=102/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch147_fake_A.png\n",
            "        168,433 100%    1.13MB/s    0:00:00 (xfr#368, to-chk=101/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch147_fake_B.png\n",
            "        124,597 100%  844.98kB/s    0:00:00 (xfr#369, to-chk=100/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch147_idt_A.png\n",
            "         24,382 100%  157.69kB/s    0:00:00 (xfr#370, to-chk=99/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch147_idt_B.png\n",
            "        157,742 100%  939.30kB/s    0:00:00 (xfr#371, to-chk=98/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch147_real_A.png\n",
            "        165,442 100%  933.90kB/s    0:00:00 (xfr#372, to-chk=97/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch147_real_B.png\n",
            "         21,732 100%  122.67kB/s    0:00:00 (xfr#373, to-chk=96/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch147_rec_A.png\n",
            "        152,629 100%  810.06kB/s    0:00:00 (xfr#374, to-chk=95/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch147_rec_B.png\n",
            "         41,014 100%  217.68kB/s    0:00:00 (xfr#375, to-chk=94/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch160_fake_A.png\n",
            "        167,324 100%  837.96kB/s    0:00:00 (xfr#376, to-chk=93/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch160_fake_B.png\n",
            "        104,176 100%  508.67kB/s    0:00:00 (xfr#377, to-chk=92/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch160_idt_A.png\n",
            "         29,411 100%  139.43kB/s    0:00:00 (xfr#378, to-chk=91/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch160_idt_B.png\n",
            "        166,374 100%  501.46kB/s    0:00:00 (xfr#379, to-chk=90/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch160_real_A.png\n",
            "        171,747 100%  503.67kB/s    0:00:00 (xfr#380, to-chk=89/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch160_real_B.png\n",
            "         25,649 100%   75.22kB/s    0:00:00 (xfr#381, to-chk=88/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch160_rec_A.png\n",
            "        154,719 100%  437.95kB/s    0:00:00 (xfr#382, to-chk=87/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch160_rec_B.png\n",
            "         47,185 100%  133.56kB/s    0:00:00 (xfr#383, to-chk=86/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch174_fake_A.png\n",
            "        168,745 100%  461.60kB/s    0:00:00 (xfr#384, to-chk=85/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch174_fake_B.png\n",
            "        116,548 100%  317.92kB/s    0:00:00 (xfr#385, to-chk=84/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch174_idt_A.png\n",
            "         38,985 100%  104.30kB/s    0:00:00 (xfr#386, to-chk=83/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch174_idt_B.png\n",
            "        161,451 100%  417.11kB/s    0:00:00 (xfr#387, to-chk=82/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch174_real_A.png\n",
            "        171,539 100%  435.11kB/s    0:00:00 (xfr#388, to-chk=81/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch174_real_B.png\n",
            "         30,857 100%   78.27kB/s    0:00:00 (xfr#389, to-chk=80/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch174_rec_A.png\n",
            "        152,371 100%  372.93kB/s    0:00:00 (xfr#390, to-chk=79/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch174_rec_B.png\n",
            "         54,722 100%  133.93kB/s    0:00:00 (xfr#391, to-chk=78/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch187_fake_A.png\n",
            "        159,729 100%  301.71kB/s    0:00:00 (xfr#392, to-chk=77/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch187_fake_B.png\n",
            "         79,947 100%  151.01kB/s    0:00:00 (xfr#393, to-chk=76/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch187_idt_A.png\n",
            "         17,467 100%   32.93kB/s    0:00:00 (xfr#394, to-chk=75/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch187_idt_B.png\n",
            "        168,187 100%  304.72kB/s    0:00:00 (xfr#395, to-chk=74/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch187_real_A.png\n",
            "        172,142 100%  307.89kB/s    0:00:00 (xfr#396, to-chk=73/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch187_real_B.png\n",
            "         16,696 100%   29.86kB/s    0:00:00 (xfr#397, to-chk=72/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch187_rec_A.png\n",
            "        162,512 100%  283.40kB/s    0:00:00 (xfr#398, to-chk=71/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch187_rec_B.png\n",
            "         27,174 100%   47.39kB/s    0:00:00 (xfr#399, to-chk=70/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch200_fake_A.png\n",
            "        162,651 100%  277.21kB/s    0:00:00 (xfr#400, to-chk=69/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch200_fake_B.png\n",
            "         61,576 100%  104.94kB/s    0:00:00 (xfr#401, to-chk=68/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch200_idt_A.png\n",
            "         19,256 100%   32.76kB/s    0:00:00 (xfr#402, to-chk=67/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch200_idt_B.png\n",
            "        164,614 100%  271.55kB/s    0:00:00 (xfr#403, to-chk=66/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch200_real_A.png\n",
            "        172,770 100%  281.67kB/s    0:00:00 (xfr#404, to-chk=65/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch200_real_B.png\n",
            "         17,964 100%   29.24kB/s    0:00:00 (xfr#405, to-chk=64/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch200_rec_A.png\n",
            "        145,594 100%  198.02kB/s    0:00:00 (xfr#406, to-chk=63/507)\n",
            "NucleiSegmentation/checkpoints/CASE4/web/images/epoch200_rec_B.png\n",
            "         31,478 100%   42.81kB/s    0:00:00 (xfr#407, to-chk=62/507)\n",
            "NucleiSegmentation/data/\n",
            "NucleiSegmentation/data/__init__.py\n",
            "          2,406 100%    3.27kB/s    0:00:00 (xfr#408, to-chk=61/507)\n",
            "NucleiSegmentation/data/aligned_dataset.py\n",
            "          2,504 100%    3.40kB/s    0:00:00 (xfr#409, to-chk=60/507)\n",
            "NucleiSegmentation/data/base_data_loader.py\n",
            "            171 100%    0.23kB/s    0:00:00 (xfr#410, to-chk=59/507)\n",
            "NucleiSegmentation/data/base_dataset.py\n",
            "          3,421 100%    4.63kB/s    0:00:00 (xfr#411, to-chk=58/507)\n",
            "NucleiSegmentation/data/image_folder.py\n",
            "          1,946 100%    2.63kB/s    0:00:00 (xfr#412, to-chk=57/507)\n",
            "NucleiSegmentation/data/single_dataset.py\n",
            "          1,151 100%    1.55kB/s    0:00:00 (xfr#413, to-chk=56/507)\n",
            "NucleiSegmentation/data/unaligned_dataset.py\n",
            "          2,055 100%    2.78kB/s    0:00:00 (xfr#414, to-chk=55/507)\n",
            "NucleiSegmentation/data/__pycache__/\n",
            "NucleiSegmentation/data/__pycache__/__init__.cpython-36.pyc\n",
            "          2,574 100%    3.48kB/s    0:00:00 (xfr#415, to-chk=53/507)\n",
            "NucleiSegmentation/data/__pycache__/aligned_dataset.cpython-36.pyc\n",
            "          2,751 100%    3.72kB/s    0:00:00 (xfr#416, to-chk=52/507)\n",
            "NucleiSegmentation/data/__pycache__/base_data_loader.cpython-36.pyc\n",
            "            668 100%    0.90kB/s    0:00:00 (xfr#417, to-chk=51/507)\n",
            "NucleiSegmentation/data/__pycache__/base_dataset.cpython-36.pyc\n",
            "          3,384 100%    4.57kB/s    0:00:00 (xfr#418, to-chk=50/507)\n",
            "NucleiSegmentation/data/__pycache__/image_folder.cpython-36.pyc\n",
            "          2,050 100%    2.77kB/s    0:00:00 (xfr#419, to-chk=49/507)\n",
            "NucleiSegmentation/data/__pycache__/unaligned_dataset.cpython-36.pyc\n",
            "          2,154 100%    2.91kB/s    0:00:00 (xfr#420, to-chk=48/507)\n",
            "NucleiSegmentation/datasets/\n",
            "NucleiSegmentation/datasets/Nuclei_Segmentation/\n",
            "NucleiSegmentation/datasets/Nuclei_Segmentation/test/\n",
            "NucleiSegmentation/datasets/Nuclei_Segmentation/test/example.jpg\n",
            "         27,099 100%   36.60kB/s    0:00:00 (xfr#421, to-chk=44/507)\n",
            "NucleiSegmentation/datasets/Nuclei_Segmentation/train/\n",
            "NucleiSegmentation/datasets/Nuclei_Segmentation/train/example.jpg\n",
            "         31,383 100%   42.39kB/s    0:00:00 (xfr#422, to-chk=43/507)\n",
            "NucleiSegmentation/imgs/\n",
            "NucleiSegmentation/imgs/6.gif\n",
            "        143,958 100%  149.08kB/s    0:00:00 (xfr#423, to-chk=42/507)\n",
            "NucleiSegmentation/imgs/7.gif\n",
            "        148,575 100%  152.89kB/s    0:00:00 (xfr#424, to-chk=41/507)\n",
            "NucleiSegmentation/imgs/8.gif\n",
            "        148,773 100%  152.13kB/s    0:00:00 (xfr#425, to-chk=40/507)\n",
            "NucleiSegmentation/models/\n",
            "NucleiSegmentation/models/__init__.py\n",
            "          1,267 100%    1.30kB/s    0:00:00 (xfr#426, to-chk=39/507)\n",
            "NucleiSegmentation/models/base_model.py\n",
            "          6,278 100%    6.42kB/s    0:00:00 (xfr#427, to-chk=38/507)\n",
            "NucleiSegmentation/models/cycle_gan_model.py\n",
            "          7,113 100%    7.27kB/s    0:00:00 (xfr#428, to-chk=37/507)\n",
            "NucleiSegmentation/models/networks.py\n",
            "         16,683 100%   17.06kB/s    0:00:00 (xfr#429, to-chk=36/507)\n",
            "NucleiSegmentation/models/pix2pix_model.py\n",
            "          4,548 100%    4.65kB/s    0:00:00 (xfr#430, to-chk=35/507)\n",
            "NucleiSegmentation/models/spectral_norm.py\n",
            "          6,076 100%    6.21kB/s    0:00:00 (xfr#431, to-chk=34/507)\n",
            "NucleiSegmentation/models/test_model.py\n",
            "          1,943 100%    1.98kB/s    0:00:00 (xfr#432, to-chk=33/507)\n",
            "NucleiSegmentation/models/__pycache__/\n",
            "NucleiSegmentation/models/__pycache__/__init__.cpython-36.pyc\n",
            "          1,132 100%    1.16kB/s    0:00:00 (xfr#433, to-chk=31/507)\n",
            "NucleiSegmentation/models/__pycache__/base_model.cpython-36.pyc\n",
            "          5,643 100%    5.76kB/s    0:00:00 (xfr#434, to-chk=30/507)\n",
            "NucleiSegmentation/models/__pycache__/cycle_gan_model.cpython-36.pyc\n",
            "          4,982 100%    5.09kB/s    0:00:00 (xfr#435, to-chk=29/507)\n",
            "NucleiSegmentation/models/__pycache__/networks.cpython-36.pyc\n",
            "         11,125 100%   11.36kB/s    0:00:00 (xfr#436, to-chk=28/507)\n",
            "NucleiSegmentation/models/__pycache__/pix2pix_model.cpython-36.pyc\n",
            "          3,531 100%    3.61kB/s    0:00:00 (xfr#437, to-chk=27/507)\n",
            "NucleiSegmentation/models/__pycache__/spectral_norm.cpython-36.pyc\n",
            "          5,325 100%    5.44kB/s    0:00:00 (xfr#438, to-chk=26/507)\n",
            "NucleiSegmentation/options/\n",
            "NucleiSegmentation/options/base_options.py\n",
            "          6,595 100%    6.74kB/s    0:00:00 (xfr#439, to-chk=25/507)\n",
            "NucleiSegmentation/options/test_options.py\n",
            "          1,056 100%    1.08kB/s    0:00:00 (xfr#440, to-chk=24/507)\n",
            "NucleiSegmentation/options/train_options.py\n",
            "          2,646 100%    2.70kB/s    0:00:00 (xfr#441, to-chk=23/507)\n",
            "NucleiSegmentation/options/__pycache__/\n",
            "NucleiSegmentation/options/__pycache__/base_options.cpython-36.pyc\n",
            "          5,240 100%    5.35kB/s    0:00:00 (xfr#442, to-chk=21/507)\n",
            "NucleiSegmentation/options/__pycache__/train_options.cpython-36.pyc\n",
            "          2,330 100%    2.38kB/s    0:00:00 (xfr#443, to-chk=20/507)\n",
            "NucleiSegmentation/scripts/\n",
            "NucleiSegmentation/scripts/conda_deps.sh\n",
            "            223 100%    0.23kB/s    0:00:00 (xfr#444, to-chk=19/507)\n",
            "NucleiSegmentation/scripts/download_cyclegan_model.sh\n",
            "            579 100%    0.59kB/s    0:00:00 (xfr#445, to-chk=18/507)\n",
            "NucleiSegmentation/scripts/download_pix2pix_model.sh\n",
            "            355 100%    0.36kB/s    0:00:00 (xfr#446, to-chk=17/507)\n",
            "NucleiSegmentation/scripts/install_deps.sh\n",
            "             48 100%    0.05kB/s    0:00:00 (xfr#447, to-chk=16/507)\n",
            "NucleiSegmentation/scripts/test_before_push.py\n",
            "          1,853 100%    1.89kB/s    0:00:00 (xfr#448, to-chk=15/507)\n",
            "NucleiSegmentation/scripts/test_cyclegan.sh\n",
            "            115 100%    0.12kB/s    0:00:00 (xfr#449, to-chk=14/507)\n",
            "NucleiSegmentation/scripts/test_pix2pix.sh\n",
            "            179 100%    0.18kB/s    0:00:00 (xfr#450, to-chk=13/507)\n",
            "NucleiSegmentation/scripts/test_single.sh\n",
            "            182 100%    0.19kB/s    0:00:00 (xfr#451, to-chk=12/507)\n",
            "NucleiSegmentation/scripts/train_cyclegan.sh\n",
            "            118 100%    0.12kB/s    0:00:00 (xfr#452, to-chk=11/507)\n",
            "NucleiSegmentation/scripts/train_pix2pix.sh\n",
            "            221 100%    0.23kB/s    0:00:00 (xfr#453, to-chk=10/507)\n",
            "NucleiSegmentation/util/\n",
            "NucleiSegmentation/util/get_data.py\n",
            "          3,511 100%    3.58kB/s    0:00:00 (xfr#454, to-chk=9/507)\n",
            "NucleiSegmentation/util/html.py\n",
            "          1,912 100%    1.95kB/s    0:00:00 (xfr#455, to-chk=8/507)\n",
            "NucleiSegmentation/util/image_pool.py\n",
            "          1,072 100%    1.09kB/s    0:00:00 (xfr#456, to-chk=7/507)\n",
            "NucleiSegmentation/util/util.py\n",
            "          1,613 100%    1.65kB/s    0:00:00 (xfr#457, to-chk=6/507)\n",
            "NucleiSegmentation/util/visualizer.py\n",
            "          7,336 100%    7.48kB/s    0:00:00 (xfr#458, to-chk=5/507)\n",
            "NucleiSegmentation/util/__pycache__/\n",
            "NucleiSegmentation/util/__pycache__/html.cpython-36.pyc\n",
            "          2,292 100%    2.34kB/s    0:00:00 (xfr#459, to-chk=3/507)\n",
            "NucleiSegmentation/util/__pycache__/image_pool.cpython-36.pyc\n",
            "            977 100%    1.00kB/s    0:00:00 (xfr#460, to-chk=2/507)\n",
            "NucleiSegmentation/util/__pycache__/util.cpython-36.pyc\n",
            "          1,876 100%    1.91kB/s    0:00:00 (xfr#461, to-chk=1/507)\n",
            "NucleiSegmentation/util/__pycache__/visualizer.cpython-36.pyc\n",
            "          5,800 100%    5.91kB/s    0:00:00 (xfr#462, to-chk=0/507)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Ml4oEsjw86U",
        "outputId": "345bfb0f-69c0-4f78-b8b9-d0bcd6e6ef51"
      },
      "source": [
        "!du -sh NucleiSegmentation/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4.1G\tNucleiSegmentation/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16PqIaAgAdpb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}